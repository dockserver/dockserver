{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"DockServer \u00b6 Docker + Traefik with Authelia and Cloudflare Protection Migration \u00b6 If you currently have a server with PG/MHS/PTS, have a look here before you start the installation: Migration Guide Minimum Specs and Requirements \u00b6 Stable: Ubuntu 22 CPU 2 Cores or 2 VCores (x86/x64) No ARM Support 4GB Ram 20GB Disk Space A VPS/VM or Dedicated Server your Domain or buy a new namecheap Cloudflare account free tier For Testing \u00b6 Hetzner Cloud Digital Ocean Vault Pre-Install \u00b6 Login to your Cloudflare Account & goto DNS click on Add record. Add 1 A-Record pointed to your server's ip. Copy your CloudFlare-Global-Key and CloudFlare-Zone-ID . Set the following on Cloudflare \u00b6 SSL = FULL ( not FULL/STRICT ) Always on = YES HTTP to HTTPS = YES RocketLoader and Broli / Onion Routing = NO TLS min = 1.2 TLS = v1.3 Easy Mode install \u00b6 Follow our install instructions: Wiki Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Code and Permissions \u00b6 Copyright 2021 @dockserver Code owner @dockserver Dev Code @dockserver Co-Dev -APPS- @CONTRIBUTORS-LIST Contributors \u2728 \u00b6 Thanks goes to these wonderful people ( emoji key ): Contributors \u00b6 doob187 FSCorrupt DrAg0n141 Aelfa cyb3rgh05t justinglock40 mrfret DoCtEuR3805 | FRENCH-QC brtbach Mend Renovate ramsaytc Shayne Nossersvinet Ookla, Ariel, Ride! Imgbot James Townsend Red Daut domesticwarlord86","title":"Home"},{"location":"index.html#dockserver","text":"Docker + Traefik with Authelia and Cloudflare Protection","title":"DockServer"},{"location":"index.html#migration","text":"If you currently have a server with PG/MHS/PTS, have a look here before you start the installation: Migration Guide","title":"Migration"},{"location":"index.html#minimum-specs-and-requirements","text":"Stable: Ubuntu 22 CPU 2 Cores or 2 VCores (x86/x64) No ARM Support 4GB Ram 20GB Disk Space A VPS/VM or Dedicated Server your Domain or buy a new namecheap Cloudflare account free tier","title":"Minimum Specs and Requirements"},{"location":"index.html#for-testing","text":"Hetzner Cloud Digital Ocean Vault","title":"For Testing"},{"location":"index.html#pre-install","text":"Login to your Cloudflare Account & goto DNS click on Add record. Add 1 A-Record pointed to your server's ip. Copy your CloudFlare-Global-Key and CloudFlare-Zone-ID .","title":"Pre-Install"},{"location":"index.html#set-the-following-on-cloudflare","text":"SSL = FULL ( not FULL/STRICT ) Always on = YES HTTP to HTTPS = YES RocketLoader and Broli / Onion Routing = NO TLS min = 1.2 TLS = v1.3","title":"Set the following on Cloudflare"},{"location":"index.html#easy-mode-install","text":"Follow our install instructions: Wiki","title":"Easy Mode install"},{"location":"index.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord","title":"Support"},{"location":"index.html#code-and-permissions","text":"Copyright 2021 @dockserver Code owner @dockserver Dev Code @dockserver Co-Dev -APPS- @CONTRIBUTORS-LIST","title":"Code and Permissions"},{"location":"index.html#contributors","text":"Thanks goes to these wonderful people ( emoji key ):","title":"Contributors \u2728"},{"location":"index.html#contributors_1","text":"doob187 FSCorrupt DrAg0n141 Aelfa cyb3rgh05t justinglock40 mrfret DoCtEuR3805 | FRENCH-QC brtbach Mend Renovate ramsaytc Shayne Nossersvinet Ookla, Ariel, Ride! Imgbot James Townsend Red Daut domesticwarlord86","title":"Contributors"},{"location":"apps/apps.html","text":"Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Applications"},{"location":"apps/apps.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/a-train.html","text":"A-Train \u00b6 A-Train is the official Autoscan trigger that listens for changes within Google Drive. It is the successor of Autoscan's Bernard trigger, which unfortunately contains enough logic errors to prompt a rewrite. Supports Shared Drives Service Account -based authentication Does not support My Drive Does not support encrypted files Does not support alternative authentication methods Prerequisites \u00b6 A-Train works exclusively through Shared Drives and Service Accounts . Shared Drives can only be created on GSuite / Google Workspace accounts. First, you must create a Service Account and create a JSON key . Afterwards, if you do not have one already, create a Shared Drive within Google Drive and then add the email address of the Service Account to the Shared Drive (with Reader permission). Setup A-Train \u00b6 Install A-Train from Docksever Addons Menu. Stop the container. sudo docker stop a-train Head over to the appdata folder. cd /opt/appdata/a-train/data/ Create a a-train.toml file. sudo nano a-train.toml Copy / Paste the following config into the created file from previous step and edit it to your needs. [autoscan] url = \"http://autoscan:3030\" username = \"your_username\" password = \"your_password\" [drive] account = \"./service-account.json\" drives = [\"shared_drive_id\", ....] Create a service-account.json. create a Service Account and create a JSON key . Copy it in /opt/appdata/a-train/data/ That\u00b4s it... Now you can start A-Train with sudo docker start a-train and check logs sudo docker logs -f a-train for errors. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"A-Train"},{"location":"apps/addons/a-train.html#a-train","text":"A-Train is the official Autoscan trigger that listens for changes within Google Drive. It is the successor of Autoscan's Bernard trigger, which unfortunately contains enough logic errors to prompt a rewrite. Supports Shared Drives Service Account -based authentication Does not support My Drive Does not support encrypted files Does not support alternative authentication methods","title":"A-Train"},{"location":"apps/addons/a-train.html#prerequisites","text":"A-Train works exclusively through Shared Drives and Service Accounts . Shared Drives can only be created on GSuite / Google Workspace accounts. First, you must create a Service Account and create a JSON key . Afterwards, if you do not have one already, create a Shared Drive within Google Drive and then add the email address of the Service Account to the Shared Drive (with Reader permission).","title":"Prerequisites"},{"location":"apps/addons/a-train.html#setup-a-train","text":"Install A-Train from Docksever Addons Menu. Stop the container. sudo docker stop a-train Head over to the appdata folder. cd /opt/appdata/a-train/data/ Create a a-train.toml file. sudo nano a-train.toml Copy / Paste the following config into the created file from previous step and edit it to your needs. [autoscan] url = \"http://autoscan:3030\" username = \"your_username\" password = \"your_password\" [drive] account = \"./service-account.json\" drives = [\"shared_drive_id\", ....] Create a service-account.json. create a Service Account and create a JSON key . Copy it in /opt/appdata/a-train/data/ That\u00b4s it... Now you can start A-Train with sudo docker start a-train and check logs sudo docker logs -f a-train for errors.","title":"Setup A-Train"},{"location":"apps/addons/a-train.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/autoscan.html","text":"Autoscan \u00b6 Autoscan replaces the default Plex and Emby behaviour for picking up file changes on the file system. Autoscan integrates with Sonarr, Radarr, Lidarr and Google Drive to fetch changes in near real-time without relying on the file system. Wait, what happened to Plex Autoscan ? Well, Autoscan is a rewrite of the original Plex Autoscan written in the Go language. In addition, this rewrite introduces a more modular approach and should be easy to extend in the future. Comparison to Plex Autoscan \u00b6 A-Train , Autoscan's Google Drive integration, only supports Shared Drives and requires Service Account authentication. A-Train does not support RClone Crypt remotes. Autoscan does not rely on manual trash deletion when connected to Plex. Therefore, you should re-enable the Empty trash automatically after every scan setting in Plex. Autoscan also improves upon Plex Autoscan by adding the following features: Autoscan supports Plex music libraries. Autoscan adds additional support for Emby and Jellyfin. Autoscan can send scans to multiple Plex, Emby and Jellyfin servers. Installing autoscan \u00b6 Autoscan offers pre-compiled binaries for both Linux and MacOS for each official release. In addition, we also offer a Docker image ! Alternatively, you can build the Autoscan binary yourself. To build the autoscan CLI on your system, make sure: Your machine runs Linux, macOS or WSL2 You have Go installed (1.16 or later) Clone this repository and cd into it from the terminal Run go build -o autoscan ./cmd/autoscan from the terminal You should now have a binary with the name autoscan in the root directory of the project. To start autoscan, simply run ./autoscan . If you want autoscan to be globally available, move it to /bin or /usr/local/bin . If you need to debug certain Autoscan behaviour, either add the -v flag for debug mode or the -vv flag for trace mode to get even more details about internal behaviour. Overview \u00b6 Autoscan is split into three distinct modules: Triggers Processor Targets Rewriting paths \u00b6 Triggers, targets and the processor all live in different contexts. Some are used in Docker containers, others run on host OS, it can be a big mess! That's where rewrite rules come into play. They allow you to translate paths between a trigger's / target's perspective and the processor's perspective. Before you begin, make sure you understand how regular expressions work! \\ Make sure you know how capture groups work, as these are used for the to field. Triggers can receive paths from any source: A remote server, a Docker container and the local file system. The rewrite field can be defined for each individual trigger. This field can contain multiple rewriting rules. Therefore, each rule should have a - to indicate the next rule on the list. The from should be a regexp pattern describing the path from the trigger's perspective. The to should then convert this path into a path which is local to Autoscan. Targets work the other way around. They have to convert the path local to Autoscan to a path understood by the target, which can be a Docker container, remote server, etc. The from should be a regexp pattern describing the path from Autoscan's perspective. The to should then convert this path into a path which is local to the target. It is important that all three modules can have access to a file. When a trigger receives a scan, then the file should be available from both the processor and all targets. Simple example \u00b6 Sonarr running in a Docker container (same example works for Lidarr and Radarr) Autoscan running on the host OS (not in a container) Plex running in a Docker container The following config only defines rewrite paths, this should not be used directly! triggers : sonarr : - rewrite : # /tv contains folders with tv shows # This path is used within the Sonarr Docker container - from : /tv/ # /mnt/unionfs/Media/TV links to the same folder, though from the host OS # This folder is accessed by Autoscan to : /mnt/unionfs/Media/TV/ targets : plex : - rewrite : # Same folder as above, accessible by Autoscan. # Note how we strip the \"TV\" part, # as we want both Movies and TV. - from : /mnt/unionfs/Media/ # This path is used within the Plex Docker container to : /data/ Let's take a look at the journey of the path /tv/Westworld/Season 1/s01e01.mkv coming from Sonarr. Sonarr's path is translated to a path local to Autoscan. \\ /mnt/unionfs/Media/TV/Westworld/Season 1/s01e01.mkv The path is accessed by Autoscan to check whether it exists and adds it to the datastore. Autoscan's path is translated to a path local to Plex. \\ /data/TV/Season 1/s01e01.mkv This should be all that's needed to get you going. Good luck! Triggers \u00b6 Triggers are the 'input' of Autoscan. They translate incoming data into a common data format called the Scan. Autoscan currently supports the following triggers: A-Train : The official Google Drive trigger for Autoscan. \\ A-Train is available separately . Inotify: Listens for changes on the file system. \\ This should not be used on top of RClone mounts. \\ Bugs may still exist. Manual: When you want to scan a path manually. The -arrs: Lidarr, Sonarr and Radarr. \\ Webhook support for Lidarr, Sonarrr and Radarr. All triggers support: Trigger-wide priority: higher priorities are processed sooner. \\ Defaults to 0. RegExp-based rewriting rules: translate a path given by the trigger to a path on the local file system. \\ If the paths are identical between the trigger and the local file system, then the rewrite field should be ignored. A-Train \u00b6 Autoscan can monitor Google Drive through A-Train . A-Train is a stand-alone tool created by the Autoscan developers and is officially part of the Autoscan project. The A-Train trigger configuration is not required, as Autoscan automatically listens for A-Train requests. However, to configure global and drive-specific rewrite rules, you could add A-Train to your config: triggers : a-train : priority : 5 rewrite : # Global rewrites - from : ^/ to : /mnt/unionfs/ # Drives only need to be given when Drive-specific rewrites are used drives : - id : 0A1xxxxxxxxxUk9PVA # The ID of Shared Drive #1 rewrite : # Drive-specific rewrite (has priority over global rewrite) - from : ^/TV/ to : /mnt/unionfs/TV/ - id : 0A2xxxxxxxxxUk9PVA # The ID of Shared Drive #2 rewrite : # Drive-specific rewrite (has priority over global rewrite) - from : ^/Movies/ to : /mnt/unionfs/Movies/ Manual \u00b6 Note: You can visit /triggers/manual within a browser to manually submit requests Autoscan also supports a manual webhook for custom scripts or for software which is not supported by Autoscan directly. The manual endpoint is available at /triggers/manual . The manual endpoint accepts one or multiple directory paths as input and should be given one or multiple dir query parameters. Just like the other webhooks, the manual webhook is protected with basic authentication if the auth option is set in the config file of the user. URL template: POST /triggers/manual?dir=$path1&dir=$path2 The following curl command sends a request to Autoscan to scan the directories /test/one and /test/two : curl --request POST \\ --url 'http://localhost:3030/triggers/manual?dir=%2Ftest%2Fone&dir=%2Ftest%2Ftwo' \\ --header 'Authorization: Basic aGVsbG8gdGhlcmU6Z2VuZXJhbCBrZW5vYmk=' The -arrs \u00b6 If one wants to configure a HTTPTrigger with multiple distinct configurations, then these configurations MUST provide a field called Name which uniquely identifies the trigger. The name field is then used to create the route: /triggers/:name . The following -arrs are currently provided by Autoscan: Lidarr Radarr Sonarr Connecting the -arrs \u00b6 To add your webhook to Sonarr, Radarr or Lidarr, do: Open the settings page in Sonarr/Radarr/Lidarr Select the tab connect Click on the big plus sign Select webhook Use Autoscan as name (or whatever you prefer) Select On Import and On Upgrade Set the URL to Autoscan's URL and add /triggers/:name where name is the name set in the trigger's config. Optional: set username and password. The latest events \u00b6 Autoscan also supports the following events in the latest versions of Radarr and Sonarr: - Rename - On Movie Delete and On Series Delete - On Movie File Delete and On Episode File Delete We are not 100% sure whether these three events cover all the possible file system interactions. So for now, please do keep using Bernard or the Inotify trigger to fetch all scans. Configuration \u00b6 A snippet of the config.yml file showcasing what is possible. You can mix and match exactly the way you like: # Optionally, protect your webhooks with authentication authentication : username : hello there password : general kenobi # port for Autoscan webhooks to listen on port : 3030 triggers : # The manual trigger is always enabled, the config only adjusts its priority and the rewrite rules. manual : priority : 5 rewrite : - from : ^/Media/ to : /mnt/unionfs/Media/ a-train : priority : 5 rewrite : # Global rewrites - from : ^/ to : /mnt/unionfs/ # Drives only need to be given when Drive-specific rewrites are used drives : - id : 0A1xxxxxxxxxUk9PVA # The ID of Shared Drive #1 rewrite : # Drive-specific rewrite (has priority over global rewrite) - from : ^/TV/ to : /mnt/unionfs/TV/ inotify : - priority : 0 # filter with regular expressions include : - ^/mnt/unionfs/Media/ exclude : - '\\.(srt|pdf)$' # rewrite inotify path to unified filesystem rewrite : - from : ^/mnt/local/Media/ to : /mnt/unionfs/Media/ # local filesystem paths to monitor paths : - path : /mnt/local/Media lidarr : - name : lidarr # /triggers/lidarr priority : 1 radarr : - name : radarr # /triggers/radarr priority : 2 - name : radarr4k # /triggers/radarr4k priority : 5 sonarr : - name : sonarr-docker # /triggers/sonarr-docker priority : 2 # Rewrite the path from within the container # to your local filesystem. rewrite : - from : /tv/ to : /mnt/unionfs/Media/TV/ Processor \u00b6 Triggers pass the Scans they receive to the processor. The processor then saves the Scans to its datastore. The processor uses SQLite as its datastore, feel free to hack around! In a separate process, the processor selects Scans from the datastore. It will always group files belonging to the same folder together and it waits until all the files in that folder are older than the minimum-age , which defaults to 10 minutes. When all files are older than the minimum age, then the processor will call all the configured targets in parallel to request a folder scan. Anchor files \u00b6 To prevent the processor from calling targets when a remote mount is offline, you can define a list of so called anchor files . These anchor files do not have any special properties and often have no content. However, they can be used to check whether a file exists on the file system. If the file does not exist and you have not made any changes to the file, then it is certain that the remote mount must be offline or the software is having problems. When an anchor file is unavailable, the processor will halt its operations until the file is back online. We suggest you to use different anchor file names if you merge multiple remote mounts together with a tool such as UnionFS or MergerFS . Each remote mount MUST have its own anchor file and its own name for that anchor file. In addition, make sure to define the 'merged' path to the file and not the remote mount path. This helps check whether the union-software is working correctly as well. Minimum age \u00b6 Autoscan does not check whether scan requests received by triggers exist on the file system. Therefore, to make sure a file exists before it reaches the targets, you should set a minimum age. The minimum age delays the scan from being send to the targets after it has been added to the queue by a trigger. The default minimum age is set at 10 minutes to prevent common synchronisation issues. Customising the processor \u00b6 The processor allows you to set the minimum age of a Scan. In addition, you can also define a list of anchor files. A snippet of the config.yml file: # override the minimum age to 30 minutes: minimum-age : 30m # override the delay between processed scans: # defaults to 5 seconds scan-delay : 15s # override the interval scan stats are displayed: # defaults to 1 hour / 0s to disable scan-stats : 1m # set multiple anchor files anchors : - /mnt/unionfs/drive1.anchor - /mnt/unionfs/drive2.anchor The minimum-age , scan-delay and scan-stats fields should be given a string in the following format: 1s if the min-age should be set at 1 second. 5m if the min-age should be set at 5 minutes. 1m30s if the min-age should be set at 1 minute and 30 seconds. 1h if the min-age should be set at 1 hour. Please do not forget the s , m or h suffix, otherwise the time unit defaults to nanoseconds. Scan stats will print the following information at a configured interval: Scans processed Scans remaining Targets \u00b6 While collecting Scans is fun and all, they need to have a final destination. Targets are these final destinations and are given Scans from the processor, one batch at a time. Autoscan currently supports the following targets: Plex Emby Jellyfin Autoscan Plex \u00b6 Autoscan replaces Plex's default behaviour of updating the Plex library automatically. Therefore, it is advised to turn off Plex's Update my library automatically feature. You can setup one or multiple Plex targets in the config: targets : plex : - url : https://plex.domain.tld # URL of your Plex server token : XXXX # Plex API Token rewrite : - from : /mnt/unionfs/Media/ # local file system to : /data/ # path accessible by the Plex docker container (if applicable) There are a couple of things to take note of in the config: URL. The URL can link to the docker container directly, the localhost or a reverse proxy sitting in front of Plex. Token. We need a Plex API Token to make requests on your behalf. This article should help you out. Rewrite. If Plex is not running on the host OS, but in a Docker container (or Autoscan is running in a Docker container), then you need to rewrite paths accordingly. Check out our rewriting section for more info. Emby \u00b6 While Emby provides much better behaviour out of the box than Plex, it still might be useful to use Autoscan for even better performance. You can setup one or multiple Emby targets in the config: targets : emby : - url : https://emby.domain.tld # URL of your Emby server token : XXXX # Emby API Token rewrite : - from : /mnt/unionfs/Media/ # local file system to : /data/ # path accessible by the Emby docker container (if applicable) URL. The URL can link to the docker container directly, the localhost or a reverse proxy sitting in front of Emby. Token. We need an Emby API Token to make requests on your behalf. This article should help you out. \\ It's a bit out of date, but I'm sure you will manage! Rewrite. If Emby is not running on the host OS, but in a Docker container (or Autoscan is running in a Docker container), then you need to rewrite paths accordingly. Check out our rewriting section for more info. Jellyfin \u00b6 While Jellyfin provides much better behaviour out of the box than Plex, it still might be useful to use Autoscan for even better performance. You can setup one or multiple Jellyfin targets in the config: targets : jellyfin : - url : https://jellyfin.domain.tld # URL of your Jellyfin server token : XXXX # Jellyfin API Token rewrite : - from : /mnt/unionfs/Media/ # local file system to : /data/ # path accessible by the Jellyfin docker container (if applicable) URL. The URL can link to the docker container directly, the localhost or a reverse proxy sitting in front of Jellyfin. Token. We need a Jellyfin API Token to make requests on your behalf. This article should help you out. \\ It's a bit out of date, but I'm sure you will manage! Rewrite. If Jellyfin is not running on the host OS, but in a Docker container (or Autoscan is running in a Docker container), then you need to rewrite paths accordingly. Check out our rewriting section for more info. Autoscan \u00b6 You can also send scan requests to other instances of autoscan! targets : autoscan : - url : https://autoscan.domain.tld # URL of Autoscan username : XXXX # Username for remote autoscan instance password : XXXX # Password for remote autoscan instance rewrite : - from : /mnt/unionfs/Media/ # local file system to : /mnt/nfs/Media/ # path accessible by the remote autoscan instance (if applicable) Full config file \u00b6 With the examples given in the triggers , processor and targets sections, here is what your full config file could look like: # <- processor -> # override the minimum age to 30 minutes: minimum-age : 30m # set multiple anchor files anchors : - /mnt/unionfs/drive1.anchor - /mnt/unionfs/drive2.anchor # <- triggers -> # Protect your webhooks with authentication authentication : username : hello there password : general kenobi # port for Autoscan webhooks to listen on port : 3030 triggers : lidarr : - name : lidarr # /triggers/lidarr priority : 1 radarr : - name : radarr # /triggers/radarr priority : 2 - name : radarr4k # /triggers/radarr4k priority : 5 sonarr : - name : sonarr-docker # /triggers/sonarr-docker priority : 2 # Rewrite the path from within the container # to your local filesystem. rewrite : - from : /tv/ to : /mnt/unionfs/Media/TV/ # <- targets -> targets : plex : - url : https://plex.domain.tld # URL of your Plex server token : XXXX # Plex API Token rewrite : - from : /mnt/unionfs/Media/ # local file system to : /data/ # path accessible by the Plex docker container (if applicable) emby : - url : https://emby.domain.tld # URL of your Emby server token : XXXX # Emby API Token rewrite : - from : /mnt/unionfs/Media/ # local file system to : /data/ # path accessible by the Emby docker container (if applicable) Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Autoscan"},{"location":"apps/addons/autoscan.html#autoscan","text":"Autoscan replaces the default Plex and Emby behaviour for picking up file changes on the file system. Autoscan integrates with Sonarr, Radarr, Lidarr and Google Drive to fetch changes in near real-time without relying on the file system. Wait, what happened to Plex Autoscan ? Well, Autoscan is a rewrite of the original Plex Autoscan written in the Go language. In addition, this rewrite introduces a more modular approach and should be easy to extend in the future.","title":"Autoscan"},{"location":"apps/addons/autoscan.html#comparison-to-plex-autoscan","text":"A-Train , Autoscan's Google Drive integration, only supports Shared Drives and requires Service Account authentication. A-Train does not support RClone Crypt remotes. Autoscan does not rely on manual trash deletion when connected to Plex. Therefore, you should re-enable the Empty trash automatically after every scan setting in Plex. Autoscan also improves upon Plex Autoscan by adding the following features: Autoscan supports Plex music libraries. Autoscan adds additional support for Emby and Jellyfin. Autoscan can send scans to multiple Plex, Emby and Jellyfin servers.","title":"Comparison to Plex Autoscan"},{"location":"apps/addons/autoscan.html#installing-autoscan","text":"Autoscan offers pre-compiled binaries for both Linux and MacOS for each official release. In addition, we also offer a Docker image ! Alternatively, you can build the Autoscan binary yourself. To build the autoscan CLI on your system, make sure: Your machine runs Linux, macOS or WSL2 You have Go installed (1.16 or later) Clone this repository and cd into it from the terminal Run go build -o autoscan ./cmd/autoscan from the terminal You should now have a binary with the name autoscan in the root directory of the project. To start autoscan, simply run ./autoscan . If you want autoscan to be globally available, move it to /bin or /usr/local/bin . If you need to debug certain Autoscan behaviour, either add the -v flag for debug mode or the -vv flag for trace mode to get even more details about internal behaviour.","title":"Installing autoscan"},{"location":"apps/addons/autoscan.html#overview","text":"Autoscan is split into three distinct modules: Triggers Processor Targets","title":"Overview"},{"location":"apps/addons/autoscan.html#rewriting-paths","text":"Triggers, targets and the processor all live in different contexts. Some are used in Docker containers, others run on host OS, it can be a big mess! That's where rewrite rules come into play. They allow you to translate paths between a trigger's / target's perspective and the processor's perspective. Before you begin, make sure you understand how regular expressions work! \\ Make sure you know how capture groups work, as these are used for the to field. Triggers can receive paths from any source: A remote server, a Docker container and the local file system. The rewrite field can be defined for each individual trigger. This field can contain multiple rewriting rules. Therefore, each rule should have a - to indicate the next rule on the list. The from should be a regexp pattern describing the path from the trigger's perspective. The to should then convert this path into a path which is local to Autoscan. Targets work the other way around. They have to convert the path local to Autoscan to a path understood by the target, which can be a Docker container, remote server, etc. The from should be a regexp pattern describing the path from Autoscan's perspective. The to should then convert this path into a path which is local to the target. It is important that all three modules can have access to a file. When a trigger receives a scan, then the file should be available from both the processor and all targets.","title":"Rewriting paths"},{"location":"apps/addons/autoscan.html#simple-example","text":"Sonarr running in a Docker container (same example works for Lidarr and Radarr) Autoscan running on the host OS (not in a container) Plex running in a Docker container The following config only defines rewrite paths, this should not be used directly! triggers : sonarr : - rewrite : # /tv contains folders with tv shows # This path is used within the Sonarr Docker container - from : /tv/ # /mnt/unionfs/Media/TV links to the same folder, though from the host OS # This folder is accessed by Autoscan to : /mnt/unionfs/Media/TV/ targets : plex : - rewrite : # Same folder as above, accessible by Autoscan. # Note how we strip the \"TV\" part, # as we want both Movies and TV. - from : /mnt/unionfs/Media/ # This path is used within the Plex Docker container to : /data/ Let's take a look at the journey of the path /tv/Westworld/Season 1/s01e01.mkv coming from Sonarr. Sonarr's path is translated to a path local to Autoscan. \\ /mnt/unionfs/Media/TV/Westworld/Season 1/s01e01.mkv The path is accessed by Autoscan to check whether it exists and adds it to the datastore. Autoscan's path is translated to a path local to Plex. \\ /data/TV/Season 1/s01e01.mkv This should be all that's needed to get you going. Good luck!","title":"Simple example"},{"location":"apps/addons/autoscan.html#triggers","text":"Triggers are the 'input' of Autoscan. They translate incoming data into a common data format called the Scan. Autoscan currently supports the following triggers: A-Train : The official Google Drive trigger for Autoscan. \\ A-Train is available separately . Inotify: Listens for changes on the file system. \\ This should not be used on top of RClone mounts. \\ Bugs may still exist. Manual: When you want to scan a path manually. The -arrs: Lidarr, Sonarr and Radarr. \\ Webhook support for Lidarr, Sonarrr and Radarr. All triggers support: Trigger-wide priority: higher priorities are processed sooner. \\ Defaults to 0. RegExp-based rewriting rules: translate a path given by the trigger to a path on the local file system. \\ If the paths are identical between the trigger and the local file system, then the rewrite field should be ignored.","title":"Triggers"},{"location":"apps/addons/autoscan.html#a-train","text":"Autoscan can monitor Google Drive through A-Train . A-Train is a stand-alone tool created by the Autoscan developers and is officially part of the Autoscan project. The A-Train trigger configuration is not required, as Autoscan automatically listens for A-Train requests. However, to configure global and drive-specific rewrite rules, you could add A-Train to your config: triggers : a-train : priority : 5 rewrite : # Global rewrites - from : ^/ to : /mnt/unionfs/ # Drives only need to be given when Drive-specific rewrites are used drives : - id : 0A1xxxxxxxxxUk9PVA # The ID of Shared Drive #1 rewrite : # Drive-specific rewrite (has priority over global rewrite) - from : ^/TV/ to : /mnt/unionfs/TV/ - id : 0A2xxxxxxxxxUk9PVA # The ID of Shared Drive #2 rewrite : # Drive-specific rewrite (has priority over global rewrite) - from : ^/Movies/ to : /mnt/unionfs/Movies/","title":"A-Train"},{"location":"apps/addons/autoscan.html#manual","text":"Note: You can visit /triggers/manual within a browser to manually submit requests Autoscan also supports a manual webhook for custom scripts or for software which is not supported by Autoscan directly. The manual endpoint is available at /triggers/manual . The manual endpoint accepts one or multiple directory paths as input and should be given one or multiple dir query parameters. Just like the other webhooks, the manual webhook is protected with basic authentication if the auth option is set in the config file of the user. URL template: POST /triggers/manual?dir=$path1&dir=$path2 The following curl command sends a request to Autoscan to scan the directories /test/one and /test/two : curl --request POST \\ --url 'http://localhost:3030/triggers/manual?dir=%2Ftest%2Fone&dir=%2Ftest%2Ftwo' \\ --header 'Authorization: Basic aGVsbG8gdGhlcmU6Z2VuZXJhbCBrZW5vYmk='","title":"Manual"},{"location":"apps/addons/autoscan.html#the-arrs","text":"If one wants to configure a HTTPTrigger with multiple distinct configurations, then these configurations MUST provide a field called Name which uniquely identifies the trigger. The name field is then used to create the route: /triggers/:name . The following -arrs are currently provided by Autoscan: Lidarr Radarr Sonarr","title":"The -arrs"},{"location":"apps/addons/autoscan.html#connecting-the-arrs","text":"To add your webhook to Sonarr, Radarr or Lidarr, do: Open the settings page in Sonarr/Radarr/Lidarr Select the tab connect Click on the big plus sign Select webhook Use Autoscan as name (or whatever you prefer) Select On Import and On Upgrade Set the URL to Autoscan's URL and add /triggers/:name where name is the name set in the trigger's config. Optional: set username and password.","title":"Connecting the -arrs"},{"location":"apps/addons/autoscan.html#the-latest-events","text":"Autoscan also supports the following events in the latest versions of Radarr and Sonarr: - Rename - On Movie Delete and On Series Delete - On Movie File Delete and On Episode File Delete We are not 100% sure whether these three events cover all the possible file system interactions. So for now, please do keep using Bernard or the Inotify trigger to fetch all scans.","title":"The latest events"},{"location":"apps/addons/autoscan.html#configuration","text":"A snippet of the config.yml file showcasing what is possible. You can mix and match exactly the way you like: # Optionally, protect your webhooks with authentication authentication : username : hello there password : general kenobi # port for Autoscan webhooks to listen on port : 3030 triggers : # The manual trigger is always enabled, the config only adjusts its priority and the rewrite rules. manual : priority : 5 rewrite : - from : ^/Media/ to : /mnt/unionfs/Media/ a-train : priority : 5 rewrite : # Global rewrites - from : ^/ to : /mnt/unionfs/ # Drives only need to be given when Drive-specific rewrites are used drives : - id : 0A1xxxxxxxxxUk9PVA # The ID of Shared Drive #1 rewrite : # Drive-specific rewrite (has priority over global rewrite) - from : ^/TV/ to : /mnt/unionfs/TV/ inotify : - priority : 0 # filter with regular expressions include : - ^/mnt/unionfs/Media/ exclude : - '\\.(srt|pdf)$' # rewrite inotify path to unified filesystem rewrite : - from : ^/mnt/local/Media/ to : /mnt/unionfs/Media/ # local filesystem paths to monitor paths : - path : /mnt/local/Media lidarr : - name : lidarr # /triggers/lidarr priority : 1 radarr : - name : radarr # /triggers/radarr priority : 2 - name : radarr4k # /triggers/radarr4k priority : 5 sonarr : - name : sonarr-docker # /triggers/sonarr-docker priority : 2 # Rewrite the path from within the container # to your local filesystem. rewrite : - from : /tv/ to : /mnt/unionfs/Media/TV/","title":"Configuration"},{"location":"apps/addons/autoscan.html#processor","text":"Triggers pass the Scans they receive to the processor. The processor then saves the Scans to its datastore. The processor uses SQLite as its datastore, feel free to hack around! In a separate process, the processor selects Scans from the datastore. It will always group files belonging to the same folder together and it waits until all the files in that folder are older than the minimum-age , which defaults to 10 minutes. When all files are older than the minimum age, then the processor will call all the configured targets in parallel to request a folder scan.","title":"Processor"},{"location":"apps/addons/autoscan.html#anchor-files","text":"To prevent the processor from calling targets when a remote mount is offline, you can define a list of so called anchor files . These anchor files do not have any special properties and often have no content. However, they can be used to check whether a file exists on the file system. If the file does not exist and you have not made any changes to the file, then it is certain that the remote mount must be offline or the software is having problems. When an anchor file is unavailable, the processor will halt its operations until the file is back online. We suggest you to use different anchor file names if you merge multiple remote mounts together with a tool such as UnionFS or MergerFS . Each remote mount MUST have its own anchor file and its own name for that anchor file. In addition, make sure to define the 'merged' path to the file and not the remote mount path. This helps check whether the union-software is working correctly as well.","title":"Anchor files"},{"location":"apps/addons/autoscan.html#minimum-age","text":"Autoscan does not check whether scan requests received by triggers exist on the file system. Therefore, to make sure a file exists before it reaches the targets, you should set a minimum age. The minimum age delays the scan from being send to the targets after it has been added to the queue by a trigger. The default minimum age is set at 10 minutes to prevent common synchronisation issues.","title":"Minimum age"},{"location":"apps/addons/autoscan.html#customising-the-processor","text":"The processor allows you to set the minimum age of a Scan. In addition, you can also define a list of anchor files. A snippet of the config.yml file: # override the minimum age to 30 minutes: minimum-age : 30m # override the delay between processed scans: # defaults to 5 seconds scan-delay : 15s # override the interval scan stats are displayed: # defaults to 1 hour / 0s to disable scan-stats : 1m # set multiple anchor files anchors : - /mnt/unionfs/drive1.anchor - /mnt/unionfs/drive2.anchor The minimum-age , scan-delay and scan-stats fields should be given a string in the following format: 1s if the min-age should be set at 1 second. 5m if the min-age should be set at 5 minutes. 1m30s if the min-age should be set at 1 minute and 30 seconds. 1h if the min-age should be set at 1 hour. Please do not forget the s , m or h suffix, otherwise the time unit defaults to nanoseconds. Scan stats will print the following information at a configured interval: Scans processed Scans remaining","title":"Customising the processor"},{"location":"apps/addons/autoscan.html#targets","text":"While collecting Scans is fun and all, they need to have a final destination. Targets are these final destinations and are given Scans from the processor, one batch at a time. Autoscan currently supports the following targets: Plex Emby Jellyfin Autoscan","title":"Targets"},{"location":"apps/addons/autoscan.html#plex","text":"Autoscan replaces Plex's default behaviour of updating the Plex library automatically. Therefore, it is advised to turn off Plex's Update my library automatically feature. You can setup one or multiple Plex targets in the config: targets : plex : - url : https://plex.domain.tld # URL of your Plex server token : XXXX # Plex API Token rewrite : - from : /mnt/unionfs/Media/ # local file system to : /data/ # path accessible by the Plex docker container (if applicable) There are a couple of things to take note of in the config: URL. The URL can link to the docker container directly, the localhost or a reverse proxy sitting in front of Plex. Token. We need a Plex API Token to make requests on your behalf. This article should help you out. Rewrite. If Plex is not running on the host OS, but in a Docker container (or Autoscan is running in a Docker container), then you need to rewrite paths accordingly. Check out our rewriting section for more info.","title":"Plex"},{"location":"apps/addons/autoscan.html#emby","text":"While Emby provides much better behaviour out of the box than Plex, it still might be useful to use Autoscan for even better performance. You can setup one or multiple Emby targets in the config: targets : emby : - url : https://emby.domain.tld # URL of your Emby server token : XXXX # Emby API Token rewrite : - from : /mnt/unionfs/Media/ # local file system to : /data/ # path accessible by the Emby docker container (if applicable) URL. The URL can link to the docker container directly, the localhost or a reverse proxy sitting in front of Emby. Token. We need an Emby API Token to make requests on your behalf. This article should help you out. \\ It's a bit out of date, but I'm sure you will manage! Rewrite. If Emby is not running on the host OS, but in a Docker container (or Autoscan is running in a Docker container), then you need to rewrite paths accordingly. Check out our rewriting section for more info.","title":"Emby"},{"location":"apps/addons/autoscan.html#jellyfin","text":"While Jellyfin provides much better behaviour out of the box than Plex, it still might be useful to use Autoscan for even better performance. You can setup one or multiple Jellyfin targets in the config: targets : jellyfin : - url : https://jellyfin.domain.tld # URL of your Jellyfin server token : XXXX # Jellyfin API Token rewrite : - from : /mnt/unionfs/Media/ # local file system to : /data/ # path accessible by the Jellyfin docker container (if applicable) URL. The URL can link to the docker container directly, the localhost or a reverse proxy sitting in front of Jellyfin. Token. We need a Jellyfin API Token to make requests on your behalf. This article should help you out. \\ It's a bit out of date, but I'm sure you will manage! Rewrite. If Jellyfin is not running on the host OS, but in a Docker container (or Autoscan is running in a Docker container), then you need to rewrite paths accordingly. Check out our rewriting section for more info.","title":"Jellyfin"},{"location":"apps/addons/autoscan.html#autoscan_1","text":"You can also send scan requests to other instances of autoscan! targets : autoscan : - url : https://autoscan.domain.tld # URL of Autoscan username : XXXX # Username for remote autoscan instance password : XXXX # Password for remote autoscan instance rewrite : - from : /mnt/unionfs/Media/ # local file system to : /mnt/nfs/Media/ # path accessible by the remote autoscan instance (if applicable)","title":"Autoscan"},{"location":"apps/addons/autoscan.html#full-config-file","text":"With the examples given in the triggers , processor and targets sections, here is what your full config file could look like: # <- processor -> # override the minimum age to 30 minutes: minimum-age : 30m # set multiple anchor files anchors : - /mnt/unionfs/drive1.anchor - /mnt/unionfs/drive2.anchor # <- triggers -> # Protect your webhooks with authentication authentication : username : hello there password : general kenobi # port for Autoscan webhooks to listen on port : 3030 triggers : lidarr : - name : lidarr # /triggers/lidarr priority : 1 radarr : - name : radarr # /triggers/radarr priority : 2 - name : radarr4k # /triggers/radarr4k priority : 5 sonarr : - name : sonarr-docker # /triggers/sonarr-docker priority : 2 # Rewrite the path from within the container # to your local filesystem. rewrite : - from : /tv/ to : /mnt/unionfs/Media/TV/ # <- targets -> targets : plex : - url : https://plex.domain.tld # URL of your Plex server token : XXXX # Plex API Token rewrite : - from : /mnt/unionfs/Media/ # local file system to : /data/ # path accessible by the Plex docker container (if applicable) emby : - url : https://emby.domain.tld # URL of your Emby server token : XXXX # Emby API Token rewrite : - from : /mnt/unionfs/Media/ # local file system to : /data/ # path accessible by the Emby docker container (if applicable)","title":"Full config file"},{"location":"apps/addons/autoscan.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/cloud.html","text":"Cloud \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Cloud"},{"location":"apps/addons/cloud.html#cloud","text":"Wiki Coming Soon .....","title":"Cloud"},{"location":"apps/addons/cloud.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/cloudcmd.html","text":"Cloud Commander v15.9.7 \u00b6 Main Blog Live( Heroku ) \u00b6 Cloud Commander a file manager for the web with console and editor. More documentation you can find on https://cloudcmd.io/ . Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"CloudCMD"},{"location":"apps/addons/cloudcmd.html#cloud-commander-v1597","text":"","title":"Cloud Commander v15.9.7"},{"location":"apps/addons/cloudcmd.html#main-blog-liveheroku","text":"Cloud Commander a file manager for the web with console and editor. More documentation you can find on https://cloudcmd.io/ .","title":"Main Blog Live(Heroku)"},{"location":"apps/addons/cloudcmd.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/cloudflare-ddns.html","text":"Docker CloudFlare DDNS \u00b6 This small Alpine Linux based Docker image will allow you to use the free CloudFlare DNS Service as a Dynamic DNS Provider ( DDNS ). This is a multi-arch image and will run on amd64, aarch64, and armhf devices, including the Raspberry Pi. Image Variants \u00b6 Image Tag Architecture OS Size latest x64 Alpine Linux armhf arm32v6 Alpine Linux aarch64 arm64 Alpine Linux Usage \u00b6 Quick Setup: docker run \\ -e API_KEY = xxxxxxx \\ -e ZONE = example.com \\ -e SUBDOMAIN = subdomain \\ oznu/cloudflare-ddns Parameters \u00b6 --restart=always - ensure the container restarts automatically after host reboot. -e API_KEY - Your CloudFlare scoped API token. See the Creating a Cloudflare API token below. Required API_KEY_FILE - Path to load your CloudFlare scoped API token from (e.g. a Docker secret). If both API_KEY_FILE and API_KEY are specified, API_KEY_FILE takes precedence. -e ZONE - The DNS zone that DDNS updates should be applied to. Required ZONE_FILE - Path to load your CloudFlare DNS Zone from (e.g. a Docker secret). If both ZONE_FILE and ZONE are specified, ZONE_FILE takes precedence. -e SUBDOMAIN - A subdomain of the ZONE to write DNS changes to. If this is not supplied the root zone will be used. SUBDOMAIN_FILE - Path to load your CloudFlare DNS Subdomain from (e.g. a Docker secret). If both SUBDOMAIN_FILE and SUBDOMAIN are specified, SUBDOMAIN_FILE takes precedence. Optional Parameters \u00b6 -e PROXIED - Set to true to make traffic go through the CloudFlare CDN. Defaults to false . -e RRTYPE=A - Set to AAAA to use set IPv6 records instead of IPv4 records. Defaults to A for IPv4 records. -e DELETE_ON_STOP - Set to true to have the dns record deleted when the container is stopped. Defaults to false . -e INTERFACE=tun0 - Set to tun0 to have the IP pulled from a network interface named tun0 . If this is not supplied the public IP will be used instead. Requires --network host run argument. -e CUSTOM_LOOKUP_CMD=\"echo '1.1.1.1'\" - Set to any shell command to run them and have the IP pulled from the standard output. Leave unset to use default IP address detection methods. -e DNS_SERVER=10.0.0.2 - Set to the IP address of the DNS server you would like to use. Defaults to 1.1.1.1 otherwise. -e CRON=\"@daily\" - Set your own custom CRON value before the exec portion. Defaults to every 5 minutes - */5 * * * * . Depreciated Parameters \u00b6 -e EMAIL - Your CloudFlare email address when using an Account-level token. This variable MUST NOT be set when using a scoped API token. Creating a Cloudflare API token \u00b6 To create a CloudFlare API token for your DNS zone go to https://dash.cloudflare.com/profile/api-tokens and follow these steps: Click Create Token Provide the token a name, for example, cloudflare-ddns Grant the token the following permissions: Zone - Zone Settings - Read Zone - Zone - Read Zone - DNS - Edit Set the zone resources to: Include - All zones Complete the wizard and copy the generated token into the API_KEY variable for the container Multiple Domains \u00b6 If you need multiple records pointing to your public IP address you can create CNAME records in CloudFlare. IPv6 \u00b6 If you're wanting to set IPv6 records set the envrionment variable RRTYPE=AAAA . You will also need to run docker with IPv6 support, or run the container with host networking enabled. License \u00b6 Copyright (C) 2017-2020 oznu This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Cloudflare-DDNS"},{"location":"apps/addons/cloudflare-ddns.html#docker-cloudflare-ddns","text":"This small Alpine Linux based Docker image will allow you to use the free CloudFlare DNS Service as a Dynamic DNS Provider ( DDNS ). This is a multi-arch image and will run on amd64, aarch64, and armhf devices, including the Raspberry Pi.","title":"Docker CloudFlare DDNS"},{"location":"apps/addons/cloudflare-ddns.html#image-variants","text":"Image Tag Architecture OS Size latest x64 Alpine Linux armhf arm32v6 Alpine Linux aarch64 arm64 Alpine Linux","title":"Image Variants"},{"location":"apps/addons/cloudflare-ddns.html#usage","text":"Quick Setup: docker run \\ -e API_KEY = xxxxxxx \\ -e ZONE = example.com \\ -e SUBDOMAIN = subdomain \\ oznu/cloudflare-ddns","title":"Usage"},{"location":"apps/addons/cloudflare-ddns.html#parameters","text":"--restart=always - ensure the container restarts automatically after host reboot. -e API_KEY - Your CloudFlare scoped API token. See the Creating a Cloudflare API token below. Required API_KEY_FILE - Path to load your CloudFlare scoped API token from (e.g. a Docker secret). If both API_KEY_FILE and API_KEY are specified, API_KEY_FILE takes precedence. -e ZONE - The DNS zone that DDNS updates should be applied to. Required ZONE_FILE - Path to load your CloudFlare DNS Zone from (e.g. a Docker secret). If both ZONE_FILE and ZONE are specified, ZONE_FILE takes precedence. -e SUBDOMAIN - A subdomain of the ZONE to write DNS changes to. If this is not supplied the root zone will be used. SUBDOMAIN_FILE - Path to load your CloudFlare DNS Subdomain from (e.g. a Docker secret). If both SUBDOMAIN_FILE and SUBDOMAIN are specified, SUBDOMAIN_FILE takes precedence.","title":"Parameters"},{"location":"apps/addons/cloudflare-ddns.html#optional-parameters","text":"-e PROXIED - Set to true to make traffic go through the CloudFlare CDN. Defaults to false . -e RRTYPE=A - Set to AAAA to use set IPv6 records instead of IPv4 records. Defaults to A for IPv4 records. -e DELETE_ON_STOP - Set to true to have the dns record deleted when the container is stopped. Defaults to false . -e INTERFACE=tun0 - Set to tun0 to have the IP pulled from a network interface named tun0 . If this is not supplied the public IP will be used instead. Requires --network host run argument. -e CUSTOM_LOOKUP_CMD=\"echo '1.1.1.1'\" - Set to any shell command to run them and have the IP pulled from the standard output. Leave unset to use default IP address detection methods. -e DNS_SERVER=10.0.0.2 - Set to the IP address of the DNS server you would like to use. Defaults to 1.1.1.1 otherwise. -e CRON=\"@daily\" - Set your own custom CRON value before the exec portion. Defaults to every 5 minutes - */5 * * * * .","title":"Optional Parameters"},{"location":"apps/addons/cloudflare-ddns.html#depreciated-parameters","text":"-e EMAIL - Your CloudFlare email address when using an Account-level token. This variable MUST NOT be set when using a scoped API token.","title":"Depreciated Parameters"},{"location":"apps/addons/cloudflare-ddns.html#creating-a-cloudflare-api-token","text":"To create a CloudFlare API token for your DNS zone go to https://dash.cloudflare.com/profile/api-tokens and follow these steps: Click Create Token Provide the token a name, for example, cloudflare-ddns Grant the token the following permissions: Zone - Zone Settings - Read Zone - Zone - Read Zone - DNS - Edit Set the zone resources to: Include - All zones Complete the wizard and copy the generated token into the API_KEY variable for the container","title":"Creating a Cloudflare API token"},{"location":"apps/addons/cloudflare-ddns.html#multiple-domains","text":"If you need multiple records pointing to your public IP address you can create CNAME records in CloudFlare.","title":"Multiple Domains"},{"location":"apps/addons/cloudflare-ddns.html#ipv6","text":"If you're wanting to set IPv6 records set the envrionment variable RRTYPE=AAAA . You will also need to run docker with IPv6 support, or run the container with host networking enabled.","title":"IPv6"},{"location":"apps/addons/cloudflare-ddns.html#license","text":"Copyright (C) 2017-2020 oznu This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.","title":"License"},{"location":"apps/addons/cloudflare-ddns.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/dashmachine.html","text":"DashMachine \u00b6 The un-opinionated dashboard. \u00b6 Want a feature added now? Open a bounty Documentation \u00b6 Docker Hub Image \u00b6 VS Code Extension \u00b6 Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Dashmachine"},{"location":"apps/addons/dashmachine.html#dashmachine","text":"","title":"DashMachine"},{"location":"apps/addons/dashmachine.html#the-un-opinionated-dashboard","text":"Want a feature added now? Open a bounty","title":"The un-opinionated dashboard."},{"location":"apps/addons/dashmachine.html#documentation","text":"","title":"Documentation"},{"location":"apps/addons/dashmachine.html#docker-hub-image","text":"","title":"Docker Hub Image"},{"location":"apps/addons/dashmachine.html#vs-code-extension","text":"","title":"VS Code Extension"},{"location":"apps/addons/dashmachine.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/diun.html","text":"Diun \u00b6 What is Diun? \u00b6 **D**ocker **I**mage **U**pdate **N**otifier is a CLI application written in Go and delivered as a single executable (and a Docker image ) to receive notifications when a Docker image is updated on a Docker registry. With Go, this can be done with an independent binary distribution across all platforms and architectures that Go supports. This support includes Linux, macOS, and Windows, on architectures like amd64, i386, ARM, PowerPC, and others. Features \u00b6 Allow to watch a Docker repository and report new tags Include and exclude filters with regular expression for tags Internal cron implementation through go routines Worker pool to parallelize analyses Allow overriding image os and architecture Docker , Swarm , Kubernetes , Dockerfile and File providers available Get notified through Gotify, Mail, Slack, Telegram and more Healthchecks Support to monitor Diun watcher Enhanced logging Official Docker image ) to receive notifications when a Docker image is updated on Install Diun \u00b6 Open dockserver dockserver sh [ 2 ] DockServer - Applications sh addons sh diun Finish Diun will be installed full automatically. The installation folder is /opt/appdata/diun About \u00b6 Diun is a CLI application written in Go and delivered as a single executable (and a Docker image ) to receive notifications when a Docker image is updated on a Docker registry. Documentation \u00b6 Documentation can be found on https://crazy-max.github.io/diun/ How can I help? \u00b6 All kinds of contributions are welcome ! The most basic way to show your support is to star the project, or to raise issues You can also support this project by becoming a sponsor on GitHub or by making a Paypal donation to ensure this journey continues indefinitely! Thanks again for your support, it is much appreciated! License \u00b6 MIT. See LICENSE for more details Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Diun"},{"location":"apps/addons/diun.html#diun","text":"","title":"Diun"},{"location":"apps/addons/diun.html#what-is-diun","text":"**D**ocker **I**mage **U**pdate **N**otifier is a CLI application written in Go and delivered as a single executable (and a Docker image ) to receive notifications when a Docker image is updated on a Docker registry. With Go, this can be done with an independent binary distribution across all platforms and architectures that Go supports. This support includes Linux, macOS, and Windows, on architectures like amd64, i386, ARM, PowerPC, and others.","title":"What is Diun?"},{"location":"apps/addons/diun.html#features","text":"Allow to watch a Docker repository and report new tags Include and exclude filters with regular expression for tags Internal cron implementation through go routines Worker pool to parallelize analyses Allow overriding image os and architecture Docker , Swarm , Kubernetes , Dockerfile and File providers available Get notified through Gotify, Mail, Slack, Telegram and more Healthchecks Support to monitor Diun watcher Enhanced logging Official Docker image ) to receive notifications when a Docker image is updated on","title":"Features"},{"location":"apps/addons/diun.html#install-diun","text":"Open dockserver dockserver sh [ 2 ] DockServer - Applications sh addons sh diun Finish Diun will be installed full automatically. The installation folder is /opt/appdata/diun","title":"Install Diun"},{"location":"apps/addons/diun.html#about","text":"Diun is a CLI application written in Go and delivered as a single executable (and a Docker image ) to receive notifications when a Docker image is updated on a Docker registry.","title":"About"},{"location":"apps/addons/diun.html#documentation","text":"Documentation can be found on https://crazy-max.github.io/diun/","title":"Documentation"},{"location":"apps/addons/diun.html#how-can-i-help","text":"All kinds of contributions are welcome ! The most basic way to show your support is to star the project, or to raise issues You can also support this project by becoming a sponsor on GitHub or by making a Paypal donation to ensure this journey continues indefinitely! Thanks again for your support, it is much appreciated!","title":"How can I help?"},{"location":"apps/addons/diun.html#license","text":"MIT. See LICENSE for more details","title":"License"},{"location":"apps/addons/diun.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/dozzle.html","text":"Dozzle - dozzle.dev \u00b6 Dozzle is a small lightweight application with a web based interface to monitor Docker logs. It doesn\u2019t store any log files. It is for live monitoring of your container logs only. Features \u00b6 Intelligent fuzzy search for container names \ud83e\udd16 Search logs using regex \ud83d\udd26 Small memory footprint \ud83c\udfce Split screen for viewing multiple logs Download logs easy Live stats with memory and CPU usage Authentication with username and password \ud83d\udea8 Dozzle should work for most. It has been tested with hundreds of containers. However, it doesn't support offline searching. Products like Loggly , Papertrail or Kibana are more suited for full search capabilities. Dozzle doesn't cost any money and aims to focus on real-time debugging. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Dozzle"},{"location":"apps/addons/dozzle.html#dozzle-dozzledev","text":"Dozzle is a small lightweight application with a web based interface to monitor Docker logs. It doesn\u2019t store any log files. It is for live monitoring of your container logs only.","title":"Dozzle - dozzle.dev"},{"location":"apps/addons/dozzle.html#features","text":"Intelligent fuzzy search for container names \ud83e\udd16 Search logs using regex \ud83d\udd26 Small memory footprint \ud83c\udfce Split screen for viewing multiple logs Download logs easy Live stats with memory and CPU usage Authentication with username and password \ud83d\udea8 Dozzle should work for most. It has been tested with hundreds of containers. However, it doesn't support offline searching. Products like Loggly , Papertrail or Kibana are more suited for full search capabilities. Dozzle doesn't cost any money and aims to focus on real-time debugging.","title":"Features"},{"location":"apps/addons/dozzle.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/flaresolverr.html","text":"FlareSolverr \u00b6 FlareSolverr is a proxy server to bypass Cloudflare protection. How it works \u00b6 FlareSolverr starts a proxy server and it waits for user requests in an idle state using few resources. When some request arrives, it uses puppeteer with the stealth plugin to create a headless browser (Chrome). It opens the URL with user parameters and waits until the Cloudflare challenge is solved (or timeout). The HTML code and the cookies are sent back to the user, and those cookies can be used to bypass Cloudflare using other HTTP clients. NOTE : Web browsers consume a lot of memory. If you are running FlareSolverr on a machine with few RAM, do not make many requests at once. With each request a new browser is launched. It is also possible to use a permanent session. However, if you use sessions, you should make sure to close them as soon as you are done using them. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Flaresolverr"},{"location":"apps/addons/flaresolverr.html#flaresolverr","text":"FlareSolverr is a proxy server to bypass Cloudflare protection.","title":"FlareSolverr"},{"location":"apps/addons/flaresolverr.html#how-it-works","text":"FlareSolverr starts a proxy server and it waits for user requests in an idle state using few resources. When some request arrives, it uses puppeteer with the stealth plugin to create a headless browser (Chrome). It opens the URL with user parameters and waits until the Cloudflare challenge is solved (or timeout). The HTML code and the cookies are sent back to the user, and those cookies can be used to bypass Cloudflare using other HTTP clients. NOTE : Web browsers consume a lot of memory. If you are running FlareSolverr on a machine with few RAM, do not make many requests at once. With each request a new browser is launched. It is also possible to use a permanent session. However, if you use sessions, you should make sure to close them as soon as you are done using them.","title":"How it works"},{"location":"apps/addons/flaresolverr.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/heimdall.html","text":"Heimdall \u00b6 Visit the website - https://heimdall.site About \u00b6 As the name suggests Heimdall Application Dashboard is a dashboard for all your web applications. It doesn't need to be limited to applications though, you can add links to anything you like. Heimdall is an elegant solution to organise all your web applications. It\u2019s dedicated to this purpose so you won\u2019t lose your links in a sea of bookmarks. Why not use it as your browser start page? It even has the ability to include a search bar using either Google, Bing or DuckDuckGo. Video \u00b6 If you want to see a quick video of it in use, go to https://youtu.be/GXnnMAxPzMc Supported applications \u00b6 You can use the app to link to any site or application, but Foundation apps will auto fill in the icon for the app and supply a default color for the tile. In addition Enhanced apps allow you provide details to an apps API, allowing you to view live stats directly on the dashboad. For example, the NZBGet and Sabnzbd Enhanced apps will display the queue size and download speed while something is downloading. Supported applications are recognized by the title of the application as entered in the title field when adding an application. For example, to add a link to pfSense, begin by typing \"p\" in the title field and then select \"pfSense\" from the list of supported applications. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Heimdall"},{"location":"apps/addons/heimdall.html#heimdall","text":"Visit the website - https://heimdall.site","title":"Heimdall"},{"location":"apps/addons/heimdall.html#about","text":"As the name suggests Heimdall Application Dashboard is a dashboard for all your web applications. It doesn't need to be limited to applications though, you can add links to anything you like. Heimdall is an elegant solution to organise all your web applications. It\u2019s dedicated to this purpose so you won\u2019t lose your links in a sea of bookmarks. Why not use it as your browser start page? It even has the ability to include a search bar using either Google, Bing or DuckDuckGo.","title":"About"},{"location":"apps/addons/heimdall.html#video","text":"If you want to see a quick video of it in use, go to https://youtu.be/GXnnMAxPzMc","title":"Video"},{"location":"apps/addons/heimdall.html#supported-applications","text":"You can use the app to link to any site or application, but Foundation apps will auto fill in the icon for the app and supply a default color for the tile. In addition Enhanced apps allow you provide details to an apps API, allowing you to view live stats directly on the dashboad. For example, the NZBGet and Sabnzbd Enhanced apps will display the queue size and download speed while something is downloading. Supported applications are recognized by the title of the application as entered in the title field when adding an application. For example, to add a link to pfSense, begin by typing \"p\" in the title field and then select \"pfSense\" from the list of supported applications.","title":"Supported applications"},{"location":"apps/addons/heimdall.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/kitana.html","text":"Kitana \u00b6 A responsive Plex plugin web frontend Introduction \u00b6 What is Kitana? \u00b6 Kitana exposes your Plex plugin interfaces \"to the outside world\". It does that by authenticating against Plex.TV, then connecting to the Plex Media Server you tell it to, and essentially proxying the plugin UI. It has full PMS connection awareness and allows you to connect locally, remotely, or even via relay. It does that in a responsive way, so your Plugins are easily managable from your mobile phones for example, as well. Running one instance of Kitana can serve infinite amounts of servers and plugins - you can even expose your Kitana instance to your friends, so they can manage their plugins as well, so they don't have to run their own Kitana instance. Kitana was built for Sub-Zero originally, but handles other plugins just as well. Isn't that a security concern? \u00b6 Not at all. Without a valid Plex.TV authentication, Kitana can do nothing. All authentication data is stored serverside inside the current user's session storage (which is long running), so unwanted third party access to your server is virtually impossible. The Plex plugin UIs still suck, though! \u00b6 Yes, they do. Kitana does little to improve that, besides adding responsiveness to the whole situation. Also, it isn't designed to. Kitana is an intermediate solution to the recent problem posed by Plex Inc. and their plans to phase out all UI-based plugins from the Plex Media Server environment. Features \u00b6 small footprint by using the CherryPy framework heavy caching for faster plugin handling full PMS connection awareness and automatic fallback in case the configured connection is lost fully responsive (CSS3) made to run behind reverse proxies (it doesn't provide its own HTTPS interface) fully cross-platform Screenshots \u00b6 Imgur Gallery Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Kitana"},{"location":"apps/addons/kitana.html#kitana","text":"A responsive Plex plugin web frontend","title":"Kitana"},{"location":"apps/addons/kitana.html#introduction","text":"","title":"Introduction"},{"location":"apps/addons/kitana.html#what-is-kitana","text":"Kitana exposes your Plex plugin interfaces \"to the outside world\". It does that by authenticating against Plex.TV, then connecting to the Plex Media Server you tell it to, and essentially proxying the plugin UI. It has full PMS connection awareness and allows you to connect locally, remotely, or even via relay. It does that in a responsive way, so your Plugins are easily managable from your mobile phones for example, as well. Running one instance of Kitana can serve infinite amounts of servers and plugins - you can even expose your Kitana instance to your friends, so they can manage their plugins as well, so they don't have to run their own Kitana instance. Kitana was built for Sub-Zero originally, but handles other plugins just as well.","title":"What is Kitana?"},{"location":"apps/addons/kitana.html#isnt-that-a-security-concern","text":"Not at all. Without a valid Plex.TV authentication, Kitana can do nothing. All authentication data is stored serverside inside the current user's session storage (which is long running), so unwanted third party access to your server is virtually impossible.","title":"Isn't that a security concern?"},{"location":"apps/addons/kitana.html#the-plex-plugin-uis-still-suck-though","text":"Yes, they do. Kitana does little to improve that, besides adding responsiveness to the whole situation. Also, it isn't designed to. Kitana is an intermediate solution to the recent problem posed by Plex Inc. and their plans to phase out all UI-based plugins from the Plex Media Server environment.","title":"The Plex plugin UIs still suck, though!"},{"location":"apps/addons/kitana.html#features","text":"small footprint by using the CherryPy framework heavy caching for faster plugin handling full PMS connection awareness and automatic fallback in case the configured connection is lost fully responsive (CSS3) made to run behind reverse proxies (it doesn't provide its own HTTPS interface) fully cross-platform","title":"Features"},{"location":"apps/addons/kitana.html#screenshots","text":"Imgur Gallery","title":"Screenshots"},{"location":"apps/addons/kitana.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/librespeed.html","text":"Librespeed \u00b6 Librespeed is a very lightweight Speedtest implemented in Javascript, using XMLHttpRequest and Web Workers. No Flash, No Java, No Websocket, No Bullshit. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Librespeed"},{"location":"apps/addons/librespeed.html#librespeed","text":"Librespeed is a very lightweight Speedtest implemented in Javascript, using XMLHttpRequest and Web Workers. No Flash, No Java, No Websocket, No Bullshit.","title":"Librespeed"},{"location":"apps/addons/librespeed.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/netdata.html","text":"Netdata \u00b6 Netdata is high-fidelity infrastructure monitoring and troubleshooting. Open-source, free, preconfigured, opinionated, and always real-time. Netdata's distributed, real-time monitoring Agent collects thousands of metrics from systems, hardware, containers, and applications with zero configuration. It runs permanently on all your physical/virtual servers, containers, cloud deployments, and edge/IoT devices, and is perfectly safe to install on your systems mid-incident without any preparation. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"NetData"},{"location":"apps/addons/netdata.html#netdata","text":"Netdata is high-fidelity infrastructure monitoring and troubleshooting. Open-source, free, preconfigured, opinionated, and always real-time. Netdata's distributed, real-time monitoring Agent collects thousands of metrics from systems, hardware, containers, and applications with zero configuration. It runs permanently on all your physical/virtual servers, containers, cloud deployments, and edge/IoT devices, and is perfectly safe to install on your systems mid-incident without any preparation.","title":"Netdata"},{"location":"apps/addons/netdata.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/notifiarr.html","text":"Notifiarr \u00b6 This is the unified client for Notifiarr.com . The client enables content requests from Media Bot in your Discord Server. It also provides reports for Plex usage and system health. Docker Config File \u00b6 Copy the config file from this repo. Rename it to notifiarr.conf Put it in /opt/appdata/notifiarr and set it up to your needs. Restart the container docker restart notifiarr and go to Notifiarr.com to add integrations. For more information please viste Notifiarr Repo Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"NotiFiarr"},{"location":"apps/addons/notifiarr.html#notifiarr","text":"This is the unified client for Notifiarr.com . The client enables content requests from Media Bot in your Discord Server. It also provides reports for Plex usage and system health.","title":"Notifiarr"},{"location":"apps/addons/notifiarr.html#docker-config-file","text":"Copy the config file from this repo. Rename it to notifiarr.conf Put it in /opt/appdata/notifiarr and set it up to your needs. Restart the container docker restart notifiarr and go to Notifiarr.com to add integrations. For more information please viste Notifiarr Repo","title":"Docker Config File"},{"location":"apps/addons/notifiarr.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/remmina.html","text":"Remmina remote desktop client \u00b6 Use other desktops remotely, from a tiny screen or large monitors. RDP, VNC, SPICE, NX, XDMCP, SSH and EXEC network protocols are supported. Written in GTK, with a port to Qt underway. Released as \"remmina\" (the main program) and \"remmina-plugins\". Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Remmina"},{"location":"apps/addons/remmina.html#remmina-remote-desktop-client","text":"Use other desktops remotely, from a tiny screen or large monitors. RDP, VNC, SPICE, NX, XDMCP, SSH and EXEC network protocols are supported. Written in GTK, with a port to Qt underway. Released as \"remmina\" (the main program) and \"remmina-plugins\".","title":"Remmina remote desktop client"},{"location":"apps/addons/remmina.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/speedtest.html","text":"Speedtest Tracker \u00b6 This program runs a speedtest check every hour and graphs the results. The back-end is written in Laravel and the front-end uses React . It uses the Ookla's speedtest cli package to get the data and uses Chart.js to plot the results. A demo can be found here Disclaimer: You will need to accept Ookla's EULA and privacy agreements in order to use this container. Features \u00b6 Automatically run a speedtest every hour Graph of previous speedtests going back x days Backup/restore data in JSON/CSV format Slack/Discord/Telegram notifications healthchecks.io integration Organizr integration Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Speedtest"},{"location":"apps/addons/speedtest.html#speedtest-tracker","text":"This program runs a speedtest check every hour and graphs the results. The back-end is written in Laravel and the front-end uses React . It uses the Ookla's speedtest cli package to get the data and uses Chart.js to plot the results. A demo can be found here Disclaimer: You will need to accept Ookla's EULA and privacy agreements in order to use this container.","title":"Speedtest Tracker"},{"location":"apps/addons/speedtest.html#features","text":"Automatically run a speedtest every hour Graph of previous speedtests going back x days Backup/restore data in JSON/CSV format Slack/Discord/Telegram notifications healthchecks.io integration Organizr integration","title":"Features"},{"location":"apps/addons/speedtest.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/tauticord.html","text":"Tauticord \u00b6 A Discord bot that displays live data from Tautulli Features \u00b6 Tauticord uses the Tautulli API to pull information from Tautulli and display them in a Discord channel, including: Overview: \u00b6 Number of current streams Number of transcoding streams Total bandwidth Total LAN bandwidth Total remote bandwidth Library item counts For each stream: \u00b6 Stream state (playing, paused, stopped, loading) Media type (tv show/movie/song/photo) User Media title Product and player Quality profile Stream bandwidth If stream is transcoding Progress of stream ETA of stream completion Administrator (the bot owner) can react to Tauticord's messages to terminate a specific stream (if they have Plex Pass). Users can also indicate what libraries they would like monitored. Tauticord will create/update a voice channel for each library name with item counts every hour. Installation and setup \u00b6 Requirements \u00b6 A Plex Media Server Tautulli (formerly known as PlexPy) A Discord server Docker A Discord bot token Permissions required: Manage Channels View Channels Send Messages Manage Messages Read Message History Add Reactions Manage Emojis Shortcut : Use the following link to invite your bot to your server with the above permissions: https://discord.com/oauth2/authorize?client_id=YOUR_APPLICATION_ID&scope=bot&permissions=1074080848 Requirements \u00b6 A Plex Media Server Tautulli A Discord server Installation and Setup \u00b6 Setup a Discord Bot \u00b6 HOW TO MAKE A DISCORD BOT: https://www.digitaltrends.com/gaming/how-to-make-a-discord-bot/ Permissions required: Manage Channels View Channels Send Messages Manage Messages Read Message History Add Reactions Setup Tauticord \u00b6 Install Tauticord from Docksever Addons Menu. Stop Tauticord. sudo docker stop tauticord Download config.yaml to /opt/appdata/tauticord/ wget https://raw.githubusercontent.com/cyb3rgh05t/tauticord/master/config.yaml.example -O /opt/appdata/tauticord/config.yaml Edit the config file to your needs. nano /opt/appdata/tauticord/config.yaml Start the container. sudo docker start tauticord Et voil\u00e0, your Bot should now be online in your Disord Server. Wiki Maintainer \u00b6 @cyb3rgh05t Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Tauticord"},{"location":"apps/addons/tauticord.html#tauticord","text":"A Discord bot that displays live data from Tautulli","title":"Tauticord"},{"location":"apps/addons/tauticord.html#features","text":"Tauticord uses the Tautulli API to pull information from Tautulli and display them in a Discord channel, including:","title":"Features"},{"location":"apps/addons/tauticord.html#overview","text":"Number of current streams Number of transcoding streams Total bandwidth Total LAN bandwidth Total remote bandwidth Library item counts","title":"Overview:"},{"location":"apps/addons/tauticord.html#for-each-stream","text":"Stream state (playing, paused, stopped, loading) Media type (tv show/movie/song/photo) User Media title Product and player Quality profile Stream bandwidth If stream is transcoding Progress of stream ETA of stream completion Administrator (the bot owner) can react to Tauticord's messages to terminate a specific stream (if they have Plex Pass). Users can also indicate what libraries they would like monitored. Tauticord will create/update a voice channel for each library name with item counts every hour.","title":"For each stream:"},{"location":"apps/addons/tauticord.html#installation-and-setup","text":"","title":"Installation and setup"},{"location":"apps/addons/tauticord.html#requirements","text":"A Plex Media Server Tautulli (formerly known as PlexPy) A Discord server Docker A Discord bot token Permissions required: Manage Channels View Channels Send Messages Manage Messages Read Message History Add Reactions Manage Emojis Shortcut : Use the following link to invite your bot to your server with the above permissions: https://discord.com/oauth2/authorize?client_id=YOUR_APPLICATION_ID&scope=bot&permissions=1074080848","title":"Requirements"},{"location":"apps/addons/tauticord.html#requirements_1","text":"A Plex Media Server Tautulli A Discord server","title":"Requirements"},{"location":"apps/addons/tauticord.html#installation-and-setup_1","text":"","title":"Installation and Setup"},{"location":"apps/addons/tauticord.html#setup-a-discord-bot","text":"HOW TO MAKE A DISCORD BOT: https://www.digitaltrends.com/gaming/how-to-make-a-discord-bot/ Permissions required: Manage Channels View Channels Send Messages Manage Messages Read Message History Add Reactions","title":"Setup a Discord Bot"},{"location":"apps/addons/tauticord.html#setup-tauticord","text":"Install Tauticord from Docksever Addons Menu. Stop Tauticord. sudo docker stop tauticord Download config.yaml to /opt/appdata/tauticord/ wget https://raw.githubusercontent.com/cyb3rgh05t/tauticord/master/config.yaml.example -O /opt/appdata/tauticord/config.yaml Edit the config file to your needs. nano /opt/appdata/tauticord/config.yaml Start the container. sudo docker start tauticord Et voil\u00e0, your Bot should now be online in your Disord Server.","title":"Setup Tauticord"},{"location":"apps/addons/tauticord.html#wiki-maintainer","text":"@cyb3rgh05t","title":"Wiki Maintainer"},{"location":"apps/addons/tauticord.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/addons/vnstat.html","text":"vnStat \u00b6 vnStat is a console-based network traffic monitor that uses the network interface statistics provided by the kernel as information source. This means that vnStat won't actually be sniffing any traffic and also ensures light use of system resources regardless of network traffic rate. By default, traffic statistics are stored on a five minute level for the last 48 hours, on a hourly level for the last 4 days, on a daily level for the last 2 full months and on a yearly level forever. The data retention durations are fully user configurable. Total seen traffic and a top days listing is also provided. Optional png image output is available in systems with the gd library installed. See the official webpage for additional details and output examples. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"vnstat"},{"location":"apps/addons/vnstat.html#vnstat","text":"vnStat is a console-based network traffic monitor that uses the network interface statistics provided by the kernel as information source. This means that vnStat won't actually be sniffing any traffic and also ensures light use of system resources regardless of network traffic rate. By default, traffic statistics are stored on a five minute level for the last 48 hours, on a hourly level for the last 4 days, on a daily level for the last 2 full months and on a yearly level forever. The data retention durations are fully user configurable. Total seen traffic and a top days listing is also provided. Optional png image output is available in systems with the gd library installed. See the official webpage for additional details and output examples.","title":"vnStat"},{"location":"apps/addons/vnstat.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/backup/backup.html","text":"RSync-Backup \u00b6 customized Backup script made by Dockerserver Team Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Backup"},{"location":"apps/backup/backup.html#rsync-backup","text":"customized Backup script made by Dockerserver Team","title":"RSync-Backup"},{"location":"apps/backup/backup.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/backup/duplicati.html","text":"Duplicati \u00b6 Duplicati works with standard protocols like FTP, SSH, WebDAV as well as popular services like Microsoft OneDrive, Amazon Cloud Drive & S3, Google Drive, box.com, Mega, hubiC and many others. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Duplicati"},{"location":"apps/backup/duplicati.html#duplicati","text":"Duplicati works with standard protocols like FTP, SSH, WebDAV as well as popular services like Microsoft OneDrive, Amazon Cloud Drive & S3, Google Drive, box.com, Mega, hubiC and many others.","title":"Duplicati"},{"location":"apps/backup/duplicati.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/backup/restic.html","text":"Restic \u00b6 Restic is a backup program that is fast, efficient and secure. It supports the three major operating systems (Linux, macOS, Windows) and a few smaller ones (FreeBSD, OpenBSD). Features: \u00b6 Full Rclone Support. Runs default every day at 2am. Multiple jobs possible. Automatic configuration and repository creation. Configuration \u00b6 All settings can be found here: /opt/appdata/restic/restic/restic.env USER VALUES \u00b6 Setting Default Description PUID 1000 PGUID to be used by Restic. PGID 1000 PGID to be used by Restic. TIMEZONE UTC Timezone to be used by Restic. RESTIC - SETTINGS \u00b6 Setting Default Description RESTIC_JOBS 1 Configure multiple jobs, creates for every job an extra ENV file. RESTIC_HOST Restic Restic Backup hostname. RESTIC_REPOSITORY null Rclone Backup path eg example: rclone:tdrive:backup/myservername . RESTIC_PASSWORD null Secure password for your backups. RESTIC_TAG appdata Backup Tag, good for multiple Backups. RESTIC_EXCLUDES /app/restic/excludes.txt Default Excludes File inside the Docker. RESTIC_PACK_SIZE 32 Restic Pack Size Restic documentation RESTIC_CACHE_DIR /config/.cache Backup Cache Folder. RESTIC_FOLDER /opt/appdata Backup Folder. RCLONE - SETTINGS \u00b6 Setting Default Description GOOGLE_IP 142.250.74.78 Set hardcoded IP for www.googleapis.com this does prevent Error 429. You can specify multiple IPs with comma separated. PROXY null Set HTTP or SOCKS5 Proxy for RClone. Rclone documentation for details. NOTIFICATION - SETTINGS \u00b6 Apprise has been integrated into Uploader and is defaulted to format all notifications in Markdown . Please refer to the Apprise documentation for more information. Setting Default Description NOTIFICATION_URL null The notification URL to be passed to Apprise. Discord examples: https://discordapp.com/api/webhooks/{WebhookID}/{WebhookToken} discord://{WebhookID}/{WebhookToken}/ discord://{user}@{WebhookID}/{WebhookToken}/ NOTIFICATION_LEVEL ALL What notifications should be sent to NOTIFICATION_URL . Options: ALL - Send notification for all backups ERROR - Send notification for only errors NONE - Do not send any notifications NOTIFICATION_SERVERNAME null What to display on the notification, after \"Restic - \". null will default to \"Restic - Docker\". Anything else will only replace \"Docker\". Examples: NOTIFICATION_SERVERNAME=null results in \"Restic - Docker\" NOTIFICATION_SERVERNAME=My Awesome Server will result in \"Restic Backup - My Awesome Server\" Setup Restic Backup \u00b6 Install Container \u00b6 Install from dockserver>apps>backup menu Create Service Account \u00b6 Put service account into /opt/appdata/restic/rclone/keys IMPORTANT : Make sure service account has manager permissions on google. Create Rclone.conf \u00b6 nano /opt/appdata/restic/rclone/rclone.conf Should look something like this: [tdrive] type = drive scope = drive service_account_file = /config/rclone/keys/NAMEOFSA team_drive =xxxxxxxxx ENV Setup \u00b6 nano /opt/appdata/restic/restic/restic.env change RESTIC_REPOSITORY=\"null\" to RESTIC_REPOSITORY=\"rclone:tdrive:PATH/TO/BACKUP/FOLDER\" change RESTIC_PASSWORD=null to RESTIC_PASSWORD=YOURPASSWORD Restart Container \u00b6 After changes, sudo docker restart restic Restic Commands \u00b6 Manual Backup docker exec -it restic bash source /app/restic/restic.sh resticbackup Full Restore docker exec -it restic bash source /app/restic/restic.sh resticrestore-full App Restore docker exec -it restic bash source /app/restic/restic.sh resticrestore <APPNAME> View Snapshots docker exec -it restic bash source /app/restic/restic.sh resticsnapshots Restore Specific App Snapshot (Replace SNAPSHOT_ID and NAMEOFAPP) docker exec -it restic bash source /app/restic/restic.sh source /config/restic/restic.env $(which restic) restore <SNAPSHOT_ID> --repo \"${RESTIC_REPOSITORY}\" --password-command \"$(which echo) ${RESTIC_PASSWORD}\" --target \"/\" --tag \"${RESTIC_TAG}\" --option rclone.args=\"serve restic --stdio --checkers=16 --drive-chunk-size=32M --drive-use-trash=false --fast-list --config=/config/rclone/rclone.conf\" --include \"${RESTIC_FOLDER}/<NAMEOFAPP>\" Configuration \u00b6 All settings can be found here: /opt/appdata/restic/restic/restic.env USER VALUES \u00b6 Setting Default Description PUID 1000 PGUID to be used by Restic. PGID 1000 PGID to be used by Restic. TIMEZONE UTC Timezone to be used by Restic. RESTIC - SETTINGS \u00b6 Setting Default Description RESTIC_JOBS 1 .. RESTIC_HOST Restic .. RESTIC_REPOSITORY null Rclone Backup path eg example: rclone:tdrive:backup/myservername . RESTIC_PASSWORD null Secure password for your backups. RESTIC_TAG appdata .. RESTIC_PACK_SIZE 32 .. RESTIC_CACHE_DIR /config/.cache .. RESTIC_FOLDER /opt/appdata .. RCLONE - SETTINGS \u00b6 Setting Default Description GOOGLE_IP 142.250.74.78 Set hardcoded IP for www.googleapis.com this does prevent Error 429. You can specify multiple IPs with comma separated. PROXY null Set HTTP or SOCKS5 Proxy for RClone. Rclone documentation for details. NOTIFICATION - SETTINGS \u00b6 Apprise has been integrated into Uploader and is defaulted to format all notifications in Markdown . Please refer to the Apprise documentation for more information. Setting Default Description NOTIFICATION_URL null The notification URL to be passed to Apprise. Discord examples: https://discordapp.com/api/webhooks/{WebhookID}/{WebhookToken} discord://{WebhookID}/{WebhookToken}/ discord://{user}@{WebhookID}/{WebhookToken}/ NOTIFICATION_LEVEL ALL What notifications should be sent to NOTIFICATION_URL . Options: ALL - Send notification for all backups ERROR - Send notification for only errors NONE - Do not send any notifications NOTIFICATION_SERVERNAME null What to display on the notification, after \"Restic - \". null will default to \"Restic - Docker\". Anything else will only replace \"Docker\". Examples: NOTIFICATION_SERVERNAME=null results in \"Restic - Docker\" NOTIFICATION_SERVERNAME=My Awesome Server will result in \"Restic Backup - My Awesome Server\" Setup Restic Backup \u00b6 Create Service Account \u00b6 Create Rclone.conf \u00b6 ENV Setup \u00b6 Deploy Container \u00b6 Restic Backup Commands \u00b6 Support \u00b6 Kindly report any issues on GitHub or Join our for Support","title":"Restic"},{"location":"apps/backup/restic.html#restic","text":"Restic is a backup program that is fast, efficient and secure. It supports the three major operating systems (Linux, macOS, Windows) and a few smaller ones (FreeBSD, OpenBSD).","title":"Restic"},{"location":"apps/backup/restic.html#features","text":"Full Rclone Support. Runs default every day at 2am. Multiple jobs possible. Automatic configuration and repository creation.","title":"Features:"},{"location":"apps/backup/restic.html#configuration","text":"All settings can be found here: /opt/appdata/restic/restic/restic.env","title":"Configuration"},{"location":"apps/backup/restic.html#user-values","text":"Setting Default Description PUID 1000 PGUID to be used by Restic. PGID 1000 PGID to be used by Restic. TIMEZONE UTC Timezone to be used by Restic.","title":"USER VALUES"},{"location":"apps/backup/restic.html#restic-settings","text":"Setting Default Description RESTIC_JOBS 1 Configure multiple jobs, creates for every job an extra ENV file. RESTIC_HOST Restic Restic Backup hostname. RESTIC_REPOSITORY null Rclone Backup path eg example: rclone:tdrive:backup/myservername . RESTIC_PASSWORD null Secure password for your backups. RESTIC_TAG appdata Backup Tag, good for multiple Backups. RESTIC_EXCLUDES /app/restic/excludes.txt Default Excludes File inside the Docker. RESTIC_PACK_SIZE 32 Restic Pack Size Restic documentation RESTIC_CACHE_DIR /config/.cache Backup Cache Folder. RESTIC_FOLDER /opt/appdata Backup Folder.","title":"RESTIC - SETTINGS"},{"location":"apps/backup/restic.html#rclone-settings","text":"Setting Default Description GOOGLE_IP 142.250.74.78 Set hardcoded IP for www.googleapis.com this does prevent Error 429. You can specify multiple IPs with comma separated. PROXY null Set HTTP or SOCKS5 Proxy for RClone. Rclone documentation for details.","title":"RCLONE - SETTINGS"},{"location":"apps/backup/restic.html#notification-settings","text":"Apprise has been integrated into Uploader and is defaulted to format all notifications in Markdown . Please refer to the Apprise documentation for more information. Setting Default Description NOTIFICATION_URL null The notification URL to be passed to Apprise. Discord examples: https://discordapp.com/api/webhooks/{WebhookID}/{WebhookToken} discord://{WebhookID}/{WebhookToken}/ discord://{user}@{WebhookID}/{WebhookToken}/ NOTIFICATION_LEVEL ALL What notifications should be sent to NOTIFICATION_URL . Options: ALL - Send notification for all backups ERROR - Send notification for only errors NONE - Do not send any notifications NOTIFICATION_SERVERNAME null What to display on the notification, after \"Restic - \". null will default to \"Restic - Docker\". Anything else will only replace \"Docker\". Examples: NOTIFICATION_SERVERNAME=null results in \"Restic - Docker\" NOTIFICATION_SERVERNAME=My Awesome Server will result in \"Restic Backup - My Awesome Server\"","title":"NOTIFICATION - SETTINGS"},{"location":"apps/backup/restic.html#setup-restic-backup","text":"","title":"Setup Restic Backup"},{"location":"apps/backup/restic.html#install-container","text":"Install from dockserver>apps>backup menu","title":"Install Container"},{"location":"apps/backup/restic.html#create-service-account","text":"Put service account into /opt/appdata/restic/rclone/keys IMPORTANT : Make sure service account has manager permissions on google.","title":"Create Service Account"},{"location":"apps/backup/restic.html#create-rcloneconf","text":"nano /opt/appdata/restic/rclone/rclone.conf Should look something like this: [tdrive] type = drive scope = drive service_account_file = /config/rclone/keys/NAMEOFSA team_drive =xxxxxxxxx","title":"Create Rclone.conf"},{"location":"apps/backup/restic.html#env-setup","text":"nano /opt/appdata/restic/restic/restic.env change RESTIC_REPOSITORY=\"null\" to RESTIC_REPOSITORY=\"rclone:tdrive:PATH/TO/BACKUP/FOLDER\" change RESTIC_PASSWORD=null to RESTIC_PASSWORD=YOURPASSWORD","title":"ENV Setup"},{"location":"apps/backup/restic.html#restart-container","text":"After changes, sudo docker restart restic","title":"Restart Container"},{"location":"apps/backup/restic.html#restic-commands","text":"Manual Backup docker exec -it restic bash source /app/restic/restic.sh resticbackup Full Restore docker exec -it restic bash source /app/restic/restic.sh resticrestore-full App Restore docker exec -it restic bash source /app/restic/restic.sh resticrestore <APPNAME> View Snapshots docker exec -it restic bash source /app/restic/restic.sh resticsnapshots Restore Specific App Snapshot (Replace SNAPSHOT_ID and NAMEOFAPP) docker exec -it restic bash source /app/restic/restic.sh source /config/restic/restic.env $(which restic) restore <SNAPSHOT_ID> --repo \"${RESTIC_REPOSITORY}\" --password-command \"$(which echo) ${RESTIC_PASSWORD}\" --target \"/\" --tag \"${RESTIC_TAG}\" --option rclone.args=\"serve restic --stdio --checkers=16 --drive-chunk-size=32M --drive-use-trash=false --fast-list --config=/config/rclone/rclone.conf\" --include \"${RESTIC_FOLDER}/<NAMEOFAPP>\"","title":"Restic Commands"},{"location":"apps/backup/restic.html#configuration_1","text":"All settings can be found here: /opt/appdata/restic/restic/restic.env","title":"Configuration"},{"location":"apps/backup/restic.html#user-values_1","text":"Setting Default Description PUID 1000 PGUID to be used by Restic. PGID 1000 PGID to be used by Restic. TIMEZONE UTC Timezone to be used by Restic.","title":"USER VALUES"},{"location":"apps/backup/restic.html#restic-settings_1","text":"Setting Default Description RESTIC_JOBS 1 .. RESTIC_HOST Restic .. RESTIC_REPOSITORY null Rclone Backup path eg example: rclone:tdrive:backup/myservername . RESTIC_PASSWORD null Secure password for your backups. RESTIC_TAG appdata .. RESTIC_PACK_SIZE 32 .. RESTIC_CACHE_DIR /config/.cache .. RESTIC_FOLDER /opt/appdata ..","title":"RESTIC - SETTINGS"},{"location":"apps/backup/restic.html#rclone-settings_1","text":"Setting Default Description GOOGLE_IP 142.250.74.78 Set hardcoded IP for www.googleapis.com this does prevent Error 429. You can specify multiple IPs with comma separated. PROXY null Set HTTP or SOCKS5 Proxy for RClone. Rclone documentation for details.","title":"RCLONE - SETTINGS"},{"location":"apps/backup/restic.html#notification-settings_1","text":"Apprise has been integrated into Uploader and is defaulted to format all notifications in Markdown . Please refer to the Apprise documentation for more information. Setting Default Description NOTIFICATION_URL null The notification URL to be passed to Apprise. Discord examples: https://discordapp.com/api/webhooks/{WebhookID}/{WebhookToken} discord://{WebhookID}/{WebhookToken}/ discord://{user}@{WebhookID}/{WebhookToken}/ NOTIFICATION_LEVEL ALL What notifications should be sent to NOTIFICATION_URL . Options: ALL - Send notification for all backups ERROR - Send notification for only errors NONE - Do not send any notifications NOTIFICATION_SERVERNAME null What to display on the notification, after \"Restic - \". null will default to \"Restic - Docker\". Anything else will only replace \"Docker\". Examples: NOTIFICATION_SERVERNAME=null results in \"Restic - Docker\" NOTIFICATION_SERVERNAME=My Awesome Server will result in \"Restic Backup - My Awesome Server\"","title":"NOTIFICATION - SETTINGS"},{"location":"apps/backup/restic.html#setup-restic-backup_1","text":"","title":"Setup Restic Backup"},{"location":"apps/backup/restic.html#create-service-account_1","text":"","title":"Create Service Account"},{"location":"apps/backup/restic.html#create-rcloneconf_1","text":"","title":"Create Rclone.conf"},{"location":"apps/backup/restic.html#env-setup_1","text":"","title":"ENV Setup"},{"location":"apps/backup/restic.html#deploy-container","text":"","title":"Deploy Container"},{"location":"apps/backup/restic.html#restic-backup-commands","text":"","title":"Restic Backup Commands"},{"location":"apps/backup/restic.html#support","text":"Kindly report any issues on GitHub or Join our for Support","title":"Support"},{"location":"apps/backup/rsnapshot.html","text":"RSnapShot \u00b6 Rsnapshot comes with ABSOLUTELY NO WARRANTY. This is free software, and you are welcome to redistribute it under certain conditions. See the GNU General Public Licence for details. rsnapshot is a filesystem snapshot utility based on rsync. rsnapshot makes it easy to make periodic snapshots of local machines, and remote machines over ssh. The code makes extensive use of hard links whenever possible, to greatly reduce the disk space required. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Rsnapshot"},{"location":"apps/backup/rsnapshot.html#rsnapshot","text":"Rsnapshot comes with ABSOLUTELY NO WARRANTY. This is free software, and you are welcome to redistribute it under certain conditions. See the GNU General Public Licence for details. rsnapshot is a filesystem snapshot utility based on rsync. rsnapshot makes it easy to make periodic snapshots of local machines, and remote machines over ssh. The code makes extensive use of hard links whenever possible, to greatly reduce the disk space required.","title":"RSnapShot"},{"location":"apps/backup/rsnapshot.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/coding/cloud9.html","text":"Cloud9 \u00b6 Cloud9 Cloud9 is a complete web based IDE with terminal access. This container is for running their core SDK locally and developing plugins. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Cloud9"},{"location":"apps/coding/cloud9.html#cloud9","text":"Cloud9 Cloud9 is a complete web based IDE with terminal access. This container is for running their core SDK locally and developing plugins.","title":"Cloud9"},{"location":"apps/coding/cloud9.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/coding/code-server.html","text":"Code-Server \u00b6 Code-server is VS Code running on a remote server, accessible through the browser. Code on your Chromebook, tablet, and laptop with a consistent dev environment. If you have a Windows or Mac workstation, more easily develop for Linux. Take advantage of large cloud servers to speed up tests, compilations, downloads, and more. Preserve battery life when you're on the go. All intensive computation runs on your server. You're no longer running excess instances of Chrome. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Code-Server"},{"location":"apps/coding/code-server.html#code-server","text":"Code-server is VS Code running on a remote server, accessible through the browser. Code on your Chromebook, tablet, and laptop with a consistent dev environment. If you have a Windows or Mac workstation, more easily develop for Linux. Take advantage of large cloud servers to speed up tests, compilations, downloads, and more. Preserve battery life when you're on the go. All intensive computation runs on your server. You're no longer running excess instances of Chrome.","title":"Code-Server"},{"location":"apps/coding/code-server.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/downloadclients/davos.html","text":"Davos \u00b6 Davos is an FTP download automation tool that allows you to scan various FTP servers for files you are interested in. This can be used to configure file feeds as part of a wider workflow. Why use davos? \u00b6 A fair number of services still rely on \"file-drops\" to transport data from place to place. A common practice is to configure a cron job to periodically trigger FTP/SFTP programs to download those files. davos is relatively similar, only it also adds a web UI to the whole process, making the management of these schedules easier. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Davos"},{"location":"apps/downloadclients/davos.html#davos","text":"Davos is an FTP download automation tool that allows you to scan various FTP servers for files you are interested in. This can be used to configure file feeds as part of a wider workflow.","title":"Davos"},{"location":"apps/downloadclients/davos.html#why-use-davos","text":"A fair number of services still rely on \"file-drops\" to transport data from place to place. A common practice is to configure a cron job to periodically trigger FTP/SFTP programs to download those files. davos is relatively similar, only it also adds a web UI to the whole process, making the management of these schedules easier.","title":"Why use davos?"},{"location":"apps/downloadclients/davos.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/downloadclients/deluge.html","text":"Deluge BitTorrent Client \u00b6 Deluge is a BitTorrent client that utilizes a daemon/client model. It has various user interfaces available such as the GTK-UI, Web-UI and a Console-UI. It uses [libtorrent][lt] at it's core to handle the BitTorrent protocol. Advanced, lightweight Torrent client Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Deluge"},{"location":"apps/downloadclients/deluge.html#deluge-bittorrent-client","text":"Deluge is a BitTorrent client that utilizes a daemon/client model. It has various user interfaces available such as the GTK-UI, Web-UI and a Console-UI. It uses [libtorrent][lt] at it's core to handle the BitTorrent protocol. Advanced, lightweight Torrent client","title":"Deluge BitTorrent Client"},{"location":"apps/downloadclients/deluge.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/downloadclients/filezilla.html","text":"FileZilla \u00b6 This is a Docker container for FileZilla . The GUI of the application is accessed through a modern web browser (no installation or configuration needed on the client side) or via any VNC client. FileZilla is a cross-platform graphical FTP, SFTP, and FTPS file management tool with a vast list of features. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"FileZilla"},{"location":"apps/downloadclients/filezilla.html#filezilla","text":"This is a Docker container for FileZilla . The GUI of the application is accessed through a modern web browser (no installation or configuration needed on the client side) or via any VNC client. FileZilla is a cross-platform graphical FTP, SFTP, and FTPS file management tool with a vast list of features.","title":"FileZilla"},{"location":"apps/downloadclients/filezilla.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/downloadclients/jackett.html","text":"Jackett \u00b6 This project is a new fork and is recruiting development help. If you are able to help out please contact us . Please see our troubleshooting and contributing guidelines before submitting any issues or pull requests Jackett works as a proxy server: it translates queries from apps ( Sonarr , Radarr , SickRage , CouchPotato , Mylar , Lidarr , DuckieTV , qBittorrent , Nefarious etc.) into tracker-site-specific http queries, parses the html response, then sends results back to the requesting software. This allows for getting recent uploads (like RSS) and performing searches. Jackett is a single repository of maintained indexer scraping & translation logic - removing the burden from other apps. Developer note: The software implements the Torznab (with hybrid nZEDb / Newznab category numbering ) and TorrentPotato APIs. A third-party Golang SDK for Jackett is available from webtor-io/go-jackett Supported Public Trackers - 1337x - 7torrents - ACG.RIP - ACGsou (36DM) - Anidex - AniLibria - AnimeClipse - Animedia - Anime Tosho - AniRena - AniSource - AudioBook Bay (ABB) - Badass Torrents - BigFANGroup - BitRu - BT.etree - BT4G - BTDB - BTDIGG - BTSOW - Byrutor - CiliPro (LIAORENCILI) - comicat - ConCen - cpasbien - cpasbienClone - Demonoid - dmhy - E-Hentai - elitetorrent - emtrek - Erai-Raws - ETTV - EXT Torrents - ExtraTorrent.cd - ExtraTorrent.it - EZTV - Filebase - FireBit - Frozen Layer - GamesTorrents - GkTorrent - GloDLS - GTorrent - GTorrent.pro - HDhouse (HDReactor) - IBit - Idope - Il CorSaRo Blu - Il Corsaro Nero - Internet Archive (archive.org) - Isohunt2 - iTorrent - kickasstorrents.ws - kickasstorrents.to - Legit Torrents - LePorno.info - LimeTorrents - LinuxTracker - MacTorrents - Magnet4You - MejorTorrent - MixTapeTorrent - Montorrent - MoviesDVDR - MovieTorrent - MyPornClub - NewPCT (aka: tvsinpagar, descargas2020, torrentlocura, torrentrapid, tumejortorrent, pctnew, etc) - Newstudio - Nitro - NNTT - NoNaMe Club (NNM-Club) - Nyaa-Pantsu - Nyaa.si - OnceSearch - OneJAV - OxTorrent - ParnuXi - PC-torrent - PiratBit - Pirateiro - Pornforall - PornLeech - PornoLive - PornoRip - PornoTor - Portugas - ProPorn - ProStyleX - Rapidzona - RARBG - RinTor - RinTorNeT - Rus-media - RuTor - RuTracker.RU - seleZen - Sexy-Pics - ShizaProject - shokweb - ShowRSS - SkyTorrents.to - Solid Torrents - sosulki - SubsPlease - sukebei-Pantsu - sukebei.Nyaa.si - The Pirate Bay (TPB) - TNTfork - Tokyo Tosho - Torlock - TOROS - Torrent Downloads (TD) - Torrent Oyun indir - Torrent Paradise (ML) - torrent-pirat - Torrent4You - Torrent9 - Torrent9 clone - TorrentDownload - TorrentFunk - TorrentGalaxy (TGx) - TorrentKitty - TorrentMafya - TorrentMax (\ud1a0\ub80c\ud2b8\ub9e5\uc2a4) - TorrentParadise - TorrentProject2 - TorrentQQ (\ud1a0\ub80c\ud2b8\ud050\ud050) - Torrents.csv - TorrentSir (\ud1a0\ub80c\ud2b8\uc370) - Torrentv - TorrentView (\ud1a0\ub80c\ud2b8\ubdf0) - TorrentWhiz ( \ud1a0\ub80c\ud2b8\uc704\uc988) - truPornolabs - ttobogo - Underverse - UnionDHT - VSTHouse - VST Torrents - xxxAdultTorrent - xxxtor - xxxtorrents - YourBittorrent - YTS.ag - zetorrents - Zooqle Supported Semi-Private Trackers - AniDUB - Anime-Free - ArenaBG - BaibaKo - BookTracker - BootyTape - CasStudioTV - Catorrent - Darmowe torrenty - Deildu - DimeADozen (EzTorrent) - DXP (Deaf Experts) - EniaHD - Erzsebet.pl - ExKinoRay - Genesis-Movement - HamsterStudio - HD-CzTorrent - HunTorrent - IV-Torrents - KinoNaVse100 - Kinorun - Kinozal - LostFilm.tv - Magnetico (Local DHT) [[site](https://github.com/boramalper/magnetico)] - MVGroup Forum - MVGroup Main - Marine Tracker - Metal Tracker - MuziekFrabriek - NetHD (VietTorrent) - PornoLab - PussyTorrents - Rainbow Tracker - RiperAM - RockBox - RuTracker - Rustorka - SDkino - Sharewood - SkTorrent - SkTorrent-org - themixingbowl (TMB) - Toloka.to - Torrent-Explosiv - Torrents-Local - TribalMixes - Union Fansub - YggTorrent (YGG) - Ztracker Supported Private Trackers - 0day.kiev - 1ptbar - 2 Fast 4 You - 3ChangTrai (3CT) [![(invite needed)][inviteneeded]](#) - 3D Torrents (3DT) [![(invite needed)][inviteneeded]](#) - 4thD (4th Dimension) - 52PT - 720pier - Abnormal [![(invite needed)][inviteneeded]](#) - ABtorrents (ABT + RNS) - Acid Lounge (A-L) [![(invite needed)][inviteneeded]](#) - AcrossTheTasman [![(invite needed)][inviteneeded]](#) - Aftershock - Aidoru!Online - Aither - AlphaRatio (AR) - AmigosShareClub - anasch.cc - AnimeBytes (AB) - AnimeTorrents (AnT) - AnimeWorld [![(invite needed)][inviteneeded]](#) - Anthelion - Araba Fenice (Phoenix) [![(invite needed)][inviteneeded]](#) - ArabP2P - AsianCinema - Asylum Share - AudioNews (AN) - Aussierul.es [![(invite needed)][inviteneeded]](#) - AvistaZ (AsiaTorrents) - Borgzelle - Back-ups - bB - BakaBT - BeiTai - BeyondHD (BHD) - Bibliotik - BIGTorrent - Bit-City Reloaded [![(invite needed)][inviteneeded]](#) - BIT-HDTV - BiT-TiTAN - BitHUmen - BitTorrentFiles - BiTTuRK - Bithorlo (BHO) - Bitspyder - BJ-Share (BJ) - BlueBird [![(invite needed)][inviteneeded]](#) - Blutopia (BLU) - Boxing Torrents - Brasil Tracker - BroadCity [![(invite needed)][inviteneeded]](#) - BroadcasTheNet (BTN) - BrokenStones [![(invite needed)][inviteneeded]](#) - BTNext (BTNT) - BTSCHOOL - BWTorrents - CCFBits - CGPeers - CHDBits - Carp-Hunter - Carpathians - CartoonChaos (CC) - CasaTorrent [![(invite needed)][inviteneeded]](#) - ChileBT - Cinecalidad - CinemaMovieS_ZT - CinemaZ (EuTorrents) - Cinemageddon - Cinematik - Classix - Coastal-Crew - Concertos - CrazyHD - CrazySpirits - CrnaBerza - DANISH BYTES - Darius Tracker - Dark-Shadow - Dark Tracker - Das Unerwartete [![(invite needed)][inviteneeded]](#) - DataScene (DS) - DesiReleasers - DesiTorrents - Diablo Torrent - DICMusic - DigitalCore - DivTeam - DivxTotal - Dragonworld Reloaded [![(invite needed)][inviteneeded]](#) - EbookParadijs - Ebooks-Shares - EfectoDoppler - Empornium (EMP) - EpubLibre - eShareNet - eStone (XiDER, BeLoad) - ExoticaZ (YourExotic) - ExtremeBits - ExtremeTorrents [![(invite needed)][inviteneeded]](#) - FANO.IN - Fantastic Heaven - FeedUrNeed - Femdomcult - FileList (FL) - Film-Paleis - FinElite (FE) - FinVip - FocusX - Fou-Du-Cinema - FreeTorrent - FunFile (FF) - FunkyTorrents (FT) [![(invite needed)][inviteneeded]](#) - Fuzer (FZ) - GFXPeers - Gay-Torrents.net - Gay-Torrents.org [![(invite needed)][inviteneeded]](#) - GAYtorrent.ru - GazelleGames (GGn) [![(invite needed)][inviteneeded]](#) - Generation-Free - GigaTorrents - GimmePeers (formerly ILT) - GiroTorrent - GreekDiamond - Greek Team - HaiDan - HD Dolby [![(invite needed)][inviteneeded]](#) - HD-Bits.com - HD-Forever (HDF) - HD-Olimpo - HD-Only (HDO) - HD-Space (HDS) - HD-Spain [![(invite needed)][inviteneeded]](#) - HD-Torrents (HDT) - HD4FANS [![(invite needed)][inviteneeded]](#) - HDArea (HDA) - HDAtmos - HDBits - HDCenter [![(invite needed)][inviteneeded]](#) - HDChina (HDWing) - HDC (HDCiTY) - HDCity - HDHome (HDBigger) - HDME - HDRoute [![(invite needed)][inviteneeded]](#) - HDSky - HDTime - HDTorrents.it - HDTurk [![(invite needed)][inviteneeded]](#) - HDU [![(invite needed)][inviteneeded]](#) - HDZone - Hebits - HellasTZ - Hon3y HD - HQSource (HQS) - HuSh [![(invite needed)][inviteneeded]](#) - IPTorrents (IPT) - ImmortalSeed (iS) - Immortuos - Insane Tracker - IPTorrents (IPT) - JPopsuki - JPTV - Karagarga - Keep Friends - LastFiles - LatinoP2P - Le Saloon - LemonHD - LearnFlakes - LegacyHD (HD4Free) - Libble - LibraNet (LN) - LinkoManija - LosslessClub - M-Team TP (MTTP) - MaDs Revolution - magic-heaven - Magico (Trellas) - Majompar\u00e1d\u00e9 (TurkDepo) - MeseVil\u00e1g (Fairytale World) - MicroBit (\u00b5Bit) - Milkie - MMA-Torrents - MNV (Max-New-Vision) - Mononok\u00e9-BT [![(invite needed)][inviteneeded]](#) - MoreThanTV (MTV) - MyAnonamouse (MAM) - MySpleen [![(invite needed)][inviteneeded]](#) - NBTorrents [![(invite needed)][inviteneeded]](#) - NCore - Nebulance (NBL) (TransmiTheNet) - NetCosmo - NetLab - NorBits - Nordic+ - Oasis - Obscure - oMg[WtF]trackr - OpenCD - Oppaitime [![(invite needed)][inviteneeded]](#) - Orpheus - OshenPT - Ourbits (HDPter) - P2PBG - P2PElite - PassThePopcorn (PTP) - Peers.FM - Pirata Digital - PirateTheNet (PTN) - PixelCove (Ultimate Gamer) - PiXELHD (PxHD) [![(invite needed)][inviteneeded]](#) - Pleasuredome - PolishSource (PS) - PolishTracker - PornBits (PB) - Pornbay [![(invite needed)][inviteneeded]](#) - PotUK - Pretome - PrivateHD (PHD) - ProAudioTorrents (PAT) - PTerClub - PTFiles (PTF) - PThome - PTMSG - PTSBAO - PTtime - PuntoTorrent - PuroVicio - Puur-Hollands - PWTorrents (PWT) - R3V WTF! [![(invite needed)][inviteneeded]](#) - Racing4Everyone (R4E) - RacingForMe (RFM) - RedBits - Red Star Torrent (RST) [![(invite needed)][inviteneeded]](#) - Redacted (PassTheHeadphones) - RetroFlix - RevolutionTT - ROFD - Romanian Metal Torrents (RMT) [![(invite needed)][inviteneeded]](#) - RPTorrents - SceneHD - ScenePalace (SP) - SceneRush - SceneTime - SDBits [![(invite needed)][inviteneeded]](#) - Secret Cinema - SeedFile (SF) - ShareFiles - Shareisland - Shazbat - SiamBIT - SnowPT (SSPT) - SoulVoice [![(invite needed)][inviteneeded]](#) - SpeedApp (SceneFZ, XtreMeZone / MYXZ, ICE Torrent) - SpeedCD - Speedmaster HD - SpeedTorrent Reloaded - Spirit of Revolution [![(invite needed)][inviteneeded]](#) - SportHD [![(invite needed)][inviteneeded]](#) - SportsCult - SpringSunday - SugoiMusic - Superbits (SBS) - Tapochek - Tasmanit [![(invite needed)][inviteneeded]](#) - TeamHD - TeamOS - TEKNO3D [![(invite needed)][inviteneeded]](#) - TellyTorrent - teracod (Movie Zone) - The Falling Angels (TFA) - The Geeks [![(invite needed)][inviteneeded]](#) - The Horror Charnel (THC) - The New Retro - The Occult [![(invite needed)][inviteneeded]](#) - The Place [![(invite needed)][inviteneeded]](#) - The Shinning (TsH) - The Show [![(invite needed)][inviteneeded]](#) - The Vault [![(invite needed)][inviteneeded]](#) - TheAudioScene - TheEmpire (TE) [![(invite needed)][inviteneeded]](#) - TheLeachZone - TheScenePlace (TSP) - TJUPT - TLFBits [![(invite needed)][inviteneeded]](#) - ToTheGlory (TTG) - Torrent Network (TN) - Torrent Sector Crew (TSC) - Torrent Surf - Torrent-Syndikat [![(invite needed)][inviteneeded]](#) - TOrrent-tuRK (TORK) - Torrent.LT - TorrentBD - TorrentBytes (TBy) - TorrentCCF (TCCF) - TorrentDay (TD) - TorrentDB - TorrentFactory - TorrentHR - TorrentHeaven [![(invite needed)][inviteneeded]](#) - TorrentLeech (TL) - TorrentLeech.pl - TorrentSeeds (TS) - Torrentech (TTH) - Torrenting (TT) [![(invite needed)][inviteneeded]](#) - Torrentland - TotallyKids (TK) - Trackeros - TranceTraffic [![(invite needed)][inviteneeded]](#) - Trezzor - TTsWEB - TurkSeed - TurkTorrent (TT) - TV Chaos UK (TVCUK) - TV-Vault - TVstore - Twilight Torrents - Twilights Zoom - U2 (U2 \u5206\u4eab\u5712@\u52d5\u6f2b\u82b1\u5712) [![(invite needed)][inviteneeded]](#) - UHDBits - UnionGang [![(invite needed)][inviteneeded]](#) - UnlimitZ - Vizuk - WDT (Wrestling Desires Torrents / Ultimate Wrestling Torrents) - Witch-Hunter (Demon-Site) - wOOt [![(invite needed)][inviteneeded]](#) - World-In-HD [![(invite needed)][inviteneeded]](#) - x-ite.me (XM) [![(invite needed)][inviteneeded]](#) - xBytesV2 - XSpeeds (XS) - XWT-Classics - XWTorrents (XWT) - Xthor - YDYPT - Zamunda.net - Zelka.org - ZonaQ Trackers marked with ![(invite needed)][inviteneeded] have no active maintainer and may be missing features or be broken. If you have an invite for them please send it to garfieldsixtynine -at- gmail.com to get them fixed/improved. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Jacket"},{"location":"apps/downloadclients/jackett.html#jackett","text":"This project is a new fork and is recruiting development help. If you are able to help out please contact us . Please see our troubleshooting and contributing guidelines before submitting any issues or pull requests Jackett works as a proxy server: it translates queries from apps ( Sonarr , Radarr , SickRage , CouchPotato , Mylar , Lidarr , DuckieTV , qBittorrent , Nefarious etc.) into tracker-site-specific http queries, parses the html response, then sends results back to the requesting software. This allows for getting recent uploads (like RSS) and performing searches. Jackett is a single repository of maintained indexer scraping & translation logic - removing the burden from other apps. Developer note: The software implements the Torznab (with hybrid nZEDb / Newznab category numbering ) and TorrentPotato APIs. A third-party Golang SDK for Jackett is available from webtor-io/go-jackett Supported Public Trackers - 1337x - 7torrents - ACG.RIP - ACGsou (36DM) - Anidex - AniLibria - AnimeClipse - Animedia - Anime Tosho - AniRena - AniSource - AudioBook Bay (ABB) - Badass Torrents - BigFANGroup - BitRu - BT.etree - BT4G - BTDB - BTDIGG - BTSOW - Byrutor - CiliPro (LIAORENCILI) - comicat - ConCen - cpasbien - cpasbienClone - Demonoid - dmhy - E-Hentai - elitetorrent - emtrek - Erai-Raws - ETTV - EXT Torrents - ExtraTorrent.cd - ExtraTorrent.it - EZTV - Filebase - FireBit - Frozen Layer - GamesTorrents - GkTorrent - GloDLS - GTorrent - GTorrent.pro - HDhouse (HDReactor) - IBit - Idope - Il CorSaRo Blu - Il Corsaro Nero - Internet Archive (archive.org) - Isohunt2 - iTorrent - kickasstorrents.ws - kickasstorrents.to - Legit Torrents - LePorno.info - LimeTorrents - LinuxTracker - MacTorrents - Magnet4You - MejorTorrent - MixTapeTorrent - Montorrent - MoviesDVDR - MovieTorrent - MyPornClub - NewPCT (aka: tvsinpagar, descargas2020, torrentlocura, torrentrapid, tumejortorrent, pctnew, etc) - Newstudio - Nitro - NNTT - NoNaMe Club (NNM-Club) - Nyaa-Pantsu - Nyaa.si - OnceSearch - OneJAV - OxTorrent - ParnuXi - PC-torrent - PiratBit - Pirateiro - Pornforall - PornLeech - PornoLive - PornoRip - PornoTor - Portugas - ProPorn - ProStyleX - Rapidzona - RARBG - RinTor - RinTorNeT - Rus-media - RuTor - RuTracker.RU - seleZen - Sexy-Pics - ShizaProject - shokweb - ShowRSS - SkyTorrents.to - Solid Torrents - sosulki - SubsPlease - sukebei-Pantsu - sukebei.Nyaa.si - The Pirate Bay (TPB) - TNTfork - Tokyo Tosho - Torlock - TOROS - Torrent Downloads (TD) - Torrent Oyun indir - Torrent Paradise (ML) - torrent-pirat - Torrent4You - Torrent9 - Torrent9 clone - TorrentDownload - TorrentFunk - TorrentGalaxy (TGx) - TorrentKitty - TorrentMafya - TorrentMax (\ud1a0\ub80c\ud2b8\ub9e5\uc2a4) - TorrentParadise - TorrentProject2 - TorrentQQ (\ud1a0\ub80c\ud2b8\ud050\ud050) - Torrents.csv - TorrentSir (\ud1a0\ub80c\ud2b8\uc370) - Torrentv - TorrentView (\ud1a0\ub80c\ud2b8\ubdf0) - TorrentWhiz ( \ud1a0\ub80c\ud2b8\uc704\uc988) - truPornolabs - ttobogo - Underverse - UnionDHT - VSTHouse - VST Torrents - xxxAdultTorrent - xxxtor - xxxtorrents - YourBittorrent - YTS.ag - zetorrents - Zooqle Supported Semi-Private Trackers - AniDUB - Anime-Free - ArenaBG - BaibaKo - BookTracker - BootyTape - CasStudioTV - Catorrent - Darmowe torrenty - Deildu - DimeADozen (EzTorrent) - DXP (Deaf Experts) - EniaHD - Erzsebet.pl - ExKinoRay - Genesis-Movement - HamsterStudio - HD-CzTorrent - HunTorrent - IV-Torrents - KinoNaVse100 - Kinorun - Kinozal - LostFilm.tv - Magnetico (Local DHT) [[site](https://github.com/boramalper/magnetico)] - MVGroup Forum - MVGroup Main - Marine Tracker - Metal Tracker - MuziekFrabriek - NetHD (VietTorrent) - PornoLab - PussyTorrents - Rainbow Tracker - RiperAM - RockBox - RuTracker - Rustorka - SDkino - Sharewood - SkTorrent - SkTorrent-org - themixingbowl (TMB) - Toloka.to - Torrent-Explosiv - Torrents-Local - TribalMixes - Union Fansub - YggTorrent (YGG) - Ztracker Supported Private Trackers - 0day.kiev - 1ptbar - 2 Fast 4 You - 3ChangTrai (3CT) [![(invite needed)][inviteneeded]](#) - 3D Torrents (3DT) [![(invite needed)][inviteneeded]](#) - 4thD (4th Dimension) - 52PT - 720pier - Abnormal [![(invite needed)][inviteneeded]](#) - ABtorrents (ABT + RNS) - Acid Lounge (A-L) [![(invite needed)][inviteneeded]](#) - AcrossTheTasman [![(invite needed)][inviteneeded]](#) - Aftershock - Aidoru!Online - Aither - AlphaRatio (AR) - AmigosShareClub - anasch.cc - AnimeBytes (AB) - AnimeTorrents (AnT) - AnimeWorld [![(invite needed)][inviteneeded]](#) - Anthelion - Araba Fenice (Phoenix) [![(invite needed)][inviteneeded]](#) - ArabP2P - AsianCinema - Asylum Share - AudioNews (AN) - Aussierul.es [![(invite needed)][inviteneeded]](#) - AvistaZ (AsiaTorrents) - Borgzelle - Back-ups - bB - BakaBT - BeiTai - BeyondHD (BHD) - Bibliotik - BIGTorrent - Bit-City Reloaded [![(invite needed)][inviteneeded]](#) - BIT-HDTV - BiT-TiTAN - BitHUmen - BitTorrentFiles - BiTTuRK - Bithorlo (BHO) - Bitspyder - BJ-Share (BJ) - BlueBird [![(invite needed)][inviteneeded]](#) - Blutopia (BLU) - Boxing Torrents - Brasil Tracker - BroadCity [![(invite needed)][inviteneeded]](#) - BroadcasTheNet (BTN) - BrokenStones [![(invite needed)][inviteneeded]](#) - BTNext (BTNT) - BTSCHOOL - BWTorrents - CCFBits - CGPeers - CHDBits - Carp-Hunter - Carpathians - CartoonChaos (CC) - CasaTorrent [![(invite needed)][inviteneeded]](#) - ChileBT - Cinecalidad - CinemaMovieS_ZT - CinemaZ (EuTorrents) - Cinemageddon - Cinematik - Classix - Coastal-Crew - Concertos - CrazyHD - CrazySpirits - CrnaBerza - DANISH BYTES - Darius Tracker - Dark-Shadow - Dark Tracker - Das Unerwartete [![(invite needed)][inviteneeded]](#) - DataScene (DS) - DesiReleasers - DesiTorrents - Diablo Torrent - DICMusic - DigitalCore - DivTeam - DivxTotal - Dragonworld Reloaded [![(invite needed)][inviteneeded]](#) - EbookParadijs - Ebooks-Shares - EfectoDoppler - Empornium (EMP) - EpubLibre - eShareNet - eStone (XiDER, BeLoad) - ExoticaZ (YourExotic) - ExtremeBits - ExtremeTorrents [![(invite needed)][inviteneeded]](#) - FANO.IN - Fantastic Heaven - FeedUrNeed - Femdomcult - FileList (FL) - Film-Paleis - FinElite (FE) - FinVip - FocusX - Fou-Du-Cinema - FreeTorrent - FunFile (FF) - FunkyTorrents (FT) [![(invite needed)][inviteneeded]](#) - Fuzer (FZ) - GFXPeers - Gay-Torrents.net - Gay-Torrents.org [![(invite needed)][inviteneeded]](#) - GAYtorrent.ru - GazelleGames (GGn) [![(invite needed)][inviteneeded]](#) - Generation-Free - GigaTorrents - GimmePeers (formerly ILT) - GiroTorrent - GreekDiamond - Greek Team - HaiDan - HD Dolby [![(invite needed)][inviteneeded]](#) - HD-Bits.com - HD-Forever (HDF) - HD-Olimpo - HD-Only (HDO) - HD-Space (HDS) - HD-Spain [![(invite needed)][inviteneeded]](#) - HD-Torrents (HDT) - HD4FANS [![(invite needed)][inviteneeded]](#) - HDArea (HDA) - HDAtmos - HDBits - HDCenter [![(invite needed)][inviteneeded]](#) - HDChina (HDWing) - HDC (HDCiTY) - HDCity - HDHome (HDBigger) - HDME - HDRoute [![(invite needed)][inviteneeded]](#) - HDSky - HDTime - HDTorrents.it - HDTurk [![(invite needed)][inviteneeded]](#) - HDU [![(invite needed)][inviteneeded]](#) - HDZone - Hebits - HellasTZ - Hon3y HD - HQSource (HQS) - HuSh [![(invite needed)][inviteneeded]](#) - IPTorrents (IPT) - ImmortalSeed (iS) - Immortuos - Insane Tracker - IPTorrents (IPT) - JPopsuki - JPTV - Karagarga - Keep Friends - LastFiles - LatinoP2P - Le Saloon - LemonHD - LearnFlakes - LegacyHD (HD4Free) - Libble - LibraNet (LN) - LinkoManija - LosslessClub - M-Team TP (MTTP) - MaDs Revolution - magic-heaven - Magico (Trellas) - Majompar\u00e1d\u00e9 (TurkDepo) - MeseVil\u00e1g (Fairytale World) - MicroBit (\u00b5Bit) - Milkie - MMA-Torrents - MNV (Max-New-Vision) - Mononok\u00e9-BT [![(invite needed)][inviteneeded]](#) - MoreThanTV (MTV) - MyAnonamouse (MAM) - MySpleen [![(invite needed)][inviteneeded]](#) - NBTorrents [![(invite needed)][inviteneeded]](#) - NCore - Nebulance (NBL) (TransmiTheNet) - NetCosmo - NetLab - NorBits - Nordic+ - Oasis - Obscure - oMg[WtF]trackr - OpenCD - Oppaitime [![(invite needed)][inviteneeded]](#) - Orpheus - OshenPT - Ourbits (HDPter) - P2PBG - P2PElite - PassThePopcorn (PTP) - Peers.FM - Pirata Digital - PirateTheNet (PTN) - PixelCove (Ultimate Gamer) - PiXELHD (PxHD) [![(invite needed)][inviteneeded]](#) - Pleasuredome - PolishSource (PS) - PolishTracker - PornBits (PB) - Pornbay [![(invite needed)][inviteneeded]](#) - PotUK - Pretome - PrivateHD (PHD) - ProAudioTorrents (PAT) - PTerClub - PTFiles (PTF) - PThome - PTMSG - PTSBAO - PTtime - PuntoTorrent - PuroVicio - Puur-Hollands - PWTorrents (PWT) - R3V WTF! [![(invite needed)][inviteneeded]](#) - Racing4Everyone (R4E) - RacingForMe (RFM) - RedBits - Red Star Torrent (RST) [![(invite needed)][inviteneeded]](#) - Redacted (PassTheHeadphones) - RetroFlix - RevolutionTT - ROFD - Romanian Metal Torrents (RMT) [![(invite needed)][inviteneeded]](#) - RPTorrents - SceneHD - ScenePalace (SP) - SceneRush - SceneTime - SDBits [![(invite needed)][inviteneeded]](#) - Secret Cinema - SeedFile (SF) - ShareFiles - Shareisland - Shazbat - SiamBIT - SnowPT (SSPT) - SoulVoice [![(invite needed)][inviteneeded]](#) - SpeedApp (SceneFZ, XtreMeZone / MYXZ, ICE Torrent) - SpeedCD - Speedmaster HD - SpeedTorrent Reloaded - Spirit of Revolution [![(invite needed)][inviteneeded]](#) - SportHD [![(invite needed)][inviteneeded]](#) - SportsCult - SpringSunday - SugoiMusic - Superbits (SBS) - Tapochek - Tasmanit [![(invite needed)][inviteneeded]](#) - TeamHD - TeamOS - TEKNO3D [![(invite needed)][inviteneeded]](#) - TellyTorrent - teracod (Movie Zone) - The Falling Angels (TFA) - The Geeks [![(invite needed)][inviteneeded]](#) - The Horror Charnel (THC) - The New Retro - The Occult [![(invite needed)][inviteneeded]](#) - The Place [![(invite needed)][inviteneeded]](#) - The Shinning (TsH) - The Show [![(invite needed)][inviteneeded]](#) - The Vault [![(invite needed)][inviteneeded]](#) - TheAudioScene - TheEmpire (TE) [![(invite needed)][inviteneeded]](#) - TheLeachZone - TheScenePlace (TSP) - TJUPT - TLFBits [![(invite needed)][inviteneeded]](#) - ToTheGlory (TTG) - Torrent Network (TN) - Torrent Sector Crew (TSC) - Torrent Surf - Torrent-Syndikat [![(invite needed)][inviteneeded]](#) - TOrrent-tuRK (TORK) - Torrent.LT - TorrentBD - TorrentBytes (TBy) - TorrentCCF (TCCF) - TorrentDay (TD) - TorrentDB - TorrentFactory - TorrentHR - TorrentHeaven [![(invite needed)][inviteneeded]](#) - TorrentLeech (TL) - TorrentLeech.pl - TorrentSeeds (TS) - Torrentech (TTH) - Torrenting (TT) [![(invite needed)][inviteneeded]](#) - Torrentland - TotallyKids (TK) - Trackeros - TranceTraffic [![(invite needed)][inviteneeded]](#) - Trezzor - TTsWEB - TurkSeed - TurkTorrent (TT) - TV Chaos UK (TVCUK) - TV-Vault - TVstore - Twilight Torrents - Twilights Zoom - U2 (U2 \u5206\u4eab\u5712@\u52d5\u6f2b\u82b1\u5712) [![(invite needed)][inviteneeded]](#) - UHDBits - UnionGang [![(invite needed)][inviteneeded]](#) - UnlimitZ - Vizuk - WDT (Wrestling Desires Torrents / Ultimate Wrestling Torrents) - Witch-Hunter (Demon-Site) - wOOt [![(invite needed)][inviteneeded]](#) - World-In-HD [![(invite needed)][inviteneeded]](#) - x-ite.me (XM) [![(invite needed)][inviteneeded]](#) - xBytesV2 - XSpeeds (XS) - XWT-Classics - XWTorrents (XWT) - Xthor - YDYPT - Zamunda.net - Zelka.org - ZonaQ Trackers marked with ![(invite needed)][inviteneeded] have no active maintainer and may be missing features or be broken. If you have an invite for them please send it to garfieldsixtynine -at- gmail.com to get them fixed/improved.","title":"Jackett"},{"location":"apps/downloadclients/jackett.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/downloadclients/jdownloader2.html","text":"JDownloader 2 \u00b6 This is a Docker container for JDownloader 2 . The GUI of the application is accessed through a modern web browser (no installation or configuration needed on the client side) or via any VNC client. JDownloader 2 is a free, open-source download management tool with a huge community of developers that makes downloading as easy and fast as it should be. Users can start, stop or pause downloads, set bandwith limitations, auto-extract archives and much more. It's an easy-to-extend framework that can save hours of your valuable time every day! Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"JDOwnloader2"},{"location":"apps/downloadclients/jdownloader2.html#jdownloader-2","text":"This is a Docker container for JDownloader 2 . The GUI of the application is accessed through a modern web browser (no installation or configuration needed on the client side) or via any VNC client. JDownloader 2 is a free, open-source download management tool with a huge community of developers that makes downloading as easy and fast as it should be. Users can start, stop or pause downloads, set bandwith limitations, auto-extract archives and much more. It's an easy-to-extend framework that can save hours of your valuable time every day!","title":"JDownloader 2"},{"location":"apps/downloadclients/jdownloader2.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/downloadclients/nzbget.html","text":"NZBGet \u00b6 NZBGet is a binary downloader, which downloads files from Usenet based on information given in nzb-files. NZBGet is written in C++ and is known for its performance and efficiency. NZBGet can run on almost any device - classic PC, NAS, media player, SAT-receiver, WLAN-router, etc. The download area provides precompiled binaries for Windows, macOS, Linux (compatible with many CPUs and platform variants), FreeBSD and Android. For other platforms the program can be compiled from sources. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"NZBGet"},{"location":"apps/downloadclients/nzbget.html#nzbget","text":"NZBGet is a binary downloader, which downloads files from Usenet based on information given in nzb-files. NZBGet is written in C++ and is known for its performance and efficiency. NZBGet can run on almost any device - classic PC, NAS, media player, SAT-receiver, WLAN-router, etc. The download area provides precompiled binaries for Windows, macOS, Linux (compatible with many CPUs and platform variants), FreeBSD and Android. For other platforms the program can be compiled from sources.","title":"NZBGet"},{"location":"apps/downloadclients/nzbget.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/downloadclients/nzbhydra.html","text":"NZBHydra \u00b6 NZBHydra is a meta search for NZB indexers. It provides easy access to a number of raw and newznab based indexers. You can search all your indexers from one place and use it as indexer source for tools like Sonarr or CouchPotato. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"NZBHydra"},{"location":"apps/downloadclients/nzbhydra.html#nzbhydra","text":"NZBHydra is a meta search for NZB indexers. It provides easy access to a number of raw and newznab based indexers. You can search all your indexers from one place and use it as indexer source for tools like Sonarr or CouchPotato.","title":"NZBHydra"},{"location":"apps/downloadclients/nzbhydra.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/downloadclients/qbittorrent.html","text":"qBittorrent - A BitTorrent client in Qt \u00b6 Description: \u00b6 qBittorrent is a bittorrent client programmed in C++ / Qt that uses libtorrent (sometimes called libtorrent-rasterbar) by Arvid Norberg. It aims to be a good alternative to all other bittorrent clients out there. qBittorrent is fast, stable and provides unicode support as well as many features. The free IP to Country Lite database by DB-IP is used for resolving the countries of peers. The database is licensed under the Creative Commons Attribution 4.0 International License . Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"QBittorrent"},{"location":"apps/downloadclients/qbittorrent.html#qbittorrent-a-bittorrent-client-in-qt","text":"","title":"qBittorrent - A BitTorrent client in Qt"},{"location":"apps/downloadclients/qbittorrent.html#description","text":"qBittorrent is a bittorrent client programmed in C++ / Qt that uses libtorrent (sometimes called libtorrent-rasterbar) by Arvid Norberg. It aims to be a good alternative to all other bittorrent clients out there. qBittorrent is fast, stable and provides unicode support as well as many features. The free IP to Country Lite database by DB-IP is used for resolving the countries of peers. The database is licensed under the Creative Commons Attribution 4.0 International License .","title":"Description:"},{"location":"apps/downloadclients/qbittorrent.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/downloadclients/rutorrent.html","text":"ruTorrent \u00b6 About \u00b6 rTorrent and ruTorrent Docker image based on Alpine Linux. Features \u00b6 Run as non-root user Multi-platform image Latest rTorrent / libTorrent release compiled from source Latest ruTorrent release Name resolving enhancements with c-ares for asynchronous DNS requests (including name resolves) Enhanced rTorrent config and bootstraping with a local config WAN IP address automatically resolved for reporting to the tracker XMLRPC through nginx over SCGI socket (basic auth optional) WebDAV on completed downloads (basic auth optional) Ability to add a custom ruTorrent plugin / theme Allow persisting specific configuration for ruTorrent plugins ruTorrent GeoIP2 plugin mktorrent installed for ruTorrent create plugin Traefik Docker image as reverse proxy and creation/renewal of Let's Encrypt certificates geoip-updater Docker image to download MaxMind's GeoIP2 databases on a time-based schedule for geolocation Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"RuTorrent"},{"location":"apps/downloadclients/rutorrent.html#rutorrent","text":"","title":"ruTorrent"},{"location":"apps/downloadclients/rutorrent.html#about","text":"rTorrent and ruTorrent Docker image based on Alpine Linux.","title":"About"},{"location":"apps/downloadclients/rutorrent.html#features","text":"Run as non-root user Multi-platform image Latest rTorrent / libTorrent release compiled from source Latest ruTorrent release Name resolving enhancements with c-ares for asynchronous DNS requests (including name resolves) Enhanced rTorrent config and bootstraping with a local config WAN IP address automatically resolved for reporting to the tracker XMLRPC through nginx over SCGI socket (basic auth optional) WebDAV on completed downloads (basic auth optional) Ability to add a custom ruTorrent plugin / theme Allow persisting specific configuration for ruTorrent plugins ruTorrent GeoIP2 plugin mktorrent installed for ruTorrent create plugin Traefik Docker image as reverse proxy and creation/renewal of Let's Encrypt certificates geoip-updater Docker image to download MaxMind's GeoIP2 databases on a time-based schedule for geolocation","title":"Features"},{"location":"apps/downloadclients/rutorrent.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/downloadclients/sabnzbd.html","text":"SABnzbd - The automated Usenet download tool \u00b6 SABnzbd is an Open Source Binary Newsreader written in Python. It's totally free, easy to use, and works practically everywhere. SABnzbd makes Usenet as simple and streamlined as possible by automating everything we can. All you have to do is add an .nzb . SABnzbd takes over from there, where it will be automatically downloaded, verified, repaired, extracted and filed away with zero human interaction. SABnzbd offers an easy setup wizard and has self-analysis tools to verify your setup. If you want to know more you can head over to our website: https://sabnzbd.org . Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"SabNZBD"},{"location":"apps/downloadclients/sabnzbd.html#sabnzbd-the-automated-usenet-download-tool","text":"SABnzbd is an Open Source Binary Newsreader written in Python. It's totally free, easy to use, and works practically everywhere. SABnzbd makes Usenet as simple and streamlined as possible by automating everything we can. All you have to do is add an .nzb . SABnzbd takes over from there, where it will be automatically downloaded, verified, repaired, extracted and filed away with zero human interaction. SABnzbd offers an easy setup wizard and has self-analysis tools to verify your setup. If you want to know more you can head over to our website: https://sabnzbd.org .","title":"SABnzbd - The automated Usenet download tool"},{"location":"apps/downloadclients/sabnzbd.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/downloadclients/youtubedl-material.html","text":"YoutubeDL-Material \u00b6 YoutubeDL-Material is a Material Design frontend for youtube-dl . It's coded using Angular 11 for the frontend, and Node.js on the backend. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Youtubedl-Material"},{"location":"apps/downloadclients/youtubedl-material.html#youtubedl-material","text":"YoutubeDL-Material is a Material Design frontend for youtube-dl . It's coded using Angular 11 for the frontend, and Node.js on the backend.","title":"YoutubeDL-Material"},{"location":"apps/downloadclients/youtubedl-material.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/encoder/handbrake.html","text":"HandBrake \u00b6 HandBrake is an open-source video transcoder available for Linux, Mac, and Windows, licensed under the GNU General Public License (GPL) Version 2 . HandBrake takes videos you already have and makes new ones that work on your mobile phone, tablet, TV media player, game console, computer, or web browser\u2014nearly anything that supports modern video formats. HandBrake works with most common video files and formats, including ones created by consumer and professional video cameras, mobile devices such as phones and tablets, game and computer screen recordings, and DVD and Blu-ray discs. HandBrake leverages tools such as FFmpeg, x264, and x265 to create new MP4 or MKV video files from these Sources . For information on downloading, building/installing, and using HandBrake, see the official HandBrake Documentation . Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"HandBrake"},{"location":"apps/encoder/handbrake.html#handbrake","text":"HandBrake is an open-source video transcoder available for Linux, Mac, and Windows, licensed under the GNU General Public License (GPL) Version 2 . HandBrake takes videos you already have and makes new ones that work on your mobile phone, tablet, TV media player, game console, computer, or web browser\u2014nearly anything that supports modern video formats. HandBrake works with most common video files and formats, including ones created by consumer and professional video cameras, mobile devices such as phones and tablets, game and computer screen recordings, and DVD and Blu-ray discs. HandBrake leverages tools such as FFmpeg, x264, and x265 to create new MP4 or MKV video files from these Sources . For information on downloading, building/installing, and using HandBrake, see the official HandBrake Documentation .","title":"HandBrake"},{"location":"apps/encoder/handbrake.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/encoder/tdarr.html","text":"Tdarr V2: Distributed Transcoding System \u00b6 Audio/Video Library Analytics & Transcode/Remux Automation FFmpeg/HandBrake + video health checking (Windows, macOS, Linux & Docker) About: Tdarr V2 is a closed-source distributed transcoding system for automating media library transcode/remux management and making sure your files are exactly how you need them to be in terms of codecs/streams/containers and so on. Put your spare hardware to use with Tdarr Nodes for Windows, Linux (including Linux arm) and macOS. Code in this repository is for Tdarr V1, Tdarr V2 is not open-source. Designed to work alongside applications like Sonarr/Radarr and built with the aim of modularisation, parallelisation and scalability, each library you add has its own transcode settings, filters and schedule. Workers can be fired up and closed down as necessary, and are split into 4 types - Transcode CPU/GPU and Health Check CPU/GPU. Worker limits can be managed by the scheduler as well as manually. For a desktop application with similar functionality please see HBBatchBeast . Cross-platform Tdarr Nodes which work together with Tdarr Server to process your files GPU and CPU workers Use/create Tdarr Plugins for infinite control on how your files are processed: https://github.com/HaveAGitGat/Tdarr_Plugins Audio and video library management 7 day, 24 hour scheduler Folder watcher Worker stall detector Load balancing between libraries/drives Use HandBrake or FFmpeg Tested on a 1,000,000 file dummy library Search for files based on hundreds of properties Library stats Hardware transcoding container (install Nvidia plugin on unRAID/Nvidia runtime container on Ubuntu) Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Tdarr"},{"location":"apps/encoder/tdarr.html#tdarr-v2-distributed-transcoding-system","text":"Audio/Video Library Analytics & Transcode/Remux Automation FFmpeg/HandBrake + video health checking (Windows, macOS, Linux & Docker)","title":"Tdarr V2: Distributed Transcoding System"},{"location":"apps/encoder/tdarr.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/kasmworkspace/kasmdesktop.html","text":"KASM Desktop \u00b6 INTRODUCTION \u00b6 Kasm Workspaces - The Container Streaming Platform Streaming containerized apps and desktops to end-users. The Workspaces platform provides enterprise-class orchestration, data loss prevention, and web streaming technology to enable the delivery of containerized workloads to your browser. For more in-depth information about KASM, visit: https://www.kasmweb.com/ Kasm Desktop Provides Ubuntu Desktop with all available applications from KASM included. Individual apps are also available via DockServer Menu under kasmworkspaces . This container allows you to choose the applications you would like to use. For example, if you want to access a specific website that may be blocked by company fire walls. Install via DockServer Menu Default User: admin@kasm.local user@kasm.local Default Pass: this is setup when you go to http://serverip:3002/ on first boot to setup. Note: If you need to use more varirables such as making persistent profiles, adding GPUs, or gaming controllers, please see LSIO Documentation https://github.com/linuxserver/docker-kasm#application-setup Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Kasmdesktop"},{"location":"apps/kasmworkspace/kasmdesktop.html#kasm-desktop","text":"","title":"KASM Desktop"},{"location":"apps/kasmworkspace/kasmdesktop.html#introduction","text":"Kasm Workspaces - The Container Streaming Platform Streaming containerized apps and desktops to end-users. The Workspaces platform provides enterprise-class orchestration, data loss prevention, and web streaming technology to enable the delivery of containerized workloads to your browser. For more in-depth information about KASM, visit: https://www.kasmweb.com/ Kasm Desktop Provides Ubuntu Desktop with all available applications from KASM included. Individual apps are also available via DockServer Menu under kasmworkspaces . This container allows you to choose the applications you would like to use. For example, if you want to access a specific website that may be blocked by company fire walls. Install via DockServer Menu Default User: admin@kasm.local user@kasm.local Default Pass: this is setup when you go to http://serverip:3002/ on first boot to setup. Note: If you need to use more varirables such as making persistent profiles, adding GPUs, or gaming controllers, please see LSIO Documentation https://github.com/linuxserver/docker-kasm#application-setup","title":"INTRODUCTION"},{"location":"apps/kasmworkspace/kasmdesktop.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/bazarr.html","text":"Bazarr \u00b6 A good client for finding subtitles for your stuff. This needs to be configured from bottom up, and an anti-captcha account is recommended but not mandatory In order to get autoscan on picking up subs you can use this under \"Custom post processing\" curl -sG -X POST -u username:password --data-urlencode \"dir={{directory}}\" http://autoscan:3030/triggers/manual Here is a heatmap that the devs on bazarr made. Great inspiration if you're looking into which indexers to choose Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Bazarr"},{"location":"apps/mediamanager/bazarr.html#bazarr","text":"A good client for finding subtitles for your stuff. This needs to be configured from bottom up, and an anti-captcha account is recommended but not mandatory In order to get autoscan on picking up subs you can use this under \"Custom post processing\" curl -sG -X POST -u username:password --data-urlencode \"dir={{directory}}\" http://autoscan:3030/triggers/manual Here is a heatmap that the devs on bazarr made. Great inspiration if you're looking into which indexers to choose","title":"Bazarr"},{"location":"apps/mediamanager/bazarr.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/calibre-web.html","text":"Calibre-Web \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Calibre-WEB"},{"location":"apps/mediamanager/calibre-web.html#calibre-web","text":"Wiki Coming Soon .....","title":"Calibre-Web"},{"location":"apps/mediamanager/calibre-web.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/embystats.html","text":"Emby Stats \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Embystats"},{"location":"apps/mediamanager/embystats.html#emby-stats","text":"Wiki Coming Soon .....","title":"Emby Stats"},{"location":"apps/mediamanager/embystats.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/lazylibrarian.html","text":"LazyLabrarian \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Lazylibrarian"},{"location":"apps/mediamanager/lazylibrarian.html#lazylabrarian","text":"Wiki Coming Soon .....","title":"LazyLabrarian"},{"location":"apps/mediamanager/lazylibrarian.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/lidarr.html","text":"Lidarr \u00b6 Lidarr is a music collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new tracks from your favorite artists and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available. Major Features Include: \u00b6 Support for major platforms: Windows, Linux, macOS, Raspberry Pi, etc. Automatically detects new tracks. Can scan your existing library and download any missing tracks. Can watch for better quality of the tracks you already have and do an automatic upgrade. Automatic failed download handling will try another release if one fails Manual search so you can pick any release or to see why a release was not downloaded automatically Fully configurable track renaming Full integration with SABnzbd and NZBGet Full integration with Kodi, Plex (notification, library update, metadata) Full support for specials and multi-album releases And a beautiful UI Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Lidarr"},{"location":"apps/mediamanager/lidarr.html#lidarr","text":"Lidarr is a music collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new tracks from your favorite artists and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.","title":"Lidarr"},{"location":"apps/mediamanager/lidarr.html#major-features-include","text":"Support for major platforms: Windows, Linux, macOS, Raspberry Pi, etc. Automatically detects new tracks. Can scan your existing library and download any missing tracks. Can watch for better quality of the tracks you already have and do an automatic upgrade. Automatic failed download handling will try another release if one fails Manual search so you can pick any release or to see why a release was not downloaded automatically Fully configurable track renaming Full integration with SABnzbd and NZBGet Full integration with Kodi, Plex (notification, library update, metadata) Full support for specials and multi-album releases And a beautiful UI","title":"Major Features Include:"},{"location":"apps/mediamanager/lidarr.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/plex-utills.html","text":"Plex-Utills \u00b6 MASSIVE UPDATE! \u00b6 The whole app now runs in a webui. This should make things easier for those who are not as comfortable in the commandline or just prefer a ui. I have also removed a couple of the config elements, namely, the PLEXPATH and MOUNTEDPATH options. These are now handled directly by the application and Docker. When you pass through you plex media directory, the app will automatically map this and find your plex path to make the config easier. Now as long as the container has write access to the media directory, it should make enabling the backup posters much easier. There is an option to automatically migrate your old config files into the new ui for easier migration. New HDR banners along with a script to migrate from the old banners to the new ones should you wish to use them. You can stick with the old banners if you would like. The new scripts us TheMoviedb for finidng posters and metadata, so for maximum compatability and fewer issues, these work best when using TheMoviedb as your metadata agent. Throughout my testing, it is only sequals that were giving me issues, as the Plex scanner will name your films like: Boss Baby 2: Family Business Whereas on TheMoviedb it is named: Boss Baby: Family Business This means that the search for the film can fail in the script. New Features: \u00b6 GUI for managing the application in a browser Add 4k mini banners to your 4K TV episodes. New HDR banner design Dolby Vision HDR Banner HDR10 Banner Migration scripts for moving from the old config files to the new database and for moving from the old HDR banner to the new designs. Features \u00b6 4K/HDR Posters \u00b6 This script will go through your library and add a 4k banner to your posters. Configurable options include: Selecting full width banners or mini corner banners enabling HDR banners Backup your original posters alongside your media This can be run on both your films library and your TV shows Library. If enabled on your TV shows, a mini 4K banner will be added to each of your 4K epiisodes, not the season posters. This is due to the possibility of having Shows/Seasons with mixed resolutions. TV shows will be done at the same time as film posters. 3D Posters \u00b6 Much like the 4K poster script, this will go through your films and add a 3D banner to your films. Currently as Plex has no support for labelling content as 3D this will only work for 3D films kept in a separate library. You can configure the script to have full width banners or the mini corner banners as well as backing up your posters. Available Banners \u00b6 The 4K/3D banners will be combined with the HDR posters if they are enabled. \u00b6 Hide 4K \u00b6 For those of you who don't separate your 4K and non-4K content into separate libraries. This script will go through your films library and add an \"Untranscodable\" tag to any of your films that only have a single 4K copy of the film available. By adding this tag to your users restrictions, they simply won't see these 4K films giving your hardware a break. If your hardware is powerful enough, there is the option to create an optimized version so that your users can play this version. This will send your film to be optimized with the Plex optimize feature baked directly into Plex. This means all the hardwork is done by your plex server, (useful if you're hosting these scripts on a lower powered device.) Once the transcode has finished, the untranscodable tag will be removed the next time the script runs and your users will be able to see the film. Disney Collection \u00b6 Where this whole project started. A simple script, that will go through your films library and add any film from the Disney Studio into a Disney collection. Pixar Collection \u00b6 As above only with Pixar Films Requirements \u00b6 A Plex Media Server How to Install \u00b6 Install Plex-Utills from Docksever Mediamanager Menu. Follow the configuration instuctions during Setup. Wiki Maintainer \u00b6 @FSCorrupt Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Plex-Utills"},{"location":"apps/mediamanager/plex-utills.html#plex-utills","text":"","title":"Plex-Utills"},{"location":"apps/mediamanager/plex-utills.html#massive-update","text":"The whole app now runs in a webui. This should make things easier for those who are not as comfortable in the commandline or just prefer a ui. I have also removed a couple of the config elements, namely, the PLEXPATH and MOUNTEDPATH options. These are now handled directly by the application and Docker. When you pass through you plex media directory, the app will automatically map this and find your plex path to make the config easier. Now as long as the container has write access to the media directory, it should make enabling the backup posters much easier. There is an option to automatically migrate your old config files into the new ui for easier migration. New HDR banners along with a script to migrate from the old banners to the new ones should you wish to use them. You can stick with the old banners if you would like. The new scripts us TheMoviedb for finidng posters and metadata, so for maximum compatability and fewer issues, these work best when using TheMoviedb as your metadata agent. Throughout my testing, it is only sequals that were giving me issues, as the Plex scanner will name your films like: Boss Baby 2: Family Business Whereas on TheMoviedb it is named: Boss Baby: Family Business This means that the search for the film can fail in the script.","title":"MASSIVE UPDATE!"},{"location":"apps/mediamanager/plex-utills.html#new-features","text":"GUI for managing the application in a browser Add 4k mini banners to your 4K TV episodes. New HDR banner design Dolby Vision HDR Banner HDR10 Banner Migration scripts for moving from the old config files to the new database and for moving from the old HDR banner to the new designs.","title":"New Features:"},{"location":"apps/mediamanager/plex-utills.html#features","text":"","title":"Features"},{"location":"apps/mediamanager/plex-utills.html#4khdr-posters","text":"This script will go through your library and add a 4k banner to your posters. Configurable options include: Selecting full width banners or mini corner banners enabling HDR banners Backup your original posters alongside your media This can be run on both your films library and your TV shows Library. If enabled on your TV shows, a mini 4K banner will be added to each of your 4K epiisodes, not the season posters. This is due to the possibility of having Shows/Seasons with mixed resolutions. TV shows will be done at the same time as film posters.","title":"4K/HDR Posters"},{"location":"apps/mediamanager/plex-utills.html#3d-posters","text":"Much like the 4K poster script, this will go through your films and add a 3D banner to your films. Currently as Plex has no support for labelling content as 3D this will only work for 3D films kept in a separate library. You can configure the script to have full width banners or the mini corner banners as well as backing up your posters.","title":"3D Posters"},{"location":"apps/mediamanager/plex-utills.html#available-banners","text":"","title":"Available Banners"},{"location":"apps/mediamanager/plex-utills.html#the-4k3d-banners-will-be-combined-with-the-hdr-posters-if-they-are-enabled","text":"","title":"The 4K/3D banners will be combined with the HDR posters if they are enabled."},{"location":"apps/mediamanager/plex-utills.html#hide-4k","text":"For those of you who don't separate your 4K and non-4K content into separate libraries. This script will go through your films library and add an \"Untranscodable\" tag to any of your films that only have a single 4K copy of the film available. By adding this tag to your users restrictions, they simply won't see these 4K films giving your hardware a break. If your hardware is powerful enough, there is the option to create an optimized version so that your users can play this version. This will send your film to be optimized with the Plex optimize feature baked directly into Plex. This means all the hardwork is done by your plex server, (useful if you're hosting these scripts on a lower powered device.) Once the transcode has finished, the untranscodable tag will be removed the next time the script runs and your users will be able to see the film.","title":"Hide 4K"},{"location":"apps/mediamanager/plex-utills.html#disney-collection","text":"Where this whole project started. A simple script, that will go through your films library and add any film from the Disney Studio into a Disney collection.","title":"Disney Collection"},{"location":"apps/mediamanager/plex-utills.html#pixar-collection","text":"As above only with Pixar Films","title":"Pixar Collection"},{"location":"apps/mediamanager/plex-utills.html#requirements","text":"A Plex Media Server","title":"Requirements"},{"location":"apps/mediamanager/plex-utills.html#how-to-install","text":"Install Plex-Utills from Docksever Mediamanager Menu. Follow the configuration instuctions during Setup.","title":"How to Install"},{"location":"apps/mediamanager/plex-utills.html#wiki-maintainer","text":"@FSCorrupt","title":"Wiki Maintainer"},{"location":"apps/mediamanager/plex-utills.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/prowlarr.html","text":"Prowlarr \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Prowlarr"},{"location":"apps/mediamanager/prowlarr.html#prowlarr","text":"Wiki Coming Soon .....","title":"Prowlarr"},{"location":"apps/mediamanager/prowlarr.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/radarr.html","text":"Radarr \u00b6 Radarr is a movie collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new movies and will interface with clients and indexers to grab, sort, and rename them. It can also be configured to automatically upgrade the quality of existing files in the library when a better quality format becomes available. Major Features Include: \u00b6 Adding new movies with lots of information, such as trailers, ratings, etc. Support for major platforms: Windows, Linux, macOS, Raspberry Pi, etc. Can watch for better quality of the movies you have and do an automatic upgrade. eg. from DVD to Blu-Ray Automatic failed download handling will try another release if one fails Manual search so you can pick any release or to see why a release was not downloaded automatically Full integration with SABnzbd and NZBGet Automatically searching for releases as well as RSS Sync Automatically importing downloaded movies Recognizing Special Editions, Director's Cut, etc. Identifying releases with hardcoded subs QBittorrent, Deluge, rTorrent, Transmission, uTorrent, and other download clients are supported Full integration with Kodi, Plex (notification, library update) A beautiful UI Importing Metadata such as trailers or subtitles Adding metadata such as posters and information for Kodi and others to use Advanced customization for profiles, such that Radarr will always download the copy you want Support \u00b6 Note: GitHub Issues are for Bugs and Feature Requests Only Feature Requests \u00b6 Feature Requests Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Radarr"},{"location":"apps/mediamanager/radarr.html#radarr","text":"Radarr is a movie collection manager for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new movies and will interface with clients and indexers to grab, sort, and rename them. It can also be configured to automatically upgrade the quality of existing files in the library when a better quality format becomes available.","title":"Radarr"},{"location":"apps/mediamanager/radarr.html#major-features-include","text":"Adding new movies with lots of information, such as trailers, ratings, etc. Support for major platforms: Windows, Linux, macOS, Raspberry Pi, etc. Can watch for better quality of the movies you have and do an automatic upgrade. eg. from DVD to Blu-Ray Automatic failed download handling will try another release if one fails Manual search so you can pick any release or to see why a release was not downloaded automatically Full integration with SABnzbd and NZBGet Automatically searching for releases as well as RSS Sync Automatically importing downloaded movies Recognizing Special Editions, Director's Cut, etc. Identifying releases with hardcoded subs QBittorrent, Deluge, rTorrent, Transmission, uTorrent, and other download clients are supported Full integration with Kodi, Plex (notification, library update) A beautiful UI Importing Metadata such as trailers or subtitles Adding metadata such as posters and information for Kodi and others to use Advanced customization for profiles, such that Radarr will always download the copy you want","title":"Major Features Include:"},{"location":"apps/mediamanager/radarr.html#support","text":"Note: GitHub Issues are for Bugs and Feature Requests Only","title":"Support"},{"location":"apps/mediamanager/radarr.html#feature-requests","text":"Feature Requests","title":"Feature Requests"},{"location":"apps/mediamanager/radarr.html#support_1","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/readarr.html","text":"Readarr \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Readarr"},{"location":"apps/mediamanager/readarr.html#readarr","text":"Wiki Coming Soon .....","title":"Readarr"},{"location":"apps/mediamanager/readarr.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/sonarr.html","text":"Sonarr \u00b6 Sonarr is a PVR for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new episodes of your favorite shows and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available. Support \u00b6 Note: GitHub Issues are for Bugs and Feature Requests Only Forums Discord GitHub - Bugs and Feature Requests Only IRC Reddit Wiki Features \u00b6 Current Features \u00b6 Support for major platforms: Windows, Linux, macOS, Raspberry Pi, etc. Automatically detects new episodes Can scan your existing library and download any missing episodes Can watch for better quality of the episodes you already have and do an automatic upgrade. eg. from DVD to Blu-Ray Automatic failed download handling will try another release if one fails Manual search so you can pick any release or to see why a release was not downloaded automatically Fully configurable episode renaming Full integration with SABnzbd and NZBGet Full integration with Kodi, Plex (notification, library update, metadata) Full support for specials and multi-episode releases And a beautiful UI Getting Started \u00b6 FAQ Wiki (WIP) API Documentation Donate Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Sonarr"},{"location":"apps/mediamanager/sonarr.html#sonarr","text":"Sonarr is a PVR for Usenet and BitTorrent users. It can monitor multiple RSS feeds for new episodes of your favorite shows and will grab, sort and rename them. It can also be configured to automatically upgrade the quality of files already downloaded when a better quality format becomes available.","title":"Sonarr"},{"location":"apps/mediamanager/sonarr.html#support","text":"Note: GitHub Issues are for Bugs and Feature Requests Only Forums Discord GitHub - Bugs and Feature Requests Only IRC Reddit Wiki","title":"Support"},{"location":"apps/mediamanager/sonarr.html#features","text":"","title":"Features"},{"location":"apps/mediamanager/sonarr.html#current-features","text":"Support for major platforms: Windows, Linux, macOS, Raspberry Pi, etc. Automatically detects new episodes Can scan your existing library and download any missing episodes Can watch for better quality of the episodes you already have and do an automatic upgrade. eg. from DVD to Blu-Ray Automatic failed download handling will try another release if one fails Manual search so you can pick any release or to see why a release was not downloaded automatically Fully configurable episode renaming Full integration with SABnzbd and NZBGet Full integration with Kodi, Plex (notification, library update, metadata) Full support for specials and multi-episode releases And a beautiful UI","title":"Current Features"},{"location":"apps/mediamanager/sonarr.html#getting-started","text":"FAQ Wiki (WIP) API Documentation Donate","title":"Getting Started"},{"location":"apps/mediamanager/sonarr.html#support_1","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/tautulli.html","text":"Tautulli \u00b6 A python based web application for monitoring, analytics and notifications for Plex Media Server . This project is based on code from Headphones and PlexWatchWeb . Features \u00b6 Responsive web design viewable on desktop, tablet and mobile web browsers. Themed to complement Plex/Web. Easy configuration setup (no separate web server required). Monitor current Plex Media Server activity. Fully customizable notifications for stream activity and recently added media. Top statistics on home page with configurable duration and measurement metric. Global watching history with search/filtering & dynamic column sorting. Full user list with general information and comparison stats. Individual user information including devices IP addresses. Complete library statistics and media file information. Rich analytics presented using Highcharts graphing. Beautiful content information pages. Full sync list data on all users syncing items from your library. And many more!! Preview \u00b6 [Full preview gallery available on our website][tautulli] https://github.com/Tautulli/Tautulli/wiki Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Tautulli"},{"location":"apps/mediamanager/tautulli.html#tautulli","text":"A python based web application for monitoring, analytics and notifications for Plex Media Server . This project is based on code from Headphones and PlexWatchWeb .","title":"Tautulli"},{"location":"apps/mediamanager/tautulli.html#features","text":"Responsive web design viewable on desktop, tablet and mobile web browsers. Themed to complement Plex/Web. Easy configuration setup (no separate web server required). Monitor current Plex Media Server activity. Fully customizable notifications for stream activity and recently added media. Top statistics on home page with configurable duration and measurement metric. Global watching history with search/filtering & dynamic column sorting. Full user list with general information and comparison stats. Individual user information including devices IP addresses. Complete library statistics and media file information. Rich analytics presented using Highcharts graphing. Beautiful content information pages. Full sync list data on all users syncing items from your library. And many more!!","title":"Features"},{"location":"apps/mediamanager/tautulli.html#preview","text":"[Full preview gallery available on our website][tautulli] https://github.com/Tautulli/Tautulli/wiki","title":"Preview"},{"location":"apps/mediamanager/tautulli.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/traktarr.html","text":"Traktarr \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Traktarr"},{"location":"apps/mediamanager/traktarr.html#traktarr","text":"Wiki Coming Soon .....","title":"Traktarr"},{"location":"apps/mediamanager/traktarr.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediamanager/xteve.html","text":"xTeve \u00b6 xTeve is a M3U Proxy for Plex DVR and Emby Live TV use ( http://xteve:34400 ) for in-app communication Install Notes: \u00b6 Access interface will be published on https://xteve.domain.com/web - Accessing xteve.domain.com will throw an XML error Settings to edit in xTeve: \u00b6 -Playlist (add yours) -EPG source (unless you use the one in Plex) -Settings -> Buffer -> Xteve -> Buffer size 8MB When setting it up in plex: -Add xteve:34400 as tuner -If you want to use the EPG from XTEVE (XEPG) the link you set in Plex must be http://xteve:34400/xmltv/xteve.xml Protip: Manage,modulate and shorten your m3u link on www.m3u4u.com - They also have an excellent EPG & Playlist editor \u00b6 Best Practice for Plex/Xteve: \u00b6 The output from your provider MUST be MPEG-TS(.ts) - make sure that this is set both at your provider and at m3u4u.com. Otherwise plex will drop the streams when the framerates drop in the streams. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Xteve"},{"location":"apps/mediamanager/xteve.html#xteve","text":"xTeve is a M3U Proxy for Plex DVR and Emby Live TV use ( http://xteve:34400 ) for in-app communication","title":"xTeve"},{"location":"apps/mediamanager/xteve.html#install-notes","text":"Access interface will be published on https://xteve.domain.com/web - Accessing xteve.domain.com will throw an XML error","title":"Install Notes:"},{"location":"apps/mediamanager/xteve.html#settings-to-edit-in-xteve","text":"-Playlist (add yours) -EPG source (unless you use the one in Plex) -Settings -> Buffer -> Xteve -> Buffer size 8MB When setting it up in plex: -Add xteve:34400 as tuner -If you want to use the EPG from XTEVE (XEPG) the link you set in Plex must be http://xteve:34400/xmltv/xteve.xml Protip: Manage,modulate and shorten your m3u link on www.m3u4u.com - They also have an excellent EPG & Playlist editor","title":"Settings to edit in xTeve:"},{"location":"apps/mediamanager/xteve.html#_1","text":"","title":""},{"location":"apps/mediamanager/xteve.html#best-practice-for-plexxteve","text":"The output from your provider MUST be MPEG-TS(.ts) - make sure that this is set both at your provider and at m3u4u.com. Otherwise plex will drop the streams when the framerates drop in the streams.","title":"Best Practice for Plex/Xteve:"},{"location":"apps/mediamanager/xteve.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediaserver/emby.html","text":"Emby \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Emby"},{"location":"apps/mediaserver/emby.html#emby","text":"Wiki Coming Soon .....","title":"Emby"},{"location":"apps/mediaserver/emby.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediaserver/jellyfin.html","text":"Jellyfin \u00b6 The Free Software Media System Jellyfin is a Free Software Media System that puts you in control of managing and streaming your media. It is an alternative to the proprietary Emby and Plex, to provide media from a dedicated server to end-user devices via multiple apps. Jellyfin is descended from Emby's 3.5.2 release and ported to the .NET Core framework to enable full cross-platform support. There are no strings attached, no premium licenses or features, and no hidden agendas: just a team who want to build something better and work together to achieve it. We welcome anyone who is interested in joining us in our quest! Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Jellyfin"},{"location":"apps/mediaserver/jellyfin.html#jellyfin","text":"The Free Software Media System Jellyfin is a Free Software Media System that puts you in control of managing and streaming your media. It is an alternative to the proprietary Emby and Plex, to provide media from a dedicated server to end-user devices via multiple apps. Jellyfin is descended from Emby's 3.5.2 release and ported to the .NET Core framework to enable full cross-platform support. There are no strings attached, no premium licenses or features, and no hidden agendas: just a team who want to build something better and work together to achieve it. We welcome anyone who is interested in joining us in our quest!","title":"Jellyfin"},{"location":"apps/mediaserver/jellyfin.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediaserver/mstream.html","text":"Mstream \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"MStream"},{"location":"apps/mediaserver/mstream.html#mstream","text":"Wiki Coming Soon .....","title":"Mstream"},{"location":"apps/mediaserver/mstream.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/mediaserver/plex.html","text":"PLEX MEDIA SERVER \u00b6 INTRODUCTION \u00b6 Plex gives you one place to find and access all the media that matters to you. From personal media on your own server, to free and on-demand Movies & Shows, live TV, podcasts, and web shows, to streaming music, you can enjoy it all in one app, on any device. And, it\u2019s really simple to start using\u2026 First, if you are streaming only third-party content (Movies & Shows, live TV, podcasts, web shows, TIDAL music), then you are good to go as soon as you have an account, just install an app on your phone, Smart TV, computer, or simply open up our web app on your browser! Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Plex"},{"location":"apps/mediaserver/plex.html#plex-media-server","text":"","title":"PLEX MEDIA SERVER"},{"location":"apps/mediaserver/plex.html#introduction","text":"Plex gives you one place to find and access all the media that matters to you. From personal media on your own server, to free and on-demand Movies & Shows, live TV, podcasts, and web shows, to streaming music, you can enjoy it all in one app, on any device. And, it\u2019s really simple to start using\u2026 First, if you are streaming only third-party content (Movies & Shows, live TV, podcasts, web shows, TIDAL music), then you are good to go as soon as you have an account, just install an app on your phone, Smart TV, computer, or simply open up our web app on your browser!","title":"INTRODUCTION"},{"location":"apps/mediaserver/plex.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/request/conreq.html","text":"Conreq Beta \u00b6 Conreq, a content requesting platform. Want to join the community or have a question? Join us on Discord , discuss on GitHub Discussions , or see our planned features and roadmap on GitHub Projects ! Looking for more info? Are you a developer and want to contribute? Check out our Documentation ! Installation (Production Environment) \u00b6 Install through Unraid Community Applications , or Hotio / SelfHosters Docker . Here's a list of all available environment variables: # General Settings TZ = \"America/Los_Angeles\" # default: UTC (Timezone for log files, in \"TZ Database\" format) BASE_URL = \"requests\" # default: None APP_NAME = \"RequestCentral\" # default: Conreq APP_DESCRIPTION = \"Get yo stuff!\" # default: Content Requesting ARR_REFRESH_INTERNAL = \"*/15\" # default: */1 (Cron minutes for Sonarr/Radarr library refresh) # Data Storage DATA_DIR = \"/example/directory\" # default: /config (Defaults to \"data\" outside of docker) DB_ENGINE = \"MYSQL\" # default: SQLITE3 MYSQL_CONFIG_FILE = \"/config/mysql.cnf\" # default: None # Security SSL_SECURITY = \"True\" # default: False (True enables advanced SSL security features) PWNED_VALIDATOR = \"False\" # default: True (False disables checking for compromised passwords) X_FRAME_OPTIONS = \"SAMEORIGIN\" # default: DENY (False disables X-Frame-Options) ALLOWED_HOST = \"192.168.0.199\" # default: * (Allows all hosts) DEBUG = False # default: False (Disable security features, only enable this during development. Defaults to True outside of docker.) # Email EMAIL_USE_TLS = \"False\" # default: True EMAIL_PORT = \"465\" # default: 587 EMAIL_HOST = \"smtp-mail.outlook.com\" # default: smtp.gmail.com EMAIL_HOST_USER = \"myself@outlook.com\" # default: None EMAIL_HOST_PASSWORD = \"dogmemes123\" # default: None Screenshots \u00b6 Discover (Desktop) More Info (Desktop) Episode Selection Modal (Desktop) Filter Modal (Desktop) Preview Modal (Desktop) Sign In (Desktop) Discover (Mobile) More Info (Mobile) Episode Selection Modal (Mobile) Filter Modal (Mobile) Registration (Mobile) Sign In (Mobile) Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Conreq"},{"location":"apps/request/conreq.html#conreq-beta","text":"Conreq, a content requesting platform. Want to join the community or have a question? Join us on Discord , discuss on GitHub Discussions , or see our planned features and roadmap on GitHub Projects ! Looking for more info? Are you a developer and want to contribute? Check out our Documentation !","title":"Conreq Beta"},{"location":"apps/request/conreq.html#installation-production-environment","text":"Install through Unraid Community Applications , or Hotio / SelfHosters Docker . Here's a list of all available environment variables: # General Settings TZ = \"America/Los_Angeles\" # default: UTC (Timezone for log files, in \"TZ Database\" format) BASE_URL = \"requests\" # default: None APP_NAME = \"RequestCentral\" # default: Conreq APP_DESCRIPTION = \"Get yo stuff!\" # default: Content Requesting ARR_REFRESH_INTERNAL = \"*/15\" # default: */1 (Cron minutes for Sonarr/Radarr library refresh) # Data Storage DATA_DIR = \"/example/directory\" # default: /config (Defaults to \"data\" outside of docker) DB_ENGINE = \"MYSQL\" # default: SQLITE3 MYSQL_CONFIG_FILE = \"/config/mysql.cnf\" # default: None # Security SSL_SECURITY = \"True\" # default: False (True enables advanced SSL security features) PWNED_VALIDATOR = \"False\" # default: True (False disables checking for compromised passwords) X_FRAME_OPTIONS = \"SAMEORIGIN\" # default: DENY (False disables X-Frame-Options) ALLOWED_HOST = \"192.168.0.199\" # default: * (Allows all hosts) DEBUG = False # default: False (Disable security features, only enable this during development. Defaults to True outside of docker.) # Email EMAIL_USE_TLS = \"False\" # default: True EMAIL_PORT = \"465\" # default: 587 EMAIL_HOST = \"smtp-mail.outlook.com\" # default: smtp.gmail.com EMAIL_HOST_USER = \"myself@outlook.com\" # default: None EMAIL_HOST_PASSWORD = \"dogmemes123\" # default: None","title":"Installation (Production Environment)"},{"location":"apps/request/conreq.html#screenshots","text":"Discover (Desktop) More Info (Desktop) Episode Selection Modal (Desktop) Filter Modal (Desktop) Preview Modal (Desktop) Sign In (Desktop) Discover (Mobile) More Info (Mobile) Episode Selection Modal (Mobile) Filter Modal (Mobile) Registration (Mobile) Sign In (Mobile)","title":"Screenshots"},{"location":"apps/request/conreq.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/request/overseerr.html","text":"Overseerr \u00b6 Overseerr is a free and open source software application for managing requests for your media library. It integrates with your existing services, such as Sonarr , Radarr , and Plex ! Current Features \u00b6 Full Plex integration. Authenticate and manage user access with Plex! Easy integration with your existing services. Currently, Overseerr supports Sonarr and Radarr. More to come! Plex library scan, to keep track of the titles which are already available. Customizable request system, which allows users to request individual seasons or movies in a friendly, easy-to-use interface. Incredibly simple request management UI. Don't dig through the app to simply approve recent requests! Granular permission system. Support for various notification agents. Mobile-friendly design, for when you need to approve requests on the go! Preview \u00b6 Support \u00b6 Check out the Overseerr Documentation before asking for help. Your question might already be in the FAQ . You can get support on Discord . You can ask questions in the Help category of our GitHub Discussions . Bug reports and feature requests can be submitted via GitHub Issues . Support by Dockserver \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Overseerr"},{"location":"apps/request/overseerr.html#overseerr","text":"Overseerr is a free and open source software application for managing requests for your media library. It integrates with your existing services, such as Sonarr , Radarr , and Plex !","title":"Overseerr"},{"location":"apps/request/overseerr.html#current-features","text":"Full Plex integration. Authenticate and manage user access with Plex! Easy integration with your existing services. Currently, Overseerr supports Sonarr and Radarr. More to come! Plex library scan, to keep track of the titles which are already available. Customizable request system, which allows users to request individual seasons or movies in a friendly, easy-to-use interface. Incredibly simple request management UI. Don't dig through the app to simply approve recent requests! Granular permission system. Support for various notification agents. Mobile-friendly design, for when you need to approve requests on the go!","title":"Current Features"},{"location":"apps/request/overseerr.html#preview","text":"","title":"Preview"},{"location":"apps/request/overseerr.html#support","text":"Check out the Overseerr Documentation before asking for help. Your question might already be in the FAQ . You can get support on Discord . You can ask questions in the Help category of our GitHub Discussions . Bug reports and feature requests can be submitted via GitHub Issues .","title":"Support"},{"location":"apps/request/overseerr.html#support-by-dockserver","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support by Dockserver"},{"location":"apps/request/petio.html","text":"Petio \u00b6 Request, review and discover companion app for plex. Allow your users to interact with media both on and off your server with this app. Available as a docker image and also as binaries. Features a React frontend utilizing Redux and a Node JS express API and MongoDb database. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Petio"},{"location":"apps/request/petio.html#petio","text":"Request, review and discover companion app for plex. Allow your users to interact with media both on and off your server with this app. Available as a docker image and also as binaries. Features a React frontend utilizing Redux and a Node JS express API and MongoDb database.","title":"Petio"},{"location":"apps/request/petio.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/alltube.html","text":"Alltube \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Alltube"},{"location":"apps/selfhosted/alltube.html#alltube","text":"Wiki Coming Soon .....","title":"Alltube"},{"location":"apps/selfhosted/alltube.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/bitwarden.html","text":"Bitwarden \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Bitwarden"},{"location":"apps/selfhosted/bitwarden.html#bitwarden","text":"Wiki Coming Soon .....","title":"Bitwarden"},{"location":"apps/selfhosted/bitwarden.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/bliss.html","text":"Bliss \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Bliss"},{"location":"apps/selfhosted/bliss.html#bliss","text":"Wiki Coming Soon .....","title":"Bliss"},{"location":"apps/selfhosted/bliss.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/changedetection.html","text":"Change-Detection \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Changedetection"},{"location":"apps/selfhosted/changedetection.html#change-detection","text":"Wiki Coming Soon .....","title":"Change-Detection"},{"location":"apps/selfhosted/changedetection.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/cloudbeaver.html","text":"Cloudbeaver \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Cloudbeaver"},{"location":"apps/selfhosted/cloudbeaver.html#cloudbeaver","text":"Wiki Coming Soon .....","title":"Cloudbeaver"},{"location":"apps/selfhosted/cloudbeaver.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/comixed.html","text":"Comixed \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Conmixed"},{"location":"apps/selfhosted/comixed.html#comixed","text":"Wiki Coming Soon .....","title":"Comixed"},{"location":"apps/selfhosted/comixed.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/crewlink.html","text":"Crewlink \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Crewlink"},{"location":"apps/selfhosted/crewlink.html#crewlink","text":"Wiki Coming Soon .....","title":"Crewlink"},{"location":"apps/selfhosted/crewlink.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/freshrss.html","text":"FreshRSS \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"FreshRSS"},{"location":"apps/selfhosted/freshrss.html#freshrss","text":"Wiki Coming Soon .....","title":"FreshRSS"},{"location":"apps/selfhosted/freshrss.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/gotify.html","text":"Gotify \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Gotify"},{"location":"apps/selfhosted/gotify.html#gotify","text":"Wiki Coming Soon .....","title":"Gotify"},{"location":"apps/selfhosted/gotify.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/homeassistant.html","text":"Home-Assistant \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Homeassistant"},{"location":"apps/selfhosted/homeassistant.html#home-assistant","text":"Wiki Coming Soon .....","title":"Home-Assistant"},{"location":"apps/selfhosted/homeassistant.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/iobroker.html","text":"IOBroker \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"IObroker"},{"location":"apps/selfhosted/iobroker.html#iobroker","text":"Wiki Coming Soon .....","title":"IOBroker"},{"location":"apps/selfhosted/iobroker.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/joplin-server.html","text":"Joplin-Server \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Joplin-server"},{"location":"apps/selfhosted/joplin-server.html#joplin-server","text":"Wiki Coming Soon .....","title":"Joplin-Server"},{"location":"apps/selfhosted/joplin-server.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/moviematch.html","text":"MovieMatch \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Moviematch"},{"location":"apps/selfhosted/moviematch.html#moviematch","text":"Wiki Coming Soon .....","title":"MovieMatch"},{"location":"apps/selfhosted/moviematch.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/netbox.html","text":"NetBox \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Netbox"},{"location":"apps/selfhosted/netbox.html#netbox","text":"Wiki Coming Soon .....","title":"NetBox"},{"location":"apps/selfhosted/netbox.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/nowshowing.html","text":"NowShowing \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Nowshowing"},{"location":"apps/selfhosted/nowshowing.html#nowshowing","text":"Wiki Coming Soon .....","title":"NowShowing"},{"location":"apps/selfhosted/nowshowing.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/organizr.html","text":"Organizr \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Organizr"},{"location":"apps/selfhosted/organizr.html#organizr","text":"Wiki Coming Soon .....","title":"Organizr"},{"location":"apps/selfhosted/organizr.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/pihole.html","text":"PIhole \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"PiHole"},{"location":"apps/selfhosted/pihole.html#pihole","text":"Wiki Coming Soon .....","title":"PIhole"},{"location":"apps/selfhosted/pihole.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/recipes.html","text":"Recipes \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Recipes"},{"location":"apps/selfhosted/recipes.html#recipes","text":"Wiki Coming Soon .....","title":"Recipes"},{"location":"apps/selfhosted/recipes.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/snapdrop.html","text":"Snapdrop \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Snapdrop"},{"location":"apps/selfhosted/snapdrop.html#snapdrop","text":"Wiki Coming Soon .....","title":"Snapdrop"},{"location":"apps/selfhosted/snapdrop.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/teamspeak.html","text":"TeamSpeak \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Teamspeak"},{"location":"apps/selfhosted/teamspeak.html#teamspeak","text":"Wiki Coming Soon .....","title":"TeamSpeak"},{"location":"apps/selfhosted/teamspeak.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/unifi-controller.html","text":"Unify-Controller \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Unifi-Controller"},{"location":"apps/selfhosted/unifi-controller.html#unify-controller","text":"Wiki Coming Soon .....","title":"Unify-Controller"},{"location":"apps/selfhosted/unifi-controller.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/whoogle.html","text":"Whoogle \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Whoogle"},{"location":"apps/selfhosted/whoogle.html#whoogle","text":"Wiki Coming Soon .....","title":"Whoogle"},{"location":"apps/selfhosted/whoogle.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/wireguard.html","text":"Wireguard \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Wireguard"},{"location":"apps/selfhosted/wireguard.html#wireguard","text":"Wiki Coming Soon .....","title":"Wireguard"},{"location":"apps/selfhosted/wireguard.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/xbvr.html","text":"XBVR \u00b6 XBVR Suggestions \u2022 XBVR Discord The ultimate tool for managing your VR porn library. ## Features - Automatically match title, tags, cast, cover image, and more to your videos - Support for all the most popular VR sites: BadoinkVR, CzechVR Network, DDFNetworkVR, MilfVR, NaughtyAmericaVR, SexBabesVR, StasyQVR, TmwVRnet, VirtualRealPorn, VirtualTaboo, VRBangers, VRHush, VRLatina and WankzVR - Supports DeoVR web mode ## TIPS / INFOS 1. With Dockserver , you don't need to disable https on the deovr player as stated in the XBVR documentation. 1. You must have the deovr app on your vr headset. Go to on the deovr browser. 1. It is not possible to disable automatic scans of the library on xbvr. this could be problematic for very large libraries. 1. The scene scrapper is very demanding on bandwidth, if you have playback problems, consider disabling automatic scene updates. 1. Your videos will passes through Cloudflare infrastructure.Even if you add a cache bypass rules for XBVR, this is technically against their TOS. [Section 2.8 of the Self-Serve Subscription Agreement](https://www.cloudflare.com/terms/) For more information please viste [XBVR Repo](https://github.com/xbapps/xbvr) ## Support Kindly report any issues/broken-parts/bugs on [github](https://github.com/dockserver/dockserver/issues) or [discord](https://discord.gg/A7h7bKBCVa) - Join our for Support","title":"XBVR"},{"location":"apps/selfhosted/xbvr.html#xbvr","text":"XBVR Suggestions \u2022 XBVR Discord","title":"XBVR"},{"location":"apps/selfhosted/share/filerun.html","text":"Filerun \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Filerun"},{"location":"apps/selfhosted/share/filerun.html#filerun","text":"Wiki Coming Soon .....","title":"Filerun"},{"location":"apps/selfhosted/share/filerun.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/share/nextcloud.html","text":"Nextcloud \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Nextcloud"},{"location":"apps/selfhosted/share/nextcloud.html#nextcloud","text":"Wiki Coming Soon .....","title":"Nextcloud"},{"location":"apps/selfhosted/share/nextcloud.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/selfhosted/share/projectsend.html","text":"Projectsend \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Projectsend"},{"location":"apps/selfhosted/share/projectsend.html#projectsend","text":"Wiki Coming Soon .....","title":"Projectsend"},{"location":"apps/selfhosted/share/projectsend.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/system/dockupdater.html","text":"Docker + Updater = Dockupdater \u00b6 Automatically keep your docker services and your docker containers up-to-date with the latest version. Overview \u00b6 Dockupdater will monitor (all or specified by a label) running docker containers and running service (in Docker swarm) and update them to the (latest or tagged) available image in the remote registry. Push your image to your registry and simply wait your defined interval for dockupdater to find the new image and redeploy your container autonomously. Notify you via many platforms courtesy of Apprise Use with Docker swarm to update services on the latest available version Limit your server SSH access Useful to keep 3 rd party container up-to-date Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Dockupdater"},{"location":"apps/system/dockupdater.html#docker-updater-dockupdater","text":"Automatically keep your docker services and your docker containers up-to-date with the latest version.","title":"Docker + Updater = Dockupdater"},{"location":"apps/system/dockupdater.html#overview","text":"Dockupdater will monitor (all or specified by a label) running docker containers and running service (in Docker swarm) and update them to the (latest or tagged) available image in the remote registry. Push your image to your registry and simply wait your defined interval for dockupdater to find the new image and redeploy your container autonomously. Notify you via many platforms courtesy of Apprise Use with Docker swarm to update services on the latest available version Limit your server SSH access Useful to keep 3 rd party container up-to-date","title":"Overview"},{"location":"apps/system/dockupdater.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/system/endlessh.html","text":"Endlessh \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"endlessh"},{"location":"apps/system/endlessh.html#endlessh","text":"Wiki Coming Soon .....","title":"Endlessh"},{"location":"apps/system/endlessh.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/system/mount.html","text":"Mount \u00b6 IMPORTANT \u00b6 Each Mount instance needs his own Project/Keys, never use keys from other projects. If you use Dropbox make sure to name them in rclone.conf like this: [DB] & [DBC] , you also have to set the filename_encoding to base32768 . Features: \u00b6 Service Key Mount. Rclone Web-GUI ( https://mount.mydomain.com ). Notifications via Apprise . Dropbox Configuration \u00b6 All settings can be found here: /opt/appdata/system/mount/mount.env Latest yml for installation can be found here Link . USER VALUES \u00b6 Setting Default Description PUID 1000 PGUID to be used by Mount. PGID 1000 PGID to be used by Mount. TIMEZONE UTC Timezone to be used by Mount. CRITICAL SETUP FOR CRYPT USER \u00b6 Setting Default Description HASHPASSWORD hashed If using drive.csv and encrypted Team Drive, this must be set. Options: hashed plain You have 2 options for this value HASHPASSWORD . hashed this tells mount that you have the encrypted password in your drive.csv . plain this tells mount that you have the plain password in your drive.csv or. You can leave the value as it is if you dont has created the drive.csv by yourself. MERGERFS ADDITIONAL FOLDER \u00b6 Setting Default Description ADDITIONAL_MOUNT null Additional mount points for unionfs . ADDITIONAL_MOUNT_PERMISSION RW Read/Write permissons for additional mount points. Options: RW - Read/Write RO - Read Only RCLONE - SETTINGS \u00b6 For Rclone WebUI - Leave user and password blank and hit login button. Setting Default Description GOOGLE_IP 142.250.74.78 Set hardcoded IP for www.googleapis.com this does prevent Error 429. You can specify multiple IPs with comma separated. PROXY null Set HTTP or SOCKS5 Proxy for RClone. Rclone documentation for details. UMASK 18 Rclone uses its own values 18 = 022 . DRIVETRASH false Whether or not the Drive Trash should be used. Options: true false DRIVE_CHUNK_SIZE 128M Rclone performance setting. This setting should only be changed if you know what you are doing. BUFFER_SIZE 32M Rclone memory buffer setting. See Rclone documentation for details. TMPRCLONE /mnt/rclone_cache Rclone cache folder. UAGENT NONE This is randomly generated and does not need to be changed. TPSLIMIT 10 Rclone limit transactions per second. See Rclone documentation for details. TPSBURST 10 Rclone limit transactions burst. See Rclone documentation for details. VFS - SETTINGS \u00b6 Setting Default Description VFS_READ_CHUNK_SIZE 128M Rclone read chunk size. See Rclone documentation for details. VFS_READ_CHUNK_SIZE_LIMIT 4096M Rclone limit read chunk size. See Rclone documentation for details. VFS_CACHE_MAX_SIZE NONE Rclone maximum allowed local cache size. VFS_CACHE_MAX_AGE 6h Rclone maximum allowed local age. Can be s,m,h,d,w,M,y . VFS_DIR_CACHE_TIME 12h Rclone dir cache time. Can be s,m,h,d,w,M,y . See Rclone documentation for details. VFS_REFRESH_ENABLE true Whether or not the VFS cache should be refreshed. Options: true false VFS_REFRESH 12h How often to perform a VFS refresh. LOG - SETTINGS \u00b6 Setting Default Description LOG_LEVEL INFO Please refer to the Rclone documentation before changes are made. Options: DEBUG INFO NOTICE ERROR NOTIFICATION - SETTINGS \u00b6 Apprise has been integrated into Mount and is defaulted to format all notifications in Markdown . Please refer to the Apprise documentation for more information. Setting Default Description NOTIFICATION_URL null The notification URL to be passed to Apprise. Discord examples: https://discordapp.com/api/webhooks/{WebhookID}/{WebhookToken} discord://{WebhookID}/{WebhookToken}/ discord://{user}@{WebhookID}/{WebhookToken}/ NOTIFICATION_SERVERNAME null What to display on the notification, after \"Mount - \". null will default to \"Mount - Docker\". Anything else will only replace \"Docker\". Examples: NOTIFICATION_SERVERNAME=null results in \"Mount - Docker\" NOTIFICATION_SERVERNAME=My Awesome Server will result in \"Mount - My Awesome Server\" LANGUAGE MESSAGES \u00b6 Setting Default Description LANGUAGE en Language to use. Options: en - English de - German Optional Settings \u00b6 Service Key Mount \u00b6 Service Key Mount is used to prevent Google API Bans . To make use of this, you need to create new Keys within a different Google Project. IMPORTANT : Do not use the same Keys as for the Uploader! Setup: \u00b6 Create new Service Account Keys (see Documentation ) Share all Keys with all Team Drives and set to Manager . Place the new Keys in opt/appdata/system/mount/keys . (You may name the Keys whatever you'd like) When Keys are present, a file named drive.csv is created under opt/appdata/system/mount . This file contains all Team Drive information from your rclone.conf located in opt/appdata/system/rclone . If you don't have an rclone.conf , you can create the drive.csv manually. Unencrypted Team Drives example: 1 = TEAM_DRIVE_NAME -> (TV) 2 = TEAM_DRIVE_ID -> (0AFsVct4HDKPrUk9PVvvvvvvvv) Important: Each line in csv is one tdrive \u00b6 Example: TV|0AFsVct4HDKPrUk9PVvvvvvvvv TV4K|0AFsVct4HDKPrUk9PVxxxxxxxxxx Movies|0AFsVct4HDKPrUk9PVyyyyyyyyyy Movies4K|0AFsVct4HDKPrUk9PVzzzzzzzzzz Encrypted Team Drives example: 1 = TEAM_DRIVE_NAME -> (tdrive1) 2 = TEAM_DRIVE_ID -> (0AFsVct4HDKPrUk9PVvvvvvvvv) 3 = PASSWORD - -> (72nsjsiwjsjsu) 4 = PASSWORD SALT - -> (72nsjsiwjsjsu) Important: Each line in csv is one tdrive \u00b6 Example: tdrive1|0AFsVct4HDKPrUk9PVvvvvvvvv|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive2|0AFsVct4HDKPrUk9PVxxxxxxxxxx|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive3|0AFsVct4HDKPrUk9PVyyyyyyyyyy|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive4|0AFsVct4HDKPrUk9PVzzzzzzzzzz|72nsjsiwjsjsu|72nsjsiwjsjsu Use RAM for rclone_cache \u00b6 IMPORTANT : Only for advanced users. If your system has less than 128GB of RAM or you are unable to allocate at least 50GB for rclone_cache, you should not attempt this. Since our servers usually have a lot of unused RAM, there is a possibility to save local storage while reducing wear and tear on the drive(s) by utilizing RAM for the rclone_cache. /dev/shm is the RAM cache in Linux and , by default, is \u00bd of all system RAM. The example below shows how to change this. Example setup for a system with 128GB of RAM: \u00b6 sudo nano /etc/fstab Add tmpfs /dev/shm tmpfs defaults,size=116g 0 0 (Where 116g is the amount of RAM to reserve for cache, in gigabytes.) Disable swap: sudo swapoff -a sudo nano /opt/appdata/system/mount/mount.env Change TMPRCLONE=/ram_cache Change VFS_CACHE_MAX_SIZE=80G Reboot machine sudo reboot -n Verify that /mnt/unionfs is mounted. If not, redeploy Mount ( sudo mountpoint /mnt/unionfs/ & sudo docker log mount ) Support \u00b6 Kindly report any issues on GitHub or Join our for Support Known issues \u00b6 After redeploy of Mount you see following error in container log? [2023/05/14 16:16:33] [Mount] -> Starting of Rclone was failed <- [2023/05/14 16:16:34] [Mount] -> Starting Mount <- Do following: stop your arrs + plex, then: docker stop mount && docker rm mount && umount /mnt/remotes && umount /mnt/unionfs && fusermount -uzq /mnt/remotes && fusermount -uzq /mnt/unionfs then redeploy mount. (You can ignore the not mounted message) After mount start, you can start your arrs and plex again.","title":"Mount"},{"location":"apps/system/mount.html#mount","text":"","title":"Mount"},{"location":"apps/system/mount.html#important","text":"Each Mount instance needs his own Project/Keys, never use keys from other projects. If you use Dropbox make sure to name them in rclone.conf like this: [DB] & [DBC] , you also have to set the filename_encoding to base32768 .","title":"IMPORTANT"},{"location":"apps/system/mount.html#features","text":"Service Key Mount. Rclone Web-GUI ( https://mount.mydomain.com ). Notifications via Apprise . Dropbox","title":"Features:"},{"location":"apps/system/mount.html#configuration","text":"All settings can be found here: /opt/appdata/system/mount/mount.env Latest yml for installation can be found here Link .","title":"Configuration"},{"location":"apps/system/mount.html#user-values","text":"Setting Default Description PUID 1000 PGUID to be used by Mount. PGID 1000 PGID to be used by Mount. TIMEZONE UTC Timezone to be used by Mount.","title":"USER VALUES"},{"location":"apps/system/mount.html#critical-setup-for-crypt-user","text":"Setting Default Description HASHPASSWORD hashed If using drive.csv and encrypted Team Drive, this must be set. Options: hashed plain You have 2 options for this value HASHPASSWORD . hashed this tells mount that you have the encrypted password in your drive.csv . plain this tells mount that you have the plain password in your drive.csv or. You can leave the value as it is if you dont has created the drive.csv by yourself.","title":"CRITICAL SETUP FOR CRYPT USER"},{"location":"apps/system/mount.html#mergerfs-additional-folder","text":"Setting Default Description ADDITIONAL_MOUNT null Additional mount points for unionfs . ADDITIONAL_MOUNT_PERMISSION RW Read/Write permissons for additional mount points. Options: RW - Read/Write RO - Read Only","title":"MERGERFS ADDITIONAL FOLDER"},{"location":"apps/system/mount.html#rclone-settings","text":"For Rclone WebUI - Leave user and password blank and hit login button. Setting Default Description GOOGLE_IP 142.250.74.78 Set hardcoded IP for www.googleapis.com this does prevent Error 429. You can specify multiple IPs with comma separated. PROXY null Set HTTP or SOCKS5 Proxy for RClone. Rclone documentation for details. UMASK 18 Rclone uses its own values 18 = 022 . DRIVETRASH false Whether or not the Drive Trash should be used. Options: true false DRIVE_CHUNK_SIZE 128M Rclone performance setting. This setting should only be changed if you know what you are doing. BUFFER_SIZE 32M Rclone memory buffer setting. See Rclone documentation for details. TMPRCLONE /mnt/rclone_cache Rclone cache folder. UAGENT NONE This is randomly generated and does not need to be changed. TPSLIMIT 10 Rclone limit transactions per second. See Rclone documentation for details. TPSBURST 10 Rclone limit transactions burst. See Rclone documentation for details.","title":"RCLONE - SETTINGS"},{"location":"apps/system/mount.html#vfs-settings","text":"Setting Default Description VFS_READ_CHUNK_SIZE 128M Rclone read chunk size. See Rclone documentation for details. VFS_READ_CHUNK_SIZE_LIMIT 4096M Rclone limit read chunk size. See Rclone documentation for details. VFS_CACHE_MAX_SIZE NONE Rclone maximum allowed local cache size. VFS_CACHE_MAX_AGE 6h Rclone maximum allowed local age. Can be s,m,h,d,w,M,y . VFS_DIR_CACHE_TIME 12h Rclone dir cache time. Can be s,m,h,d,w,M,y . See Rclone documentation for details. VFS_REFRESH_ENABLE true Whether or not the VFS cache should be refreshed. Options: true false VFS_REFRESH 12h How often to perform a VFS refresh.","title":"VFS - SETTINGS"},{"location":"apps/system/mount.html#log-settings","text":"Setting Default Description LOG_LEVEL INFO Please refer to the Rclone documentation before changes are made. Options: DEBUG INFO NOTICE ERROR","title":"LOG - SETTINGS"},{"location":"apps/system/mount.html#notification-settings","text":"Apprise has been integrated into Mount and is defaulted to format all notifications in Markdown . Please refer to the Apprise documentation for more information. Setting Default Description NOTIFICATION_URL null The notification URL to be passed to Apprise. Discord examples: https://discordapp.com/api/webhooks/{WebhookID}/{WebhookToken} discord://{WebhookID}/{WebhookToken}/ discord://{user}@{WebhookID}/{WebhookToken}/ NOTIFICATION_SERVERNAME null What to display on the notification, after \"Mount - \". null will default to \"Mount - Docker\". Anything else will only replace \"Docker\". Examples: NOTIFICATION_SERVERNAME=null results in \"Mount - Docker\" NOTIFICATION_SERVERNAME=My Awesome Server will result in \"Mount - My Awesome Server\"","title":"NOTIFICATION - SETTINGS"},{"location":"apps/system/mount.html#language-messages","text":"Setting Default Description LANGUAGE en Language to use. Options: en - English de - German","title":"LANGUAGE MESSAGES"},{"location":"apps/system/mount.html#optional-settings","text":"","title":"Optional Settings"},{"location":"apps/system/mount.html#service-key-mount","text":"Service Key Mount is used to prevent Google API Bans . To make use of this, you need to create new Keys within a different Google Project. IMPORTANT : Do not use the same Keys as for the Uploader!","title":"Service Key Mount"},{"location":"apps/system/mount.html#setup","text":"Create new Service Account Keys (see Documentation ) Share all Keys with all Team Drives and set to Manager . Place the new Keys in opt/appdata/system/mount/keys . (You may name the Keys whatever you'd like) When Keys are present, a file named drive.csv is created under opt/appdata/system/mount . This file contains all Team Drive information from your rclone.conf located in opt/appdata/system/rclone . If you don't have an rclone.conf , you can create the drive.csv manually. Unencrypted Team Drives example: 1 = TEAM_DRIVE_NAME -> (TV) 2 = TEAM_DRIVE_ID -> (0AFsVct4HDKPrUk9PVvvvvvvvv)","title":"Setup:"},{"location":"apps/system/mount.html#important-each-line-in-csv-is-one-tdrive","text":"Example: TV|0AFsVct4HDKPrUk9PVvvvvvvvv TV4K|0AFsVct4HDKPrUk9PVxxxxxxxxxx Movies|0AFsVct4HDKPrUk9PVyyyyyyyyyy Movies4K|0AFsVct4HDKPrUk9PVzzzzzzzzzz Encrypted Team Drives example: 1 = TEAM_DRIVE_NAME -> (tdrive1) 2 = TEAM_DRIVE_ID -> (0AFsVct4HDKPrUk9PVvvvvvvvv) 3 = PASSWORD - -> (72nsjsiwjsjsu) 4 = PASSWORD SALT - -> (72nsjsiwjsjsu)","title":"Important: Each line in csv is one tdrive"},{"location":"apps/system/mount.html#important-each-line-in-csv-is-one-tdrive_1","text":"Example: tdrive1|0AFsVct4HDKPrUk9PVvvvvvvvv|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive2|0AFsVct4HDKPrUk9PVxxxxxxxxxx|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive3|0AFsVct4HDKPrUk9PVyyyyyyyyyy|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive4|0AFsVct4HDKPrUk9PVzzzzzzzzzz|72nsjsiwjsjsu|72nsjsiwjsjsu","title":"Important: Each line in csv is one tdrive"},{"location":"apps/system/mount.html#use-ram-for-rclone_cache","text":"IMPORTANT : Only for advanced users. If your system has less than 128GB of RAM or you are unable to allocate at least 50GB for rclone_cache, you should not attempt this. Since our servers usually have a lot of unused RAM, there is a possibility to save local storage while reducing wear and tear on the drive(s) by utilizing RAM for the rclone_cache. /dev/shm is the RAM cache in Linux and , by default, is \u00bd of all system RAM. The example below shows how to change this.","title":"Use RAM for rclone_cache"},{"location":"apps/system/mount.html#example-setup-for-a-system-with-128gb-of-ram","text":"sudo nano /etc/fstab Add tmpfs /dev/shm tmpfs defaults,size=116g 0 0 (Where 116g is the amount of RAM to reserve for cache, in gigabytes.) Disable swap: sudo swapoff -a sudo nano /opt/appdata/system/mount/mount.env Change TMPRCLONE=/ram_cache Change VFS_CACHE_MAX_SIZE=80G Reboot machine sudo reboot -n Verify that /mnt/unionfs is mounted. If not, redeploy Mount ( sudo mountpoint /mnt/unionfs/ & sudo docker log mount )","title":"Example setup for a system with 128GB of RAM:"},{"location":"apps/system/mount.html#support","text":"Kindly report any issues on GitHub or Join our for Support","title":"Support"},{"location":"apps/system/mount.html#known-issues","text":"After redeploy of Mount you see following error in container log? [2023/05/14 16:16:33] [Mount] -> Starting of Rclone was failed <- [2023/05/14 16:16:34] [Mount] -> Starting Mount <- Do following: stop your arrs + plex, then: docker stop mount && docker rm mount && umount /mnt/remotes && umount /mnt/unionfs && fusermount -uzq /mnt/remotes && fusermount -uzq /mnt/unionfs then redeploy mount. (You can ignore the not mounted message) After mount start, you can start your arrs and plex again.","title":"Known issues"},{"location":"apps/system/rclone-gui.html","text":"Rclone-GUI \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Rclone-GUI"},{"location":"apps/system/rclone-gui.html#rclone-gui","text":"Wiki Coming Soon .....","title":"Rclone-GUI"},{"location":"apps/system/rclone-gui.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/system/statping.html","text":"Staping \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Statping"},{"location":"apps/system/statping.html#staping","text":"Wiki Coming Soon .....","title":"Staping"},{"location":"apps/system/statping.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"apps/system/uploader.html","text":"Uploader \u00b6 Automated uploader. IMPORTANT \u00b6 Each Uploader instance needs his own Project/Keys, never use keys from other projects. Features: \u00b6 Completely automated. Clean web interface. Support for encrypted Team Drives. Support for multiple Team Drives. Supports all rclone remotes. Bypass daily upload limit of 750GB via Service Accounts. Support for Autoscan . Full support for Rclone's bandwidth limit . Notifications via Apprise . Variable concurrent uploads. Dropbox Settings are refreshed for each upload. No need to restart the container after making a configuration change! Start and stop on demand via the container or web interface (active uploads are not considered when pausing via the web interface). Change time formatting. Limitations: \u00b6 No support for Google Drive. If using multiple Team Drives for Uploader, FOLDER_DEPTH must be identical across all drives. Bandwidth limit is per upload IE - If you have TRANSFERS=2 and BANDWIDTH_LIMIT=20M , the maximum total upload speed would be 40MiB. Bandwidth cannot be changed for any active uploads. Exclude files from being uploaded \u00b6 rclone.exclude is located here: /opt/appdata/system/uploader/rclone.exclude Example: if you don\u00b4t want that srt files are being uploaded, you have to add .*\\.srt$ to the file. You can exclude folders to, examples are in the file, because we already exclude certain folders. Configuration \u00b6 All settings can be found here: /opt/appdata/system/uploader/uploader.env If you use Dropbox make sure to name them in rclonegdsa.conf like this: [DB] & [DBC] , you also have to set the filename_encoding to base32768 . USER VALUES \u00b6 Setting Default Description PUID 1000 PGUID to be used by Uploader. PGID 1000 PGID to be used by Uploader. TIMEZONE UTC Timezone to be used by Uploader. CRITICAL SETUP FOR CRYPT USER \u00b6 Setting Default Description HASHPASSWORD hashed If using drive.csv or uploader.csv and encrypted Team Drive, this must be set. Options: hashed plain GDSA_NAME encrypt Here you can set the name of the crypt folder for Google. DB_NAME encrypt Here you can set the name of the crypt folder for Dropbox. DB_TEAM true With DB_TEAM = false you can activate the usage of the private Dropbox folder. You have 2 options for this value HASHPASSWORD . hashed this tells uploader that you have the encrypted password in your drive.csv or uploader.csv . plain this tells uploader that you have the plain password in your drive.csv or uploader.csv . You can leave the value as it is if you dont use Multi Drive uploading. RCLONE - SETTINGS \u00b6 Setting Default Description BANDWIDTH_LIMIT null The maximum upload speed per upload . Please refer to the Rclone documentation before changes are made. GOOGLE_IP 142.250.74.78 Set hardcoded IP for www.googleapis.com this does prevent Error 429. You can specify multiple IPs with comma separated. PROXY null Set HTTP or SOCKS5 Proxy for RClone. Rclone documentation for details. LOG_LEVEL INFO Please refer to the Rclone documentation before changes are made. DLFOLDER /mnt/downloads Path to your download directory. TRANSFERS 2 The maximum number of concurrent uploads. USER - SETTINGS \u00b6 Setting Default Description DRIVEUSEDSPACE null Amount of local storage, in percent, to use before uploading any files. Example: DRIVEUSEDSPACE=80 will wait until the drive space used reaches 80% before uploading files. FOLDER_DEPTH 1 If your movie/show folders are in root of drive, you can leave this to 1, if you have them in a subfolder you have to change the depth value, Example media/tvshow/showname would result in FOLDER_DEPTH=2 (if you use multiuploader, you need the same DEPTH/folder structure on all drives where you upload to). IMPORTANT : This setting should only be used if you know what you are doing. By changing the value, you accept all risks that come with it. FOLDER_PRIORITY null Add folders you like to prioritize - Example: tv,movies (tv first, then movies, then all others not in the list). MIN_AGE_UPLOAD 1 How old a file should be, in minutes, before it is uploaded. Example: MIN_AGE_UPLOAD=10 will wait until a file is 10 minutes old before it is uploaded. VFS - SETTINGS \u00b6 Setting Default Description VFS_REFRESH_ENABLE true Whether or not the VFS cache refresh should be send to the Mount Docker. Options: true false MOUNT mount:8554 The local address of your mount instance. LOG - SETTINGS \u00b6 Setting Default Description LOG_ENTRY 1000 How many log entries should be retained in the local database. LOG_RETENTION_DAYS null How many days of log entries should be kept. If LOG_RETENTION_DAYS is defined, then LOG_ENTRY is ignored. AUTOSCAN - SETTINGS \u00b6 Autoscan is optional, people with feeders may use it to trigger scan after upload is completed. If you enable it in uploader, you can disable it in the *arrs. Setting Default Description AUTOSCAN_URL null Remote or local path to Autoscan. Examples: Remote: AUTOSCAN_URL=https://autoscan.domain.com Local: AUTOSCAN_URL=http://autoscan:3030 AUTOSCAN_USER null Autoscan username. AUTOSCAN_PASS null Autoscan password. NOTIFICATION - SETTINGS \u00b6 Apprise has been integrated into Uploader and is defaulted to format all notifications in Markdown . Please refer to the Apprise documentation for more information. Setting Default Description NOTIFICATION_URL null The notification URL to be passed to Apprise. Discord examples: https://discordapp.com/api/webhooks/{WebhookID}/{WebhookToken} discord://{WebhookID}/{WebhookToken}/ discord://{user}@{WebhookID}/{WebhookToken}/ NOTIFICATION_LEVEL ALL What notifications should be sent to NOTIFICATION_URL . Options: ALL - Send notification for all uploads ERROR - Send notification for only errors NONE - Do not send any notifications NOTIFICATION_SERVERNAME null What to display on the notification, after \"Uploader - \". null will default to \"Uploader - Docker\". Anything else will only replace \"Docker\". Examples: NOTIFICATION_SERVERNAME=null results in \"Uploader - Docker\" NOTIFICATION_SERVERNAME=My Awesome Server will result in \"Uploader - My Awesome Server\" STRIPARR - SETTINGS \u00b6 Striparr is optional and needs the Striparr Docker to be deployed on the same System. The files will not be uploaded until they have been successfully striped. Setting Default Description STRIPARR_URL null The Striparr URL. Example: STRIPARR_URL=http://striparr:40000 LANGUAGE MESSAGES \u00b6 Setting Default Description LANGUAGE en Language to use. Options: en - English de - German Multi-Drive Uploader \u00b6 If you would like to upload to multiple Team Drives, you need to create a file named uploader.csv in /opt/appdata/system/servicekeys/ . You can find a sample file in opt/appdata/system/uploader/sample . For each Team Drive, add a line in the uploader.csv file. IMPORTANT : If \"LOCAL_FOLDER_NAME\" contains a hyphen, do not include it. Unencrypted Team Drives example: 1 = LOCAL_FOLDER_NAME -> (TV) 2 = TEAM_DRIVE_ID -> (0AFsVct4HDKPrUk9PVvvvvvvvv) Important: Each line in csv is one Local Folder \u00b6 Example: TV|0AFsVct4HDKPrUk9PVvvvvvvvv TV4K|0AFsVct4HDKPrUk9PVxxxxxxxxxx Movies|0AFsVct4HDKPrUk9PVyyyyyyyyyy Movies4K|0AFsVct4HDKPrUk9PVzzzzzzzzzz appbackups|0AFsVct4HDKPrUk9PVzzzzzzzzzz music|0AFsVct4HDKPrUk9PVzzzzzzzzzz Encrypted Team Drives example: 1 = LOCAL_FOLDER_NAME -> (Movies) 2 = TEAM_DRIVE_ID -> (0AFsVct4HDKPrUk9PVvvvvvvvv) 3 = PASSWORD - -> (72nsjsiwjsjsu) 4 = PASSWORD SALT - -> (72nsjsiwjsjsu) Important: Each line in csv is one Local Folder \u00b6 Example: Movies|0AFsVct4HDKPrUk9PVvvvvvvvv|72nsjsiwjsjsu|72nsjsiwjsjsu TV SHows|0AFsVct4HDKPrUk9PVxxxxxxxxxx|72nsjsiwjsjsu|72nsjsiwjsjsu 4K|0AFsVct4HDKPrUk9PVyyyyyyyyyy|72nsjsiwjsjsu|72nsjsiwjsjsu TV 4K|0AFsVct4HDKPrUk9PVzzzzzzzzzz|72nsjsiwjsjsu|72nsjsiwjsjsu appbackups|0AFsVct4HDKPrUk9PVzzzzzzzzzz|72nsjsiwjsjsu|72nsjsiwjsjsu music|0AFsVct4HDKPrUk9PVzzzzzzzzzz|72nsjsiwjsjsu|72nsjsiwjsjsu IMPORTANT : All Keys must be known on all Team Drives! You also have to add all folders where you want to upload files (even backup folders). Other Uploader Features \u00b6 Instead of using /opt/appdata/system/servicekeys/rclonegdsa.conf , you can now use a drive.csv where you can put the default Team Drive to upload in. To make use of this feature, you need to create a file named drive.csv in /opt/appdata/system/uploader/ . Unencrypted Team Drives \u00b6 1 = TEAM_DRIVE_NAME -> (uploader) 2 = TEAM_DRIVE_ID -> (0XXXXXXXXX000000EERR) Important: Each line in csv is one tdrive \u00b6 Example: uploader|0XXXXXXXXX000000EERR Encrypted Team Drives \u00b6 1 = TEAM_DRIVE_NAME -> (uploader) 2 = TEAM_DRIVE_ID -> (0XXXXXXXXX000000EERR) 3 = PASSWORD - HASHED OR PLAIN -> (72nsjsiwjsjsu) 4 = PASSWORD SALT - HASHED OR PLAIN -> (72nsjsiwjsjsu) Important: Each line in csv is one tdrive \u00b6 Example: uploader|0XXXXXXXXX000000EERR|72nsjsiwjsjsu|72nsjsiwjsjsu Support \u00b6 Kindly report any issues on GitHub or Join our for Support","title":"Uploader"},{"location":"apps/system/uploader.html#uploader","text":"Automated uploader.","title":"Uploader"},{"location":"apps/system/uploader.html#important","text":"Each Uploader instance needs his own Project/Keys, never use keys from other projects.","title":"IMPORTANT"},{"location":"apps/system/uploader.html#features","text":"Completely automated. Clean web interface. Support for encrypted Team Drives. Support for multiple Team Drives. Supports all rclone remotes. Bypass daily upload limit of 750GB via Service Accounts. Support for Autoscan . Full support for Rclone's bandwidth limit . Notifications via Apprise . Variable concurrent uploads. Dropbox Settings are refreshed for each upload. No need to restart the container after making a configuration change! Start and stop on demand via the container or web interface (active uploads are not considered when pausing via the web interface). Change time formatting.","title":"Features:"},{"location":"apps/system/uploader.html#limitations","text":"No support for Google Drive. If using multiple Team Drives for Uploader, FOLDER_DEPTH must be identical across all drives. Bandwidth limit is per upload IE - If you have TRANSFERS=2 and BANDWIDTH_LIMIT=20M , the maximum total upload speed would be 40MiB. Bandwidth cannot be changed for any active uploads.","title":"Limitations:"},{"location":"apps/system/uploader.html#exclude-files-from-being-uploaded","text":"rclone.exclude is located here: /opt/appdata/system/uploader/rclone.exclude Example: if you don\u00b4t want that srt files are being uploaded, you have to add .*\\.srt$ to the file. You can exclude folders to, examples are in the file, because we already exclude certain folders.","title":"Exclude files from being uploaded"},{"location":"apps/system/uploader.html#configuration","text":"All settings can be found here: /opt/appdata/system/uploader/uploader.env If you use Dropbox make sure to name them in rclonegdsa.conf like this: [DB] & [DBC] , you also have to set the filename_encoding to base32768 .","title":"Configuration"},{"location":"apps/system/uploader.html#user-values","text":"Setting Default Description PUID 1000 PGUID to be used by Uploader. PGID 1000 PGID to be used by Uploader. TIMEZONE UTC Timezone to be used by Uploader.","title":"USER VALUES"},{"location":"apps/system/uploader.html#critical-setup-for-crypt-user","text":"Setting Default Description HASHPASSWORD hashed If using drive.csv or uploader.csv and encrypted Team Drive, this must be set. Options: hashed plain GDSA_NAME encrypt Here you can set the name of the crypt folder for Google. DB_NAME encrypt Here you can set the name of the crypt folder for Dropbox. DB_TEAM true With DB_TEAM = false you can activate the usage of the private Dropbox folder. You have 2 options for this value HASHPASSWORD . hashed this tells uploader that you have the encrypted password in your drive.csv or uploader.csv . plain this tells uploader that you have the plain password in your drive.csv or uploader.csv . You can leave the value as it is if you dont use Multi Drive uploading.","title":"CRITICAL SETUP FOR CRYPT USER"},{"location":"apps/system/uploader.html#rclone-settings","text":"Setting Default Description BANDWIDTH_LIMIT null The maximum upload speed per upload . Please refer to the Rclone documentation before changes are made. GOOGLE_IP 142.250.74.78 Set hardcoded IP for www.googleapis.com this does prevent Error 429. You can specify multiple IPs with comma separated. PROXY null Set HTTP or SOCKS5 Proxy for RClone. Rclone documentation for details. LOG_LEVEL INFO Please refer to the Rclone documentation before changes are made. DLFOLDER /mnt/downloads Path to your download directory. TRANSFERS 2 The maximum number of concurrent uploads.","title":"RCLONE - SETTINGS"},{"location":"apps/system/uploader.html#user-settings","text":"Setting Default Description DRIVEUSEDSPACE null Amount of local storage, in percent, to use before uploading any files. Example: DRIVEUSEDSPACE=80 will wait until the drive space used reaches 80% before uploading files. FOLDER_DEPTH 1 If your movie/show folders are in root of drive, you can leave this to 1, if you have them in a subfolder you have to change the depth value, Example media/tvshow/showname would result in FOLDER_DEPTH=2 (if you use multiuploader, you need the same DEPTH/folder structure on all drives where you upload to). IMPORTANT : This setting should only be used if you know what you are doing. By changing the value, you accept all risks that come with it. FOLDER_PRIORITY null Add folders you like to prioritize - Example: tv,movies (tv first, then movies, then all others not in the list). MIN_AGE_UPLOAD 1 How old a file should be, in minutes, before it is uploaded. Example: MIN_AGE_UPLOAD=10 will wait until a file is 10 minutes old before it is uploaded.","title":"USER - SETTINGS"},{"location":"apps/system/uploader.html#vfs-settings","text":"Setting Default Description VFS_REFRESH_ENABLE true Whether or not the VFS cache refresh should be send to the Mount Docker. Options: true false MOUNT mount:8554 The local address of your mount instance.","title":"VFS - SETTINGS"},{"location":"apps/system/uploader.html#log-settings","text":"Setting Default Description LOG_ENTRY 1000 How many log entries should be retained in the local database. LOG_RETENTION_DAYS null How many days of log entries should be kept. If LOG_RETENTION_DAYS is defined, then LOG_ENTRY is ignored.","title":"LOG - SETTINGS"},{"location":"apps/system/uploader.html#autoscan-settings","text":"Autoscan is optional, people with feeders may use it to trigger scan after upload is completed. If you enable it in uploader, you can disable it in the *arrs. Setting Default Description AUTOSCAN_URL null Remote or local path to Autoscan. Examples: Remote: AUTOSCAN_URL=https://autoscan.domain.com Local: AUTOSCAN_URL=http://autoscan:3030 AUTOSCAN_USER null Autoscan username. AUTOSCAN_PASS null Autoscan password.","title":"AUTOSCAN - SETTINGS"},{"location":"apps/system/uploader.html#notification-settings","text":"Apprise has been integrated into Uploader and is defaulted to format all notifications in Markdown . Please refer to the Apprise documentation for more information. Setting Default Description NOTIFICATION_URL null The notification URL to be passed to Apprise. Discord examples: https://discordapp.com/api/webhooks/{WebhookID}/{WebhookToken} discord://{WebhookID}/{WebhookToken}/ discord://{user}@{WebhookID}/{WebhookToken}/ NOTIFICATION_LEVEL ALL What notifications should be sent to NOTIFICATION_URL . Options: ALL - Send notification for all uploads ERROR - Send notification for only errors NONE - Do not send any notifications NOTIFICATION_SERVERNAME null What to display on the notification, after \"Uploader - \". null will default to \"Uploader - Docker\". Anything else will only replace \"Docker\". Examples: NOTIFICATION_SERVERNAME=null results in \"Uploader - Docker\" NOTIFICATION_SERVERNAME=My Awesome Server will result in \"Uploader - My Awesome Server\"","title":"NOTIFICATION - SETTINGS"},{"location":"apps/system/uploader.html#striparr-settings","text":"Striparr is optional and needs the Striparr Docker to be deployed on the same System. The files will not be uploaded until they have been successfully striped. Setting Default Description STRIPARR_URL null The Striparr URL. Example: STRIPARR_URL=http://striparr:40000","title":"STRIPARR - SETTINGS"},{"location":"apps/system/uploader.html#language-messages","text":"Setting Default Description LANGUAGE en Language to use. Options: en - English de - German","title":"LANGUAGE MESSAGES"},{"location":"apps/system/uploader.html#multi-drive-uploader","text":"If you would like to upload to multiple Team Drives, you need to create a file named uploader.csv in /opt/appdata/system/servicekeys/ . You can find a sample file in opt/appdata/system/uploader/sample . For each Team Drive, add a line in the uploader.csv file. IMPORTANT : If \"LOCAL_FOLDER_NAME\" contains a hyphen, do not include it. Unencrypted Team Drives example: 1 = LOCAL_FOLDER_NAME -> (TV) 2 = TEAM_DRIVE_ID -> (0AFsVct4HDKPrUk9PVvvvvvvvv)","title":"Multi-Drive Uploader"},{"location":"apps/system/uploader.html#important-each-line-in-csv-is-one-local-folder","text":"Example: TV|0AFsVct4HDKPrUk9PVvvvvvvvv TV4K|0AFsVct4HDKPrUk9PVxxxxxxxxxx Movies|0AFsVct4HDKPrUk9PVyyyyyyyyyy Movies4K|0AFsVct4HDKPrUk9PVzzzzzzzzzz appbackups|0AFsVct4HDKPrUk9PVzzzzzzzzzz music|0AFsVct4HDKPrUk9PVzzzzzzzzzz Encrypted Team Drives example: 1 = LOCAL_FOLDER_NAME -> (Movies) 2 = TEAM_DRIVE_ID -> (0AFsVct4HDKPrUk9PVvvvvvvvv) 3 = PASSWORD - -> (72nsjsiwjsjsu) 4 = PASSWORD SALT - -> (72nsjsiwjsjsu)","title":"Important: Each line in csv is one Local Folder"},{"location":"apps/system/uploader.html#important-each-line-in-csv-is-one-local-folder_1","text":"Example: Movies|0AFsVct4HDKPrUk9PVvvvvvvvv|72nsjsiwjsjsu|72nsjsiwjsjsu TV SHows|0AFsVct4HDKPrUk9PVxxxxxxxxxx|72nsjsiwjsjsu|72nsjsiwjsjsu 4K|0AFsVct4HDKPrUk9PVyyyyyyyyyy|72nsjsiwjsjsu|72nsjsiwjsjsu TV 4K|0AFsVct4HDKPrUk9PVzzzzzzzzzz|72nsjsiwjsjsu|72nsjsiwjsjsu appbackups|0AFsVct4HDKPrUk9PVzzzzzzzzzz|72nsjsiwjsjsu|72nsjsiwjsjsu music|0AFsVct4HDKPrUk9PVzzzzzzzzzz|72nsjsiwjsjsu|72nsjsiwjsjsu IMPORTANT : All Keys must be known on all Team Drives! You also have to add all folders where you want to upload files (even backup folders).","title":"Important: Each line in csv is one Local Folder"},{"location":"apps/system/uploader.html#other-uploader-features","text":"Instead of using /opt/appdata/system/servicekeys/rclonegdsa.conf , you can now use a drive.csv where you can put the default Team Drive to upload in. To make use of this feature, you need to create a file named drive.csv in /opt/appdata/system/uploader/ .","title":"Other Uploader Features"},{"location":"apps/system/uploader.html#unencrypted-team-drives","text":"1 = TEAM_DRIVE_NAME -> (uploader) 2 = TEAM_DRIVE_ID -> (0XXXXXXXXX000000EERR)","title":"Unencrypted Team Drives"},{"location":"apps/system/uploader.html#important-each-line-in-csv-is-one-tdrive","text":"Example: uploader|0XXXXXXXXX000000EERR","title":"Important: Each line in csv is one tdrive"},{"location":"apps/system/uploader.html#encrypted-team-drives","text":"1 = TEAM_DRIVE_NAME -> (uploader) 2 = TEAM_DRIVE_ID -> (0XXXXXXXXX000000EERR) 3 = PASSWORD - HASHED OR PLAIN -> (72nsjsiwjsjsu) 4 = PASSWORD SALT - HASHED OR PLAIN -> (72nsjsiwjsjsu)","title":"Encrypted Team Drives"},{"location":"apps/system/uploader.html#important-each-line-in-csv-is-one-tdrive_1","text":"Example: uploader|0XXXXXXXXX000000EERR|72nsjsiwjsjsu|72nsjsiwjsjsu","title":"Important: Each line in csv is one tdrive"},{"location":"apps/system/uploader.html#support","text":"Kindly report any issues on GitHub or Join our for Support","title":"Support"},{"location":"apps/system/wiki.html","text":"Wiki \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"DockServerWiki"},{"location":"apps/system/wiki.html#wiki","text":"Wiki Coming Soon .....","title":"Wiki"},{"location":"apps/system/wiki.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"commands/backup.html","text":"Backup \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Backup"},{"location":"commands/backup.html#backup","text":"Wiki Coming Soon .....","title":"Backup"},{"location":"commands/backup.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"commands/commands.html","text":"Commands \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Commands"},{"location":"commands/commands.html#commands","text":"Wiki Coming Soon .....","title":"Commands"},{"location":"commands/commands.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"commands/restore.html","text":"Restore \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Restore"},{"location":"commands/restore.html#restore","text":"Wiki Coming Soon .....","title":"Restore"},{"location":"commands/restore.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"drive/dropbox.html","text":"Dropbox Configuration \u00b6 Preface \u00b6 In this guide, you will create 2 rclone files; one for Mount, one for Uploader. Please note, this guide only shows how to create an encrypted drive with Dropbox. \u00b6 Before you begin \u00b6 Please backup the entire /opt/appdata/system directory and ensure you are running the latest versions of Mount and Uploader. \u00b6 Create rclone configs \u00b6 Download rclone Create 2 Apps according to this guide (Mount, Uploader) and note each app key/secret. You will need it for rclone. Run rclone.exe config Create Remote (DB) New remote> n name> DB Storage (Dropbox)> 13 client_id> App Key from step 2 client_secret> App secret from step 2 Edit advanced config?> n Use web browser to automatically authenticate rclone with remote?> y Log in with your DB account and allow app Repeat for all 2 apps, copying away your rclone.conf after each run. Create Remote (DBC) New remote> n Name> DBC Storage (Crypt)> 14 remote> DB:/<directory_name> filename_encryption> 1 directory_name_encryption> 1 Generate random password> g Bits> 128 (Note the password and never lose it) Use this password?> y Password or pass phrase for salt> g Bits> 128 (Note the password and never lose it) Use this password?> y Edit advanced config?> n Keep this \"DBC\" Remote?> y Note - In remote = DB:/<directory_name> , change <directory_name> to whatever you'd like. Add the following to the crypt [DBC] section in %AppData%\\rclone\\rclone.conf directory_name_encryption = true filename_encryption = standard filename_encoding = base32768 IMPORTANT : filename_encoding must be this value: base32768 Copy the [DBC] section to the other rclone.conf file. You should end up with 2 files that look similar to this: [DB] type = dropbox token = {\"access_token\":\"<redacted>\",\"token_type\":\"bearer\",\"refresh_token\":\"<redacted>\",\"expiry\":\"2023-04-03T20:22:38.8845967+02:00\"} client_id = <redacted> client_secret = <redacted> [DBC] type = crypt directory_name_encryption = true password = <redacted> password2 = <redacted> remote = DB:/<directory_name> filename_encryption = standard filename_encoding = base32768 Copy the Mount rclone.conf file to: /opt/appdata/system/rclone/rclone.conf /opt/appdata/system/mount/rclone/rclone.conf Copy the contents of Uploader rclone.conf to /opt/appdata/system/servicekeys/rclonegdsa.conf , deleting everything that is currently there. This should be the only file/folder in this directory. Redeploy Mount and Uploader Update DB_NAME value in /opt/appdata/system/uploader/uploader.env with the name you chose during step 5. Example: DB_NAME=<directory_name> Restart Uploader Finally, assuming everything looks to be working, run the following two commands: cd /root && touch dbc.anchor rclone copy -v \"/root/dbc.anchor\" \"DBC:/.anchors\" --config=\"/opt/appdata/system/rclone/rclone.conf\" --stats=1s --checkers=4 --dropbox-chunk-size=128M --use-mmap --tpslimit=10 --transfers=6 Autoscan \u00b6 If using autoscan, you will need to update /opt/appdata/autoscan/config.yml to include the following: anchors: - /mnt/unionfs/.anchors/dbc.anchor Restart autoscan. docker restart autoscan","title":"Dropbox"},{"location":"drive/dropbox.html#dropbox-configuration","text":"","title":"Dropbox Configuration"},{"location":"drive/dropbox.html#preface","text":"","title":"Preface"},{"location":"drive/dropbox.html#in-this-guide-you-will-create-2-rclone-files-one-for-mount-one-for-uploader-please-note-this-guide-only-shows-how-to-create-an-encrypted-drive-with-dropbox","text":"","title":"In this guide, you will create 2 rclone files; one for Mount, one for Uploader. Please note, this guide only shows how to create an encrypted drive with Dropbox."},{"location":"drive/dropbox.html#before-you-begin","text":"","title":"Before you begin"},{"location":"drive/dropbox.html#please-backup-the-entire-optappdatasystem-directory-and-ensure-you-are-running-the-latest-versions-of-mount-and-uploader","text":"","title":"Please backup the entire /opt/appdata/system directory and ensure you are running the latest versions of Mount and Uploader."},{"location":"drive/dropbox.html#create-rclone-configs","text":"Download rclone Create 2 Apps according to this guide (Mount, Uploader) and note each app key/secret. You will need it for rclone. Run rclone.exe config Create Remote (DB) New remote> n name> DB Storage (Dropbox)> 13 client_id> App Key from step 2 client_secret> App secret from step 2 Edit advanced config?> n Use web browser to automatically authenticate rclone with remote?> y Log in with your DB account and allow app Repeat for all 2 apps, copying away your rclone.conf after each run. Create Remote (DBC) New remote> n Name> DBC Storage (Crypt)> 14 remote> DB:/<directory_name> filename_encryption> 1 directory_name_encryption> 1 Generate random password> g Bits> 128 (Note the password and never lose it) Use this password?> y Password or pass phrase for salt> g Bits> 128 (Note the password and never lose it) Use this password?> y Edit advanced config?> n Keep this \"DBC\" Remote?> y Note - In remote = DB:/<directory_name> , change <directory_name> to whatever you'd like. Add the following to the crypt [DBC] section in %AppData%\\rclone\\rclone.conf directory_name_encryption = true filename_encryption = standard filename_encoding = base32768 IMPORTANT : filename_encoding must be this value: base32768 Copy the [DBC] section to the other rclone.conf file. You should end up with 2 files that look similar to this: [DB] type = dropbox token = {\"access_token\":\"<redacted>\",\"token_type\":\"bearer\",\"refresh_token\":\"<redacted>\",\"expiry\":\"2023-04-03T20:22:38.8845967+02:00\"} client_id = <redacted> client_secret = <redacted> [DBC] type = crypt directory_name_encryption = true password = <redacted> password2 = <redacted> remote = DB:/<directory_name> filename_encryption = standard filename_encoding = base32768 Copy the Mount rclone.conf file to: /opt/appdata/system/rclone/rclone.conf /opt/appdata/system/mount/rclone/rclone.conf Copy the contents of Uploader rclone.conf to /opt/appdata/system/servicekeys/rclonegdsa.conf , deleting everything that is currently there. This should be the only file/folder in this directory. Redeploy Mount and Uploader Update DB_NAME value in /opt/appdata/system/uploader/uploader.env with the name you chose during step 5. Example: DB_NAME=<directory_name> Restart Uploader Finally, assuming everything looks to be working, run the following two commands: cd /root && touch dbc.anchor rclone copy -v \"/root/dbc.anchor\" \"DBC:/.anchors\" --config=\"/opt/appdata/system/rclone/rclone.conf\" --stats=1s --checkers=4 --dropbox-chunk-size=128M --use-mmap --tpslimit=10 --transfers=6","title":"Create rclone configs"},{"location":"drive/dropbox.html#autoscan","text":"If using autoscan, you will need to update /opt/appdata/autoscan/config.yml to include the following: anchors: - /mnt/unionfs/.anchors/dbc.anchor Restart autoscan. docker restart autoscan","title":"Autoscan"},{"location":"drive/gcrypt.html","text":"Creating GCrypt Remote \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"GCrypt"},{"location":"drive/gcrypt.html#creating-gcrypt-remote","text":"Wiki Coming Soon .....","title":"Creating GCrypt Remote"},{"location":"drive/gcrypt.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"drive/gdrive.html","text":"Creating Gdrive Remote \u00b6 First, install rclone: sudo apt install rclone or curl https://rclone.org/install.sh | sudo bash Then: rclone config Type n for New Remote Type gdrive Select from the list Google Drive (not Google Cloud Storage) Now it is time to make your own client_id and secret: Goto https://console.developers.google.com/ Make sure you are logged in with the correct google account. Create a New Project Under \u201cENABLE APIS AND SERVICES\u201d search for \u201cDrive\u201d, and enable the \u201cGoogle Drive API\u201d Click \"OAuth consent screen\" in the left-side panel. Choose \"External\" On the next screen type in App name (your choice), user support email (email you logged in with), at bottom developer contact info (same email) Save and continue Next screen (Scopes) change nothing. Save and continue. Next screen add test user. Same email. Save and continue. Now click \u201cCredentials\u201d in the left-side panel (not \u201cCreate credentials\u201d, which opens the wizard), then \u201c+ CREATE CREDENTIALS\u201d at top, then \u201cOAuth client ID\u201d. Choose an application type of \u201cDesktop App\u201d, and fill in name (your choice)click \u201cCreate\u201d This will then show you a client ID and client secret. Copy the Client ID Go back to the terminal window and right click to paste the Client ID Now go back to the Google developers console and copy the Client Secret Go back to terminal window and right click to paste the Client Secret You will now Have a number of prompts: scope \u2013 type 1 and then enter root folder - Leave Blank and press Enter service_account_file - Leave this blank and press enter advanced config (y/n) - Type n and then enter auto config - Type n and then enter Copy the URL provided and paste into browser. Enter your login details and paste token into terminal. Configure this as a team drive? , type n and then enter type y for Yes this is OK You can type Q to exit or move on to tdrive The rclone.conf file will be save in /.config/rclone Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"GDrive"},{"location":"drive/gdrive.html#creating-gdrive-remote","text":"First, install rclone: sudo apt install rclone or curl https://rclone.org/install.sh | sudo bash Then: rclone config Type n for New Remote Type gdrive Select from the list Google Drive (not Google Cloud Storage) Now it is time to make your own client_id and secret: Goto https://console.developers.google.com/ Make sure you are logged in with the correct google account. Create a New Project Under \u201cENABLE APIS AND SERVICES\u201d search for \u201cDrive\u201d, and enable the \u201cGoogle Drive API\u201d Click \"OAuth consent screen\" in the left-side panel. Choose \"External\" On the next screen type in App name (your choice), user support email (email you logged in with), at bottom developer contact info (same email) Save and continue Next screen (Scopes) change nothing. Save and continue. Next screen add test user. Same email. Save and continue. Now click \u201cCredentials\u201d in the left-side panel (not \u201cCreate credentials\u201d, which opens the wizard), then \u201c+ CREATE CREDENTIALS\u201d at top, then \u201cOAuth client ID\u201d. Choose an application type of \u201cDesktop App\u201d, and fill in name (your choice)click \u201cCreate\u201d This will then show you a client ID and client secret. Copy the Client ID Go back to the terminal window and right click to paste the Client ID Now go back to the Google developers console and copy the Client Secret Go back to terminal window and right click to paste the Client Secret You will now Have a number of prompts: scope \u2013 type 1 and then enter root folder - Leave Blank and press Enter service_account_file - Leave this blank and press enter advanced config (y/n) - Type n and then enter auto config - Type n and then enter Copy the URL provided and paste into browser. Enter your login details and paste token into terminal. Configure this as a team drive? , type n and then enter type y for Yes this is OK You can type Q to exit or move on to tdrive The rclone.conf file will be save in /.config/rclone","title":"Creating Gdrive Remote"},{"location":"drive/gdrive.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"drive/mdkeys.html","text":"Mount Keys \u00b6 Service Key Mount \u00b6 Service Key Mount is used to prevent Google API Bans . To make use of this, you need to create new Keys within a different Google Project. IMPORTANT : Do not use the same Keys as for the Uploader! Setup: \u00b6 Create new Service Account Keys (see Documentation ) Share all Keys with all Team Drives and set to Manager . Place the new Keys in opt/appdata/system/mount/keys . (You may name the Keys whatever you'd like) When Keys are present, a file named drive.csv is created under opt/appdata/system/mount . This file contains all Team Drive information from your rclone.conf located in opt/appdata/system/rclone . If you don't have an rclone.conf , you can create the drive.csv manually. Unencrypted Team Drives example: 1 = TEAM_DRIVE_NAME 2 = TEAM_DRIVE_ID TV|0AFsVct4HDKPrUk9PVvvvvvvvv TV4K|0AFsVct4HDKPrUk9PVxxxxxxxxxx Movies|0AFsVct4HDKPrUk9PVyyyyyyyyyy Movies4K|0AFsVct4HDKPrUk9PVzzzzzzzzzz ... Encrypted Team Drives example: 1 = TEAM_DRIVE_NAME 2 = TEAM_DRIVE_ID 3 = PASSWORD - <HASHED|PLAIN> 4 = PASSWORD SALT - <HASHED|PLAIN> tdrive1|0AFsVct4HDKPrUk9PVvvvvvvvv|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive2|0AFsVct4HDKPrUk9PVxxxxxxxxxx|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive3|0AFsVct4HDKPrUk9PVyyyyyyyyyy|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive4|0AFsVct4HDKPrUk9PVzzzzzzzzzz|72nsjsiwjsjsu|72nsjsiwjsjsu ... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord","title":"Mount Keys"},{"location":"drive/mdkeys.html#mount-keys","text":"","title":"Mount Keys"},{"location":"drive/mdkeys.html#service-key-mount","text":"Service Key Mount is used to prevent Google API Bans . To make use of this, you need to create new Keys within a different Google Project. IMPORTANT : Do not use the same Keys as for the Uploader!","title":"Service Key Mount"},{"location":"drive/mdkeys.html#setup","text":"Create new Service Account Keys (see Documentation ) Share all Keys with all Team Drives and set to Manager . Place the new Keys in opt/appdata/system/mount/keys . (You may name the Keys whatever you'd like) When Keys are present, a file named drive.csv is created under opt/appdata/system/mount . This file contains all Team Drive information from your rclone.conf located in opt/appdata/system/rclone . If you don't have an rclone.conf , you can create the drive.csv manually. Unencrypted Team Drives example: 1 = TEAM_DRIVE_NAME 2 = TEAM_DRIVE_ID TV|0AFsVct4HDKPrUk9PVvvvvvvvv TV4K|0AFsVct4HDKPrUk9PVxxxxxxxxxx Movies|0AFsVct4HDKPrUk9PVyyyyyyyyyy Movies4K|0AFsVct4HDKPrUk9PVzzzzzzzzzz ... Encrypted Team Drives example: 1 = TEAM_DRIVE_NAME 2 = TEAM_DRIVE_ID 3 = PASSWORD - <HASHED|PLAIN> 4 = PASSWORD SALT - <HASHED|PLAIN> tdrive1|0AFsVct4HDKPrUk9PVvvvvvvvv|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive2|0AFsVct4HDKPrUk9PVxxxxxxxxxx|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive3|0AFsVct4HDKPrUk9PVyyyyyyyyyy|72nsjsiwjsjsu|72nsjsiwjsjsu tdrive4|0AFsVct4HDKPrUk9PVzzzzzzzzzz|72nsjsiwjsjsu|72nsjsiwjsjsu ...","title":"Setup:"},{"location":"drive/mdkeys.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord","title":"Support"},{"location":"drive/saccounts.html","text":"Manually Creating Service Accounts \u00b6 This guide assumes you have already Created a project https://console.developers.google.com/ OAuth Consent https://console.developers.google.com/apis/credentials/consent Client ID and Secret https://console.developers.google.com/apis/credentials Enabled \"Google Drive API\" on your Project. Go to: https://console.cloud.google.com/projectselector2/iam-admin/serviceaccounts Choose your project Click \"+create service account\" name = your choice Click \"Create and continue\" Click \"Done\" To the right click actions>manage keys Add key key type = JSON Save JSON file to directory of your choice for later use repeat for as many as you wish to create rename all JSON files to: GDSA1, GDSA2, GDSA3, etc. with no file extension Now you can proceed to this portion of the migration instruction: https://dockserver.io/install/migration.html#mount-uploader Or to mount setup: https://dockserver.io/apps/system/mount.html#setup Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Service Accounts"},{"location":"drive/saccounts.html#manually-creating-service-accounts","text":"This guide assumes you have already Created a project https://console.developers.google.com/ OAuth Consent https://console.developers.google.com/apis/credentials/consent Client ID and Secret https://console.developers.google.com/apis/credentials Enabled \"Google Drive API\" on your Project. Go to: https://console.cloud.google.com/projectselector2/iam-admin/serviceaccounts Choose your project Click \"+create service account\" name = your choice Click \"Create and continue\" Click \"Done\" To the right click actions>manage keys Add key key type = JSON Save JSON file to directory of your choice for later use repeat for as many as you wish to create rename all JSON files to: GDSA1, GDSA2, GDSA3, etc. with no file extension Now you can proceed to this portion of the migration instruction: https://dockserver.io/install/migration.html#mount-uploader Or to mount setup: https://dockserver.io/apps/system/mount.html#setup","title":"Manually Creating Service Accounts"},{"location":"drive/saccounts.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"drive/tcrypt.html","text":"Creating TCrypt Remote \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"TCrypt"},{"location":"drive/tcrypt.html#creating-tcrypt-remote","text":"Wiki Coming Soon .....","title":"Creating TCrypt Remote"},{"location":"drive/tcrypt.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"drive/tdrive.html","text":"Creating Tdrive Remote \u00b6 First, install rclone if you have not: sudo apt install rclone or curl https://rclone.org/install.sh | sudo bash Then: rclone config Type n for New Remote Type tdrive Select from the list Google Drive (not Google Cloud Storage) Use the same client ID and secret from gdrive remote creation You will now Have a number of prompts: scope \u2013 type 1 and then enter root folder - Leave Blank and press Enter service_account_file - Leave this blank and press enter advanced config (y/n) - Type n and then enter auto config - Type n and then enter Copy the URL provided and paste into browser. Enter your login details and paste token into terminal. Configure this as a team drive? , type y and then enter type y for Yes this is OK You can type Q to exit The rclone.conf file will be save in /.config/rclone Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our Installation notes \u00b6 Each drive supports not more than 99 service accounts Each service account will allow 750GB of data upload per 24 hours Do NOT confuse team drive name for the actual ID To find your ID - Go to drive.google.com -> Teamdrive and copy the ID from the url example: https://drive.google.com/drive/folders/XXXXX845JTK5VXUXXXXXXXX For this example the id is XXXXX845JTK5VXUXXXXXXXX Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"TDrive"},{"location":"drive/tdrive.html#creating-tdrive-remote","text":"First, install rclone if you have not: sudo apt install rclone or curl https://rclone.org/install.sh | sudo bash Then: rclone config Type n for New Remote Type tdrive Select from the list Google Drive (not Google Cloud Storage) Use the same client ID and secret from gdrive remote creation You will now Have a number of prompts: scope \u2013 type 1 and then enter root folder - Leave Blank and press Enter service_account_file - Leave this blank and press enter advanced config (y/n) - Type n and then enter auto config - Type n and then enter Copy the URL provided and paste into browser. Enter your login details and paste token into terminal. Configure this as a team drive? , type y and then enter type y for Yes this is OK You can type Q to exit The rclone.conf file will be save in /.config/rclone","title":"Creating Tdrive Remote"},{"location":"drive/tdrive.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our","title":"Support"},{"location":"drive/tdrive.html#installation-notes","text":"Each drive supports not more than 99 service accounts Each service account will allow 750GB of data upload per 24 hours Do NOT confuse team drive name for the actual ID To find your ID - Go to drive.google.com -> Teamdrive and copy the ID from the url example: https://drive.google.com/drive/folders/XXXXX845JTK5VXUXXXXXXXX For this example the id is XXXXX845JTK5VXUXXXXXXXX","title":"Installation notes"},{"location":"drive/tdrive.html#support_1","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"install/authelia.html","text":"Authelia \u00b6 Authelia is an open-source authentication and authorization server providing 2-factor authentication and single sign-on (SSO) for your applications via a web portal. It acts as a companion of reverse proxies like nginx, Traefik or HAProxy to let them know whether queries should pass through. Unauthenticated users are redirected to Authelia Sign-in portal instead. Features summary \u00b6 Here is the list of the main available features: Several second factor methods: Security Key (U2F) with Yubikey . Time-based One-Time password with Google Authenticator . Mobile Push Notifications with Duo . Password reset with identity verification using email confirmation. Single-factor only authentication method available. Access restriction after too many authentication attempts. Fine-grained access control per subdomain, user, resource and network. Support of basic authentication for endpoints protected by single factor. Beta support for OpenID Connect . Highly available using a remote database and Redis as a highly available KV store. Compatible with Kubernetes ingress-nginx controller out of the box. For more details about the features, follow Features . If you want to know more about the roadmap, follow Roadmap . Installation and Setup \u00b6 Authelia is deployed via the DockServer main menu, option [ 1 ] Dockserver - Traefik + Authelia Follow the Instructions Two-Factor Authentication (2FA) (Optional) \u00b6 Requirements \u00b6 Authelia deployed via DockServer menu Authenticator app ( Google Authenticator , 1Password , Authy , AndOTP , etc ...) 2FA Setup \u00b6 Once Authelia is deployed, open it's configuration file: sudo nano /opt/appdata/authelia/configuration.yml Change the following: totp: issuer: authelia to: totp: issuer: authelia period: 30 skew: 1 Scroll further and change the following: ## one factor login - domain: \"*.YOURDOMAIN.COM\" policy: one_factor to this: ## two factor login - domain: \"*.YOURDOMAIN.COM\" policy: two_factor Save and exit by typing CTRL + X , then Y . Restart the container: sudo docker restart authelia Now visit https://authelia.YOURDOMAIN.com and login with the username/password. You'll be presented with a screen saying you need to register your device for TOTP. Click \"Not registered yet?\" and a message will appear on screen saying \"An email has been sent to your address to complete the process\" . As we didn't set up SMTP, no email has been sent. However, the link you need to continue the setup can be found here: cat /opt/appdata/authelia/notification.txt Copy and paste the URL found in this file into your browser, and then scan the QR code with your favourite OTP app ( Google Authenticator , 1Password , Authy , AndOTP , etc). Follow the setup instructions in your app, and enter the 6-digit OTP in Authelia. Congrats, you've got 2FA setup with Authelia! Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support License \u00b6 Authelia is licensed under the Apache 2.0 license. The terms of the license are detailed in LICENSE .","title":"Authelia"},{"location":"install/authelia.html#authelia","text":"Authelia is an open-source authentication and authorization server providing 2-factor authentication and single sign-on (SSO) for your applications via a web portal. It acts as a companion of reverse proxies like nginx, Traefik or HAProxy to let them know whether queries should pass through. Unauthenticated users are redirected to Authelia Sign-in portal instead.","title":"Authelia"},{"location":"install/authelia.html#features-summary","text":"Here is the list of the main available features: Several second factor methods: Security Key (U2F) with Yubikey . Time-based One-Time password with Google Authenticator . Mobile Push Notifications with Duo . Password reset with identity verification using email confirmation. Single-factor only authentication method available. Access restriction after too many authentication attempts. Fine-grained access control per subdomain, user, resource and network. Support of basic authentication for endpoints protected by single factor. Beta support for OpenID Connect . Highly available using a remote database and Redis as a highly available KV store. Compatible with Kubernetes ingress-nginx controller out of the box. For more details about the features, follow Features . If you want to know more about the roadmap, follow Roadmap .","title":"Features summary"},{"location":"install/authelia.html#installation-and-setup","text":"Authelia is deployed via the DockServer main menu, option [ 1 ] Dockserver - Traefik + Authelia Follow the Instructions","title":"Installation and Setup"},{"location":"install/authelia.html#two-factor-authentication-2fa-optional","text":"","title":"Two-Factor Authentication (2FA) (Optional)"},{"location":"install/authelia.html#requirements","text":"Authelia deployed via DockServer menu Authenticator app ( Google Authenticator , 1Password , Authy , AndOTP , etc ...)","title":"Requirements"},{"location":"install/authelia.html#2fa-setup","text":"Once Authelia is deployed, open it's configuration file: sudo nano /opt/appdata/authelia/configuration.yml Change the following: totp: issuer: authelia to: totp: issuer: authelia period: 30 skew: 1 Scroll further and change the following: ## one factor login - domain: \"*.YOURDOMAIN.COM\" policy: one_factor to this: ## two factor login - domain: \"*.YOURDOMAIN.COM\" policy: two_factor Save and exit by typing CTRL + X , then Y . Restart the container: sudo docker restart authelia Now visit https://authelia.YOURDOMAIN.com and login with the username/password. You'll be presented with a screen saying you need to register your device for TOTP. Click \"Not registered yet?\" and a message will appear on screen saying \"An email has been sent to your address to complete the process\" . As we didn't set up SMTP, no email has been sent. However, the link you need to continue the setup can be found here: cat /opt/appdata/authelia/notification.txt Copy and paste the URL found in this file into your browser, and then scan the QR code with your favourite OTP app ( Google Authenticator , 1Password , Authy , AndOTP , etc). Follow the setup instructions in your app, and enter the 6-digit OTP in Authelia. Congrats, you've got 2FA setup with Authelia!","title":"2FA Setup"},{"location":"install/authelia.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"install/authelia.html#license","text":"Authelia is licensed under the Apache 2.0 license. The terms of the license are detailed in LICENSE .","title":"License"},{"location":"install/cf-companion.html","text":"CF-Companion \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"cf-companion"},{"location":"install/cf-companion.html#cf-companion","text":"Wiki Coming Soon .....","title":"CF-Companion"},{"location":"install/cf-companion.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"install/changelog.html","text":"CHANGELOG \u00b6 v1.4.72 - 2024-10-08 08:01:04 \u00b6 repository changes v1.4.71 - 2024-09-27 05:49:46 \u00b6 feat: add error-pages as extra PR: #715 Feature \u00b6 general: add error-pages as extra ( #715 ) ( 4f1670a ) ( #715 ) v1.4.70 - 2024-09-26 10:27:56 \u00b6 CleanUP Github Actions PR: #711 chore(deps): update mikepenz/release-changelog-builder-action action to v5 PR: #712 feat: Update Traefik to V3 PR: #714 Feature \u00b6 general: Update Traefik to V3 ( #714 ) ( dcd3773 ) ( #714 ) v1.4.69 - 2024-06-05 06:56:21 \u00b6 v1.4.68 - 2024-05-05 16:50:59 \u00b6 v1.4.67 - 2024-04-24 15:41:50 \u00b6 v1.4.66 - 2024-03-16 18:30:39 \u00b6 v1.4.65 - 2023-10-13 16:41:04 \u00b6 repository changes v1.4.63 - 2023-10-13 14:16:53 \u00b6 chore(deps): update step-security/harden-runner digest to 1b05615 PR: #665 v1.4.62 - 2023-10-02 10:51:18 \u00b6 Plex-VPN PR: #664 v1.4.61 - 2023-10-02 08:55:21 \u00b6 v1.4.60 - 2023-09-24 14:49:36 \u00b6 repository changes v1.4.59 - 2023-09-23 18:10:18 \u00b6 chore(deps): update actions/checkout action to v4.1.0 PR: #661 v1.4.58 - 2023-09-20 09:57:35 \u00b6 repository changes v1.4.57 - 2023-09-20 09:40:07 \u00b6 chore(deps): update aquasecurity/trivy-action digest to 69cbbc0 PR: #656 chore(deps): update step-security/harden-runner digest to 2e205a2 PR: #657 chore(deps): update step-security/harden-runner action to v2 PR: #659 v1.4.56 - 2023-09-18 05:53:55 \u00b6 v1.4.54 - 2023-05-26 15:30:39 \u00b6 repository changes v1.4.53 - 2023-05-26 08:05:18 \u00b6 v1.4.52 - 2023-05-19 05:16:31 \u00b6 repository changes v1.4.51 - 2023-05-18 12:33:03 \u00b6 v1.4.50 - 2023-05-11 13:55:34 \u00b6 v1.4.49 - 2023-03-17 06:20:25 \u00b6 v1.4.48 - 2023-02-28 20:17:37 \u00b6 v1.4.47 - 2023-02-08 08:16:30 \u00b6 bugfix: Fix GPU Install ( #598 PR: #598 v1.4.45 - 2023-02-06 17:34:01 \u00b6 repository changes v1.4.43 - 2023-02-06 13:57:31 \u00b6 repository changes v1.4.42 - 2023-02-06 10:32:45 \u00b6 repository changes v1.4.41 - 2023-02-02 20:39:39 \u00b6 v1.4.39 - 2023-01-28 23:16:28 \u00b6 repository changes v1.4.38 - 2023-01-28 23:02:38 \u00b6 v1.4.37 - 2023-01-11 16:53:52 \u00b6 repository changes v1.4.36 - 2023-01-11 10:54:38 \u00b6 repository changes v1.4.35 - 2023-01-10 11:29:01 \u00b6 v1.4.34 - 2023-01-02 18:29:10 \u00b6 v1.4.33 - 2022-12-22 11:18:33 \u00b6 v1.4.32 - 2022-12-11 09:07:52 \u00b6 v1.4.31 - 2022-12-08 16:01:46 \u00b6 v1.4.30 - 2022-11-20 01:49:28 \u00b6 repository changes Documentation \u00b6 README: update contributors ( 4983328 ) update contributors ( 0e9631a ) v1.4.29 - 2022-11-19 19:52:10 \u00b6 [ImgBot] Optimize images PR: #570 uploader.md PR: #571 Create sync.yml PR: #573 Documentation \u00b6 README: update contributors ( 1eb50b9 ) update contributors ( 27f547f ) v1.4.28 - 2022-11-12 11:35:13 \u00b6 repository changes Feature \u00b6 general: add bypass rule for xbvr app ( #518 ) ( 112b16d ) ( #518 ) Bug Fixes \u00b6 general: Build Status, GitHub release ( #520 ) ( 9b129c1 ) ( #520 ) Fix Wiki Docs ( 2398586 ) fix whisparr.yml ( #464 ) ( 54fd4d2 ) ( #464 ) Documentation \u00b6 README: update contributors ( a4d2dc2 ) update contributors ( e6f4024 ) update contributors ( 0cb2b9c ) update contributors ( afee1ea ) update contributors ( 0eb0e73 ) update contributors ( 2a5357e ) update contributors ( 91c0759 ) update contributors ( aa6271c ) update contributors ( 92ff03e ) update contributors ( 9dfd313 ) update contributors ( e59ca3a ) update contributors ( b970fbf ) update contributors ( c349e0b ) update contributors ( 62e3f64 ) update contributors ( e4490d9 ) update contributors ( 033736f ) update contributors ( d2cfacf ) update contributors ( fd94c13 ) update contributors ( a44bb8e ) update contributors ( 6c81a29 ) update contributors ( 569b4da ) update contributors ( 5df1155 ) update contributors ( fb638e9 ) update contributors ( 6be3143 ) update contributors ( e635d21 ) update contributors ( 7678b7f ) update contributors ( b0dd009 ) update contributors ( 2f79634 ) update contributors ( 9d42020 ) update contributors ( b6adee2 ) update contributors ( 68fa257 ) update contributors ( c82ed5f ) update contributors ( ab06206 ) update contributors ( b9090ef ) update contributors ( 40d0997 ) update contributors ( d448743 ) update contributors ( 30e2f49 ) update contributors ( ec2a2dc ) update contributors ( 9614050 ) update contributors ( 9625b42 ) update contributors ( e6fc278 ) update contributors ( bf03f04 ) update contributors ( 9de6872 ) update contributors ( 7088768 ) update contributors ( 8948131 ) update contributors ( ae05cec ) update contributors ( 000f78b ) update contributors ( 26ee0ca ) v1.4.25 - 2022-03-20 01:08:56 \u00b6 repository changes v1.4.24 - 2022-03-15 21:24:00 \u00b6 v1.4.23 - 2022-03-13 18:47:10 \u00b6 v1.4.22 - 2022-03-13 01:58:55 \u00b6 repository changes v1.4.21 - 2022-03-13 01:50:21 \u00b6 repository changes v1.4.20 - 2022-03-13 00:50:52 \u00b6 v1.4.19 - 2022-03-06 01:43:18 \u00b6 repository changes v1.4.18 - 2022-03-06 00:51:05 \u00b6 v1.4.17 - 2022-02-27 02:12:34 \u00b6 repository changes v1.4.16 - 2022-02-27 01:41:36 \u00b6 repository changes v1.4.15 - 2022-02-27 00:44:37 \u00b6 v1.4.14 - 2022-02-20 01:39:13 \u00b6 repository changes v1.4.13 - 2022-02-20 00:14:13 \u00b6 v1.4.12 - 2022-02-13 16:16:14 \u00b6 repository changes v1.4.11 - 2022-02-13 05:22:57 \u00b6 repository changes v1.4.10 - 2022-02-13 00:01:28 \u00b6 v1.4.9 - 2022-02-06 07:51:59 \u00b6 repository changes v1.4.8 - 2022-02-06 00:25:14 \u00b6 v1.4.7 - 2022-02-02 15:19:53 \u00b6 repository changes v1.4.6 - 2022-02-02 13:43:22 \u00b6 repository changes v1.4.5 - 2022-02-02 12:08:04 \u00b6 v1.4.4 - 2022-01-31 06:41:42 \u00b6 repository changes v1.4.3 - 2022-01-30 02:00:01 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.4.2...v1.4.3 v1.4.2 - 2022-01-28 14:01:44 \u00b6 v1.4.1 - 2022-01-23 15:49:41 \u00b6 v1.4.0 - 2022-01-17 12:22:31 \u00b6 v1.3.34 - 2021-12-20 08:02:00 \u00b6 repository changes v1.3.33 - 2021-12-19 12:09:52 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.32...v1.3.33 Feature \u00b6 general: feat ( switch ) move away from.git clone ( d92d6c1 ) Bug Fixes \u00b6 general: fix ( add ) log command ( 1b7c3d4 ) v1.3.32 - 2021-12-19 02:35:50 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.31...v1.3.32 v1.3.31 - 2021-12-19 02:28:00 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.30...v1.3.31 v1.3.30 - 2021-12-19 02:16:44 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.29...v1.3.30 v1.3.29 - 2021-12-19 02:08:45 \u00b6 v1.3.28 - 2021-12-18 04:24:28 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.27...v1.3.28 v1.3.27 - 2021-12-18 04:24:10 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.26...v1.3.27 v1.3.26 - 2021-12-18 04:12:55 \u00b6 v1.3.25 - 2021-12-17 21:51:16 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.24...v1.3.25 v1.3.24 - 2021-12-17 21:39:49 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.23...v1.3.24 v1.3.23 - 2021-12-17 21:23:17 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.22...v1.3.23 v1.3.22 - 2021-12-17 21:22:28 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.21...v1.3.22 v1.3.21 - 2021-12-17 21:19:31 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.20...v1.3.21 v1.3.20 - 2021-12-17 21:13:56 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.19...v1.3.20 v1.3.19 - 2021-12-17 07:36:37 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.18...v1.3.19 v1.3.18 - 2021-12-17 07:25:11 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.17...v1.3.18 v1.3.16 - 2021-12-17 06:26:21 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.15...v1.3.16 v1.3.15 - 2021-12-17 06:19:19 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.14...v1.3.15 v1.3.14 - 2021-12-17 04:56:53 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.13...v1.3.14 v1.3.13 - 2021-12-17 04:45:27 \u00b6 v1.3.12 - 2021-12-15 17:18:19 \u00b6 v1.3.11 - 2021-12-14 07:23:55 \u00b6 repository changes v1.3.10 - 2021-12-14 07:22:44 \u00b6 repository changes v1.3.9 - 2021-12-14 07:18:49 \u00b6 repository changes v1.3.8 - 2021-12-13 22:11:57 \u00b6 repository changes v1.3.7 - 2021-12-13 22:00:15 \u00b6 v1.3.6 - 2021-12-12 17:22:36 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.5...v1.3.6 v1.3.5 - 2021-12-12 17:11:27 \u00b6 v1.3.4 - 2021-12-12 16:06:50 \u00b6 repository changes v1.3.3 - 2021-12-12 15:56:41 \u00b6 repository changes v1.3.2 - 2021-12-12 12:29:08 \u00b6 repository changes v1.3.1 - 2021-12-12 11:24:43 \u00b6 repository changes v1.3.0 - 2021-12-12 10:14:31 \u00b6 repository changes v1.2.52 - 2021-12-12 10:03:21 \u00b6 v1.2.51 - 2021-12-07 15:01:11 \u00b6 v1.2.50 - 2021-11-29 15:49:55 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.49...v1.2.50 v1.2.49 - 2021-11-29 00:58:16 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.48...v1.2.49 Documentation \u00b6 README: update contributors ( 24bff1a ) update contributors ( e055da1 ) v1.2.48 - 2021-11-27 07:01:54 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.47...v1.2.48 v1.2.47 - 2021-11-24 18:34:59 \u00b6 chore(deps): update dependency mkdocs-macros-plugin to v0.6.2 PR: #299 chore(deps): update dependency mkdocs-macros-plugin to v0.6.3 PR: #301 Feature \u00b6 general: ( add ) WebUI back to Uploader ( e851a0c ) Documentation \u00b6 README: update contributors ( 85d257d ) update contributors ( 4f35156 ) v1.2.46 - 2021-11-23 13:47:46 \u00b6 chore(deps): update actions/cache action to v2.1.7 PR: #298 Documentation \u00b6 README: update contributors ( f8654ef ) update contributors ( 43c3183 ) v1.2.45 - 2021-11-22 19:15:59 \u00b6 chore(deps): update dependency mkdocs-awesome-pages-plugin to v2.6.1 PR: #297 Documentation \u00b6 README: update contributors ( a012850 ) update contributors ( e2949f1 ) v1.2.44 - 2021-11-21 22:53:42 \u00b6 v1.2.43 - 2021-11-18 22:47:45 \u00b6 v1.2.42 - 2021-11-17 12:36:27 \u00b6 v1.2.41 - 2021-11-13 17:47:58 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.40...v1.2.41 Documentation \u00b6 README: update contributors ( fc9d0c4 ) update contributors ( 84c42a8 ) v1.2.40 - 2021-11-13 10:23:36 \u00b6 docs(wiki): update tauticord PR: #283 v1.2.39 - 2021-11-10 17:16:53 \u00b6 chore(deps): update dependency mkdocs-git-revision-date-localized-plugin to v0.10.2 PR: #282 v1.2.38 - 2021-11-09 06:22:34 \u00b6 v1.2.37 - 2021-11-08 13:39:41 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.36...v1.2.37 Documentation \u00b6 README: update contributors ( 0b38588 ) update contributors ( e621e04 ) update contributors ( 415174b ) v1.2.36 - 2021-11-07 04:42:42 \u00b6 ci(Mergify): configuration update PR: #274 Configure Renovate PR: #276 chore(deps): update actions/checkout action to v2.4.0 PR: #277 v1.2.35 - 2021-11-06 07:16:12 \u00b6 repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.34...v1.2.35 Bug Fixes \u00b6 general: use version numbers for images ( 82dec0b ) v1.2.34 - 2021-11-05 10:34:31 \u00b6 other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.33...v1.2.34 v1.2.33 - 2021-11-04 17:51:56 \u00b6 v1.2.32 - 2021-11-03 10:18:10 \u00b6 v1.2.31 - 2021-11-02 07:57:53 \u00b6 v1.2.30 - 2021-11-01 03:45:13 \u00b6 Create LICENSE PR: #265 Create LICENSE PR: #266 v1.2.29 - 2021-10-31 10:48:58 \u00b6 other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.28...v1.2.29 v1.2.28 - 2021-10-30 11:13:04 \u00b6 v1.2.27 - 2021-10-29 04:03:47 \u00b6 Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.26...v1.2.27 v1.2.26 - 2021-10-28 07:39:34 \u00b6 other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.25...v1.2.26 Bug Fixes \u00b6 general: nzb/torrent folder ( fe896e6 ) v1.2.25 - 2021-10-26 05:34:11 \u00b6 v1.2.24 - 2021-10-25 09:26:59 \u00b6 v1.2.23 - 2021-10-24 07:12:26 \u00b6 v1.2.22 - 2021-10-23 09:00:01 \u00b6 other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.21...v1.2.22 v1.2.21 - 2021-10-23 01:37:38 \u00b6 v1.2.20 - 2021-10-19 10:26:26 \u00b6 v1.2.19 - 2021-10-18 08:12:31 \u00b6 other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.18...v1.2.19 v1.2.18 - 2021-10-16 02:50:05 \u00b6 other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.17...v1.2.18 Bug Fixes \u00b6 general: faster backups ( 46891f6 ) v1.2.17 - 2021-10-15 07:08:41 \u00b6 other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.16...v1.2.17 v1.2.16 - 2021-10-15 05:54:40 \u00b6 v1.2.15 - 2021-10-13 06:13:16 \u00b6 v1.2.14 - 2021-10-12 03:54:43 \u00b6 v1.2.13 - 2021-10-11 15:35:05 \u00b6 v1.2.12 - 2021-10-10 14:02:35 \u00b6 v1.2.11 - 2021-10-07 12:23:09 \u00b6 v1.2.10 - 2021-10-07 11:03:28 \u00b6 Revert Back to v1.2.9 Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.9...v1.2.10 v1.2.9 - 2021-09-24 09:10:35 \u00b6 no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.8...v1.2.9 v1.2.8 - 2021-09-22 16:12:27 \u00b6 no changes v1.2.7 - 2021-09-22 10:35:11 \u00b6 no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.6...v1.2.7 v1.2.6 - 2021-09-16 15:58:08 \u00b6 no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.5...v1.2.6 v1.2.5 - 2021-09-16 11:36:37 \u00b6 no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.4...v1.2.5 v1.2.4 - 2021-09-12 18:35:18 \u00b6 no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.3...v1.2.4 v1.2.3 - 2021-08-29 10:00:30 \u00b6 pip-update(deps): bump mkdocs-material from 7.2.4 to 7.2.5 in /wiki PR: #199 v1.2.2 - 2021-08-24 07:07:21 \u00b6 Fixed Indentation | Removed Trailing whitespaces PR: #190 Create notifiarr.md PR: #193 Create notifiarr.yml PR: #192 GH updates(deps): Bump docker/build-push-action from 2.6.1 to 2.7.0 PR: #194 Added glances PR: #195 SET Global NameServers NS1 & NS2 PR: #197 pip-update(deps): bump mkdocs-macros-plugin from 0.5.12 to 0.6.0 in /wiki PR: #198 v1.2.1 - 2021-08-19 17:45:21 \u00b6 Create pihole-updatelists.yml PR: #184 Create deemix.yml PR: #186 Hardcoded values removed PR: #188 v1.2.0 - 2021-08-19 07:22:31 \u00b6 pip-update(deps): bump pygments from 2.9.0 to 2.10.0 in /wiki PR: #185 v1.1.15 - 2021-08-16 07:12:39 \u00b6 no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.1.14...v1.1.15 v1.1.14 - 2021-08-14 13:47:59 \u00b6 no changes v1.1.13 - 2021-08-12 21:42:11 \u00b6 pip-update(deps): bump mkdocs-material from 7.2.3 to 7.2.4 in /wiki PR: #177 v1.1.12 - 2021-08-10 18:47:53 \u00b6 no changes v1.1.11 - 2021-08-10 18:03:43 \u00b6 Full Changelog : https://github.com/dockserver/dockserver/compare/v1.1.10...v1.1.11 v1.1.10 - 2021-08-10 00:45:43 \u00b6 no changes v1.1.9 - 2021-08-08 17:18:32 \u00b6 Uncategorized - #MYSQL IMAGE CHANGE - PR: #170 v1.1.8 - 2021-08-05 15:13:20 \u00b6 Dev PR: #74 GH updates(deps): Bump mikepenz/release-changelog-builder-action from 1 to 2 PR: #77 GH updates(deps): Bump docker/login-action from 1.9.0 to 1.10.0 PR: #78 Dev PR: #76 Update portainer.md PR: #80 Update dozzle.md PR: #79 Update lidarr.md PR: #82 Update heimdall.md PR: #81 mariadb container for e.g. nextcloud PR: #84 Create instaloader.yml PR: #85 Update mellow.md PR: #92 Update conreq.md PR: #93 pip-update(deps): bump mkdocs-material from 7.1.8 to 7.1.9 in /wiki PR: #100 Update instaloader.yml PR: #99 Update jackett.md PR: #101 Update tdarr.md PR: #127 Update handbrake.yml PR: #126 Update youtubedl-material.md PR: #125 Update qbittorrent.md PR: #124 Update sabnzbd.md PR: #123 Update rutorrent.md PR: #122 Update nzbhydra.md PR: #121 Update nzbget.md PR: #120 Update jdownloader2.md PR: #118 Update filezilla.md PR: #117 Update deluge.md PR: #116 Update davos.md PR: #115 Update code-server.md PR: #114 Update cloud9.md PR: #113 Update rsnapshot.md PR: #112 Update duplicati.md PR: #111 Update backup.md PR: #110 Update vnstat.md PR: #109 Update speedtest.md PR: #108 Update remmina.md PR: #107 Update netdata.md PR: #106 Update librespeed.md PR: #105 Update flaresolverr.md PR: #104 Update cloudcmd.md PR: #103 Update mount.md PR: #90 Update instaloader.yml PR: #102 Update jackett.md PR: #119 GH updates(deps): Bump docker/setup-buildx-action from 1.3.0 to 1.4.1 PR: #129 Patch 11 PR: #133 Create kitana.yml PR: #131 Create kitana.md PR: #130 GH updates(deps): Bump docker/build-push-action from 2.5.0 to 2.6.1 PR: #135 Patch 12 PR: #136 GH updates(deps): Bump docker/setup-buildx-action from 1.4.1 to 1.5.0 PR: #138 pip-update(deps): bump mkdocs-material from 7.1.9 to 7.1.10 in /wiki PR: #146 GH updates(deps): Bump docker/setup-buildx-action from 1.5.0 to 1.5.1 PR: #145 GH updates(deps): Bump actions/stale from 3.0.19 to 4 PR: #147 pip-update(deps): bump mkdocs-material from 7.1.10 to 7.1.11 in /wiki PR: #149 pip-update(deps): bump mkdocs from 1.2.1 to 1.2.2 in /wiki PR: #150 pip-update(deps): bump mkdocs-material from 7.1.11 to 7.2.0 in /wiki PR: #152 pip-update(deps): bump mkdocs-material from 7.2.0 to 7.2.1 in /wiki PR: #155 Create fail2ban.yml PR: #156 pip-update(deps): bump mkdocs-material from 7.2.1 to 7.2.2 in /wiki PR: #161 Pihole + Unbound (two containers) | Pihole + Unbound (one container) PR: #160 Add TCP BBR PR: #164 patch Update code-server.yml \u00b6 PR: #165 v1.1.7 - 2021-06-23 11:40:42 \u00b6 no changes v1.1.6 - 2021-06-13 15:57:10 \u00b6 Full Changelog : https://github.com/dockserver/dockserver/compare/v1.1.5...v1.1.6 v1.1.5 - 2021-06-12 16:54:42 \u00b6 v1.1.4 - 2021-06-12 10:23:47 \u00b6 v1.1.3 - 2021-06-11 20:57:46 \u00b6 v1.1.2 - 2021-06-09 21:28:14 \u00b6 v1.1.1 - 2021-06-09 18:27:31 \u00b6 v1.1.0 - 2021-06-09 17:08:59 \u00b6 v1.0.0 - 2021-06-02 18:03:21 \u00b6 * This CHANGELOG was automatically generated by auto-generate-changelog","title":"Changelog"},{"location":"install/changelog.html#changelog","text":"","title":"CHANGELOG"},{"location":"install/changelog.html#v1472-2024-10-08-080104","text":"repository changes","title":"v1.4.72 - 2024-10-08 08:01:04"},{"location":"install/changelog.html#v1471-2024-09-27-054946","text":"feat: add error-pages as extra PR: #715","title":"v1.4.71 - 2024-09-27 05:49:46"},{"location":"install/changelog.html#feature","text":"general: add error-pages as extra ( #715 ) ( 4f1670a ) ( #715 )","title":"Feature"},{"location":"install/changelog.html#v1470-2024-09-26-102756","text":"CleanUP Github Actions PR: #711 chore(deps): update mikepenz/release-changelog-builder-action action to v5 PR: #712 feat: Update Traefik to V3 PR: #714","title":"v1.4.70 - 2024-09-26 10:27:56"},{"location":"install/changelog.html#feature_1","text":"general: Update Traefik to V3 ( #714 ) ( dcd3773 ) ( #714 )","title":"Feature"},{"location":"install/changelog.html#v1469-2024-06-05-065621","text":"","title":"v1.4.69 - 2024-06-05 06:56:21"},{"location":"install/changelog.html#v1468-2024-05-05-165059","text":"","title":"v1.4.68 - 2024-05-05 16:50:59"},{"location":"install/changelog.html#v1467-2024-04-24-154150","text":"","title":"v1.4.67 - 2024-04-24 15:41:50"},{"location":"install/changelog.html#v1466-2024-03-16-183039","text":"","title":"v1.4.66 - 2024-03-16 18:30:39"},{"location":"install/changelog.html#v1465-2023-10-13-164104","text":"repository changes","title":"v1.4.65 - 2023-10-13 16:41:04"},{"location":"install/changelog.html#v1463-2023-10-13-141653","text":"chore(deps): update step-security/harden-runner digest to 1b05615 PR: #665","title":"v1.4.63 - 2023-10-13 14:16:53"},{"location":"install/changelog.html#v1462-2023-10-02-105118","text":"Plex-VPN PR: #664","title":"v1.4.62 - 2023-10-02 10:51:18"},{"location":"install/changelog.html#v1461-2023-10-02-085521","text":"","title":"v1.4.61 - 2023-10-02 08:55:21"},{"location":"install/changelog.html#v1460-2023-09-24-144936","text":"repository changes","title":"v1.4.60 - 2023-09-24 14:49:36"},{"location":"install/changelog.html#v1459-2023-09-23-181018","text":"chore(deps): update actions/checkout action to v4.1.0 PR: #661","title":"v1.4.59 - 2023-09-23 18:10:18"},{"location":"install/changelog.html#v1458-2023-09-20-095735","text":"repository changes","title":"v1.4.58 - 2023-09-20 09:57:35"},{"location":"install/changelog.html#v1457-2023-09-20-094007","text":"chore(deps): update aquasecurity/trivy-action digest to 69cbbc0 PR: #656 chore(deps): update step-security/harden-runner digest to 2e205a2 PR: #657 chore(deps): update step-security/harden-runner action to v2 PR: #659","title":"v1.4.57 - 2023-09-20 09:40:07"},{"location":"install/changelog.html#v1456-2023-09-18-055355","text":"","title":"v1.4.56 - 2023-09-18 05:53:55"},{"location":"install/changelog.html#v1454-2023-05-26-153039","text":"repository changes","title":"v1.4.54 - 2023-05-26 15:30:39"},{"location":"install/changelog.html#v1453-2023-05-26-080518","text":"","title":"v1.4.53 - 2023-05-26 08:05:18"},{"location":"install/changelog.html#v1452-2023-05-19-051631","text":"repository changes","title":"v1.4.52 - 2023-05-19 05:16:31"},{"location":"install/changelog.html#v1451-2023-05-18-123303","text":"","title":"v1.4.51 - 2023-05-18 12:33:03"},{"location":"install/changelog.html#v1450-2023-05-11-135534","text":"","title":"v1.4.50 - 2023-05-11 13:55:34"},{"location":"install/changelog.html#v1449-2023-03-17-062025","text":"","title":"v1.4.49 - 2023-03-17 06:20:25"},{"location":"install/changelog.html#v1448-2023-02-28-201737","text":"","title":"v1.4.48 - 2023-02-28 20:17:37"},{"location":"install/changelog.html#v1447-2023-02-08-081630","text":"bugfix: Fix GPU Install ( #598 PR: #598","title":"v1.4.47 - 2023-02-08 08:16:30"},{"location":"install/changelog.html#v1445-2023-02-06-173401","text":"repository changes","title":"v1.4.45 - 2023-02-06 17:34:01"},{"location":"install/changelog.html#v1443-2023-02-06-135731","text":"repository changes","title":"v1.4.43 - 2023-02-06 13:57:31"},{"location":"install/changelog.html#v1442-2023-02-06-103245","text":"repository changes","title":"v1.4.42 - 2023-02-06 10:32:45"},{"location":"install/changelog.html#v1441-2023-02-02-203939","text":"","title":"v1.4.41 - 2023-02-02 20:39:39"},{"location":"install/changelog.html#v1439-2023-01-28-231628","text":"repository changes","title":"v1.4.39 - 2023-01-28 23:16:28"},{"location":"install/changelog.html#v1438-2023-01-28-230238","text":"","title":"v1.4.38 - 2023-01-28 23:02:38"},{"location":"install/changelog.html#v1437-2023-01-11-165352","text":"repository changes","title":"v1.4.37 - 2023-01-11 16:53:52"},{"location":"install/changelog.html#v1436-2023-01-11-105438","text":"repository changes","title":"v1.4.36 - 2023-01-11 10:54:38"},{"location":"install/changelog.html#v1435-2023-01-10-112901","text":"","title":"v1.4.35 - 2023-01-10 11:29:01"},{"location":"install/changelog.html#v1434-2023-01-02-182910","text":"","title":"v1.4.34 - 2023-01-02 18:29:10"},{"location":"install/changelog.html#v1433-2022-12-22-111833","text":"","title":"v1.4.33 - 2022-12-22 11:18:33"},{"location":"install/changelog.html#v1432-2022-12-11-090752","text":"","title":"v1.4.32 - 2022-12-11 09:07:52"},{"location":"install/changelog.html#v1431-2022-12-08-160146","text":"","title":"v1.4.31 - 2022-12-08 16:01:46"},{"location":"install/changelog.html#v1430-2022-11-20-014928","text":"repository changes","title":"v1.4.30 - 2022-11-20 01:49:28"},{"location":"install/changelog.html#documentation","text":"README: update contributors ( 4983328 ) update contributors ( 0e9631a )","title":"Documentation"},{"location":"install/changelog.html#v1429-2022-11-19-195210","text":"[ImgBot] Optimize images PR: #570 uploader.md PR: #571 Create sync.yml PR: #573","title":"v1.4.29 - 2022-11-19 19:52:10"},{"location":"install/changelog.html#documentation_1","text":"README: update contributors ( 1eb50b9 ) update contributors ( 27f547f )","title":"Documentation"},{"location":"install/changelog.html#v1428-2022-11-12-113513","text":"repository changes","title":"v1.4.28 - 2022-11-12 11:35:13"},{"location":"install/changelog.html#feature_2","text":"general: add bypass rule for xbvr app ( #518 ) ( 112b16d ) ( #518 )","title":"Feature"},{"location":"install/changelog.html#bug-fixes","text":"general: Build Status, GitHub release ( #520 ) ( 9b129c1 ) ( #520 ) Fix Wiki Docs ( 2398586 ) fix whisparr.yml ( #464 ) ( 54fd4d2 ) ( #464 )","title":"Bug Fixes"},{"location":"install/changelog.html#documentation_2","text":"README: update contributors ( a4d2dc2 ) update contributors ( e6f4024 ) update contributors ( 0cb2b9c ) update contributors ( afee1ea ) update contributors ( 0eb0e73 ) update contributors ( 2a5357e ) update contributors ( 91c0759 ) update contributors ( aa6271c ) update contributors ( 92ff03e ) update contributors ( 9dfd313 ) update contributors ( e59ca3a ) update contributors ( b970fbf ) update contributors ( c349e0b ) update contributors ( 62e3f64 ) update contributors ( e4490d9 ) update contributors ( 033736f ) update contributors ( d2cfacf ) update contributors ( fd94c13 ) update contributors ( a44bb8e ) update contributors ( 6c81a29 ) update contributors ( 569b4da ) update contributors ( 5df1155 ) update contributors ( fb638e9 ) update contributors ( 6be3143 ) update contributors ( e635d21 ) update contributors ( 7678b7f ) update contributors ( b0dd009 ) update contributors ( 2f79634 ) update contributors ( 9d42020 ) update contributors ( b6adee2 ) update contributors ( 68fa257 ) update contributors ( c82ed5f ) update contributors ( ab06206 ) update contributors ( b9090ef ) update contributors ( 40d0997 ) update contributors ( d448743 ) update contributors ( 30e2f49 ) update contributors ( ec2a2dc ) update contributors ( 9614050 ) update contributors ( 9625b42 ) update contributors ( e6fc278 ) update contributors ( bf03f04 ) update contributors ( 9de6872 ) update contributors ( 7088768 ) update contributors ( 8948131 ) update contributors ( ae05cec ) update contributors ( 000f78b ) update contributors ( 26ee0ca )","title":"Documentation"},{"location":"install/changelog.html#v1425-2022-03-20-010856","text":"repository changes","title":"v1.4.25 - 2022-03-20 01:08:56"},{"location":"install/changelog.html#v1424-2022-03-15-212400","text":"","title":"v1.4.24 - 2022-03-15 21:24:00"},{"location":"install/changelog.html#v1423-2022-03-13-184710","text":"","title":"v1.4.23 - 2022-03-13 18:47:10"},{"location":"install/changelog.html#v1422-2022-03-13-015855","text":"repository changes","title":"v1.4.22 - 2022-03-13 01:58:55"},{"location":"install/changelog.html#v1421-2022-03-13-015021","text":"repository changes","title":"v1.4.21 - 2022-03-13 01:50:21"},{"location":"install/changelog.html#v1420-2022-03-13-005052","text":"","title":"v1.4.20 - 2022-03-13 00:50:52"},{"location":"install/changelog.html#v1419-2022-03-06-014318","text":"repository changes","title":"v1.4.19 - 2022-03-06 01:43:18"},{"location":"install/changelog.html#v1418-2022-03-06-005105","text":"","title":"v1.4.18 - 2022-03-06 00:51:05"},{"location":"install/changelog.html#v1417-2022-02-27-021234","text":"repository changes","title":"v1.4.17 - 2022-02-27 02:12:34"},{"location":"install/changelog.html#v1416-2022-02-27-014136","text":"repository changes","title":"v1.4.16 - 2022-02-27 01:41:36"},{"location":"install/changelog.html#v1415-2022-02-27-004437","text":"","title":"v1.4.15 - 2022-02-27 00:44:37"},{"location":"install/changelog.html#v1414-2022-02-20-013913","text":"repository changes","title":"v1.4.14 - 2022-02-20 01:39:13"},{"location":"install/changelog.html#v1413-2022-02-20-001413","text":"","title":"v1.4.13 - 2022-02-20 00:14:13"},{"location":"install/changelog.html#v1412-2022-02-13-161614","text":"repository changes","title":"v1.4.12 - 2022-02-13 16:16:14"},{"location":"install/changelog.html#v1411-2022-02-13-052257","text":"repository changes","title":"v1.4.11 - 2022-02-13 05:22:57"},{"location":"install/changelog.html#v1410-2022-02-13-000128","text":"","title":"v1.4.10 - 2022-02-13 00:01:28"},{"location":"install/changelog.html#v149-2022-02-06-075159","text":"repository changes","title":"v1.4.9 - 2022-02-06 07:51:59"},{"location":"install/changelog.html#v148-2022-02-06-002514","text":"","title":"v1.4.8 - 2022-02-06 00:25:14"},{"location":"install/changelog.html#v147-2022-02-02-151953","text":"repository changes","title":"v1.4.7 - 2022-02-02 15:19:53"},{"location":"install/changelog.html#v146-2022-02-02-134322","text":"repository changes","title":"v1.4.6 - 2022-02-02 13:43:22"},{"location":"install/changelog.html#v145-2022-02-02-120804","text":"","title":"v1.4.5 - 2022-02-02 12:08:04"},{"location":"install/changelog.html#v144-2022-01-31-064142","text":"repository changes","title":"v1.4.4 - 2022-01-31 06:41:42"},{"location":"install/changelog.html#v143-2022-01-30-020001","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.4.2...v1.4.3","title":"v1.4.3 - 2022-01-30 02:00:01"},{"location":"install/changelog.html#v142-2022-01-28-140144","text":"","title":"v1.4.2 - 2022-01-28 14:01:44"},{"location":"install/changelog.html#v141-2022-01-23-154941","text":"","title":"v1.4.1 - 2022-01-23 15:49:41"},{"location":"install/changelog.html#v140-2022-01-17-122231","text":"","title":"v1.4.0 - 2022-01-17 12:22:31"},{"location":"install/changelog.html#v1334-2021-12-20-080200","text":"repository changes","title":"v1.3.34 - 2021-12-20 08:02:00"},{"location":"install/changelog.html#v1333-2021-12-19-120952","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.32...v1.3.33","title":"v1.3.33 - 2021-12-19 12:09:52"},{"location":"install/changelog.html#feature_3","text":"general: feat ( switch ) move away from.git clone ( d92d6c1 )","title":"Feature"},{"location":"install/changelog.html#bug-fixes_1","text":"general: fix ( add ) log command ( 1b7c3d4 )","title":"Bug Fixes"},{"location":"install/changelog.html#v1332-2021-12-19-023550","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.31...v1.3.32","title":"v1.3.32 - 2021-12-19 02:35:50"},{"location":"install/changelog.html#v1331-2021-12-19-022800","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.30...v1.3.31","title":"v1.3.31 - 2021-12-19 02:28:00"},{"location":"install/changelog.html#v1330-2021-12-19-021644","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.29...v1.3.30","title":"v1.3.30 - 2021-12-19 02:16:44"},{"location":"install/changelog.html#v1329-2021-12-19-020845","text":"","title":"v1.3.29 - 2021-12-19 02:08:45"},{"location":"install/changelog.html#v1328-2021-12-18-042428","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.27...v1.3.28","title":"v1.3.28 - 2021-12-18 04:24:28"},{"location":"install/changelog.html#v1327-2021-12-18-042410","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.26...v1.3.27","title":"v1.3.27 - 2021-12-18 04:24:10"},{"location":"install/changelog.html#v1326-2021-12-18-041255","text":"","title":"v1.3.26 - 2021-12-18 04:12:55"},{"location":"install/changelog.html#v1325-2021-12-17-215116","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.24...v1.3.25","title":"v1.3.25 - 2021-12-17 21:51:16"},{"location":"install/changelog.html#v1324-2021-12-17-213949","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.23...v1.3.24","title":"v1.3.24 - 2021-12-17 21:39:49"},{"location":"install/changelog.html#v1323-2021-12-17-212317","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.22...v1.3.23","title":"v1.3.23 - 2021-12-17 21:23:17"},{"location":"install/changelog.html#v1322-2021-12-17-212228","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.21...v1.3.22","title":"v1.3.22 - 2021-12-17 21:22:28"},{"location":"install/changelog.html#v1321-2021-12-17-211931","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.20...v1.3.21","title":"v1.3.21 - 2021-12-17 21:19:31"},{"location":"install/changelog.html#v1320-2021-12-17-211356","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.19...v1.3.20","title":"v1.3.20 - 2021-12-17 21:13:56"},{"location":"install/changelog.html#v1319-2021-12-17-073637","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.18...v1.3.19","title":"v1.3.19 - 2021-12-17 07:36:37"},{"location":"install/changelog.html#v1318-2021-12-17-072511","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.17...v1.3.18","title":"v1.3.18 - 2021-12-17 07:25:11"},{"location":"install/changelog.html#v1316-2021-12-17-062621","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.15...v1.3.16","title":"v1.3.16 - 2021-12-17 06:26:21"},{"location":"install/changelog.html#v1315-2021-12-17-061919","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.14...v1.3.15","title":"v1.3.15 - 2021-12-17 06:19:19"},{"location":"install/changelog.html#v1314-2021-12-17-045653","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.13...v1.3.14","title":"v1.3.14 - 2021-12-17 04:56:53"},{"location":"install/changelog.html#v1313-2021-12-17-044527","text":"","title":"v1.3.13 - 2021-12-17 04:45:27"},{"location":"install/changelog.html#v1312-2021-12-15-171819","text":"","title":"v1.3.12 - 2021-12-15 17:18:19"},{"location":"install/changelog.html#v1311-2021-12-14-072355","text":"repository changes","title":"v1.3.11 - 2021-12-14 07:23:55"},{"location":"install/changelog.html#v1310-2021-12-14-072244","text":"repository changes","title":"v1.3.10 - 2021-12-14 07:22:44"},{"location":"install/changelog.html#v139-2021-12-14-071849","text":"repository changes","title":"v1.3.9 - 2021-12-14 07:18:49"},{"location":"install/changelog.html#v138-2021-12-13-221157","text":"repository changes","title":"v1.3.8 - 2021-12-13 22:11:57"},{"location":"install/changelog.html#v137-2021-12-13-220015","text":"","title":"v1.3.7 - 2021-12-13 22:00:15"},{"location":"install/changelog.html#v136-2021-12-12-172236","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.3.5...v1.3.6","title":"v1.3.6 - 2021-12-12 17:22:36"},{"location":"install/changelog.html#v135-2021-12-12-171127","text":"","title":"v1.3.5 - 2021-12-12 17:11:27"},{"location":"install/changelog.html#v134-2021-12-12-160650","text":"repository changes","title":"v1.3.4 - 2021-12-12 16:06:50"},{"location":"install/changelog.html#v133-2021-12-12-155641","text":"repository changes","title":"v1.3.3 - 2021-12-12 15:56:41"},{"location":"install/changelog.html#v132-2021-12-12-122908","text":"repository changes","title":"v1.3.2 - 2021-12-12 12:29:08"},{"location":"install/changelog.html#v131-2021-12-12-112443","text":"repository changes","title":"v1.3.1 - 2021-12-12 11:24:43"},{"location":"install/changelog.html#v130-2021-12-12-101431","text":"repository changes","title":"v1.3.0 - 2021-12-12 10:14:31"},{"location":"install/changelog.html#v1252-2021-12-12-100321","text":"","title":"v1.2.52 - 2021-12-12 10:03:21"},{"location":"install/changelog.html#v1251-2021-12-07-150111","text":"","title":"v1.2.51 - 2021-12-07 15:01:11"},{"location":"install/changelog.html#v1250-2021-11-29-154955","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.49...v1.2.50","title":"v1.2.50 - 2021-11-29 15:49:55"},{"location":"install/changelog.html#v1249-2021-11-29-005816","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.48...v1.2.49","title":"v1.2.49 - 2021-11-29 00:58:16"},{"location":"install/changelog.html#documentation_3","text":"README: update contributors ( 24bff1a ) update contributors ( e055da1 )","title":"Documentation"},{"location":"install/changelog.html#v1248-2021-11-27-070154","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.47...v1.2.48","title":"v1.2.48 - 2021-11-27 07:01:54"},{"location":"install/changelog.html#v1247-2021-11-24-183459","text":"chore(deps): update dependency mkdocs-macros-plugin to v0.6.2 PR: #299 chore(deps): update dependency mkdocs-macros-plugin to v0.6.3 PR: #301","title":"v1.2.47 - 2021-11-24 18:34:59"},{"location":"install/changelog.html#feature_4","text":"general: ( add ) WebUI back to Uploader ( e851a0c )","title":"Feature"},{"location":"install/changelog.html#documentation_4","text":"README: update contributors ( 85d257d ) update contributors ( 4f35156 )","title":"Documentation"},{"location":"install/changelog.html#v1246-2021-11-23-134746","text":"chore(deps): update actions/cache action to v2.1.7 PR: #298","title":"v1.2.46 - 2021-11-23 13:47:46"},{"location":"install/changelog.html#documentation_5","text":"README: update contributors ( f8654ef ) update contributors ( 43c3183 )","title":"Documentation"},{"location":"install/changelog.html#v1245-2021-11-22-191559","text":"chore(deps): update dependency mkdocs-awesome-pages-plugin to v2.6.1 PR: #297","title":"v1.2.45 - 2021-11-22 19:15:59"},{"location":"install/changelog.html#documentation_6","text":"README: update contributors ( a012850 ) update contributors ( e2949f1 )","title":"Documentation"},{"location":"install/changelog.html#v1244-2021-11-21-225342","text":"","title":"v1.2.44 - 2021-11-21 22:53:42"},{"location":"install/changelog.html#v1243-2021-11-18-224745","text":"","title":"v1.2.43 - 2021-11-18 22:47:45"},{"location":"install/changelog.html#v1242-2021-11-17-123627","text":"","title":"v1.2.42 - 2021-11-17 12:36:27"},{"location":"install/changelog.html#v1241-2021-11-13-174758","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.40...v1.2.41","title":"v1.2.41 - 2021-11-13 17:47:58"},{"location":"install/changelog.html#documentation_7","text":"README: update contributors ( fc9d0c4 ) update contributors ( 84c42a8 )","title":"Documentation"},{"location":"install/changelog.html#v1240-2021-11-13-102336","text":"docs(wiki): update tauticord PR: #283","title":"v1.2.40 - 2021-11-13 10:23:36"},{"location":"install/changelog.html#v1239-2021-11-10-171653","text":"chore(deps): update dependency mkdocs-git-revision-date-localized-plugin to v0.10.2 PR: #282","title":"v1.2.39 - 2021-11-10 17:16:53"},{"location":"install/changelog.html#v1238-2021-11-09-062234","text":"","title":"v1.2.38 - 2021-11-09 06:22:34"},{"location":"install/changelog.html#v1237-2021-11-08-133941","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.36...v1.2.37","title":"v1.2.37 - 2021-11-08 13:39:41"},{"location":"install/changelog.html#documentation_8","text":"README: update contributors ( 0b38588 ) update contributors ( e621e04 ) update contributors ( 415174b )","title":"Documentation"},{"location":"install/changelog.html#v1236-2021-11-07-044242","text":"ci(Mergify): configuration update PR: #274 Configure Renovate PR: #276 chore(deps): update actions/checkout action to v2.4.0 PR: #277","title":"v1.2.36 - 2021-11-07 04:42:42"},{"location":"install/changelog.html#v1235-2021-11-06-071612","text":"repository changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.34...v1.2.35","title":"v1.2.35 - 2021-11-06 07:16:12"},{"location":"install/changelog.html#bug-fixes_2","text":"general: use version numbers for images ( 82dec0b )","title":"Bug Fixes"},{"location":"install/changelog.html#v1234-2021-11-05-103431","text":"other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.33...v1.2.34","title":"v1.2.34 - 2021-11-05 10:34:31"},{"location":"install/changelog.html#v1233-2021-11-04-175156","text":"","title":"v1.2.33 - 2021-11-04 17:51:56"},{"location":"install/changelog.html#v1232-2021-11-03-101810","text":"","title":"v1.2.32 - 2021-11-03 10:18:10"},{"location":"install/changelog.html#v1231-2021-11-02-075753","text":"","title":"v1.2.31 - 2021-11-02 07:57:53"},{"location":"install/changelog.html#v1230-2021-11-01-034513","text":"Create LICENSE PR: #265 Create LICENSE PR: #266","title":"v1.2.30 - 2021-11-01 03:45:13"},{"location":"install/changelog.html#v1229-2021-10-31-104858","text":"other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.28...v1.2.29","title":"v1.2.29 - 2021-10-31 10:48:58"},{"location":"install/changelog.html#v1228-2021-10-30-111304","text":"","title":"v1.2.28 - 2021-10-30 11:13:04"},{"location":"install/changelog.html#v1227-2021-10-29-040347","text":"Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.26...v1.2.27","title":"v1.2.27 - 2021-10-29 04:03:47"},{"location":"install/changelog.html#v1226-2021-10-28-073934","text":"other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.25...v1.2.26","title":"v1.2.26 - 2021-10-28 07:39:34"},{"location":"install/changelog.html#bug-fixes_3","text":"general: nzb/torrent folder ( fe896e6 )","title":"Bug Fixes"},{"location":"install/changelog.html#v1225-2021-10-26-053411","text":"","title":"v1.2.25 - 2021-10-26 05:34:11"},{"location":"install/changelog.html#v1224-2021-10-25-092659","text":"","title":"v1.2.24 - 2021-10-25 09:26:59"},{"location":"install/changelog.html#v1223-2021-10-24-071226","text":"","title":"v1.2.23 - 2021-10-24 07:12:26"},{"location":"install/changelog.html#v1222-2021-10-23-090001","text":"other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.21...v1.2.22","title":"v1.2.22 - 2021-10-23 09:00:01"},{"location":"install/changelog.html#v1221-2021-10-23-013738","text":"","title":"v1.2.21 - 2021-10-23 01:37:38"},{"location":"install/changelog.html#v1220-2021-10-19-102626","text":"","title":"v1.2.20 - 2021-10-19 10:26:26"},{"location":"install/changelog.html#v1219-2021-10-18-081231","text":"other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.18...v1.2.19","title":"v1.2.19 - 2021-10-18 08:12:31"},{"location":"install/changelog.html#v1218-2021-10-16-025005","text":"other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.17...v1.2.18","title":"v1.2.18 - 2021-10-16 02:50:05"},{"location":"install/changelog.html#bug-fixes_4","text":"general: faster backups ( 46891f6 )","title":"Bug Fixes"},{"location":"install/changelog.html#v1217-2021-10-15-070841","text":"other changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.16...v1.2.17","title":"v1.2.17 - 2021-10-15 07:08:41"},{"location":"install/changelog.html#v1216-2021-10-15-055440","text":"","title":"v1.2.16 - 2021-10-15 05:54:40"},{"location":"install/changelog.html#v1215-2021-10-13-061316","text":"","title":"v1.2.15 - 2021-10-13 06:13:16"},{"location":"install/changelog.html#v1214-2021-10-12-035443","text":"","title":"v1.2.14 - 2021-10-12 03:54:43"},{"location":"install/changelog.html#v1213-2021-10-11-153505","text":"","title":"v1.2.13 - 2021-10-11 15:35:05"},{"location":"install/changelog.html#v1212-2021-10-10-140235","text":"","title":"v1.2.12 - 2021-10-10 14:02:35"},{"location":"install/changelog.html#v1211-2021-10-07-122309","text":"","title":"v1.2.11 - 2021-10-07 12:23:09"},{"location":"install/changelog.html#v1210-2021-10-07-110328","text":"Revert Back to v1.2.9 Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.9...v1.2.10","title":"v1.2.10 - 2021-10-07 11:03:28"},{"location":"install/changelog.html#v129-2021-09-24-091035","text":"no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.8...v1.2.9","title":"v1.2.9 - 2021-09-24 09:10:35"},{"location":"install/changelog.html#v128-2021-09-22-161227","text":"no changes","title":"v1.2.8 - 2021-09-22 16:12:27"},{"location":"install/changelog.html#v127-2021-09-22-103511","text":"no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.6...v1.2.7","title":"v1.2.7 - 2021-09-22 10:35:11"},{"location":"install/changelog.html#v126-2021-09-16-155808","text":"no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.5...v1.2.6","title":"v1.2.6 - 2021-09-16 15:58:08"},{"location":"install/changelog.html#v125-2021-09-16-113637","text":"no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.4...v1.2.5","title":"v1.2.5 - 2021-09-16 11:36:37"},{"location":"install/changelog.html#v124-2021-09-12-183518","text":"no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.2.3...v1.2.4","title":"v1.2.4 - 2021-09-12 18:35:18"},{"location":"install/changelog.html#v123-2021-08-29-100030","text":"pip-update(deps): bump mkdocs-material from 7.2.4 to 7.2.5 in /wiki PR: #199","title":"v1.2.3 - 2021-08-29 10:00:30"},{"location":"install/changelog.html#v122-2021-08-24-070721","text":"Fixed Indentation | Removed Trailing whitespaces PR: #190 Create notifiarr.md PR: #193 Create notifiarr.yml PR: #192 GH updates(deps): Bump docker/build-push-action from 2.6.1 to 2.7.0 PR: #194 Added glances PR: #195 SET Global NameServers NS1 & NS2 PR: #197 pip-update(deps): bump mkdocs-macros-plugin from 0.5.12 to 0.6.0 in /wiki PR: #198","title":"v1.2.2 - 2021-08-24 07:07:21"},{"location":"install/changelog.html#v121-2021-08-19-174521","text":"Create pihole-updatelists.yml PR: #184 Create deemix.yml PR: #186 Hardcoded values removed PR: #188","title":"v1.2.1 - 2021-08-19 17:45:21"},{"location":"install/changelog.html#v120-2021-08-19-072231","text":"pip-update(deps): bump pygments from 2.9.0 to 2.10.0 in /wiki PR: #185","title":"v1.2.0 - 2021-08-19 07:22:31"},{"location":"install/changelog.html#v1115-2021-08-16-071239","text":"no changes Full Changelog : https://github.com/dockserver/dockserver/compare/v1.1.14...v1.1.15","title":"v1.1.15 - 2021-08-16 07:12:39"},{"location":"install/changelog.html#v1114-2021-08-14-134759","text":"no changes","title":"v1.1.14 - 2021-08-14 13:47:59"},{"location":"install/changelog.html#v1113-2021-08-12-214211","text":"pip-update(deps): bump mkdocs-material from 7.2.3 to 7.2.4 in /wiki PR: #177","title":"v1.1.13 - 2021-08-12 21:42:11"},{"location":"install/changelog.html#v1112-2021-08-10-184753","text":"no changes","title":"v1.1.12 - 2021-08-10 18:47:53"},{"location":"install/changelog.html#v1111-2021-08-10-180343","text":"Full Changelog : https://github.com/dockserver/dockserver/compare/v1.1.10...v1.1.11","title":"v1.1.11 - 2021-08-10 18:03:43"},{"location":"install/changelog.html#v1110-2021-08-10-004543","text":"no changes","title":"v1.1.10 - 2021-08-10 00:45:43"},{"location":"install/changelog.html#v119-2021-08-08-171832","text":"Uncategorized - #MYSQL IMAGE CHANGE - PR: #170","title":"v1.1.9 - 2021-08-08 17:18:32"},{"location":"install/changelog.html#v118-2021-08-05-151320","text":"Dev PR: #74 GH updates(deps): Bump mikepenz/release-changelog-builder-action from 1 to 2 PR: #77 GH updates(deps): Bump docker/login-action from 1.9.0 to 1.10.0 PR: #78 Dev PR: #76 Update portainer.md PR: #80 Update dozzle.md PR: #79 Update lidarr.md PR: #82 Update heimdall.md PR: #81 mariadb container for e.g. nextcloud PR: #84 Create instaloader.yml PR: #85 Update mellow.md PR: #92 Update conreq.md PR: #93 pip-update(deps): bump mkdocs-material from 7.1.8 to 7.1.9 in /wiki PR: #100 Update instaloader.yml PR: #99 Update jackett.md PR: #101 Update tdarr.md PR: #127 Update handbrake.yml PR: #126 Update youtubedl-material.md PR: #125 Update qbittorrent.md PR: #124 Update sabnzbd.md PR: #123 Update rutorrent.md PR: #122 Update nzbhydra.md PR: #121 Update nzbget.md PR: #120 Update jdownloader2.md PR: #118 Update filezilla.md PR: #117 Update deluge.md PR: #116 Update davos.md PR: #115 Update code-server.md PR: #114 Update cloud9.md PR: #113 Update rsnapshot.md PR: #112 Update duplicati.md PR: #111 Update backup.md PR: #110 Update vnstat.md PR: #109 Update speedtest.md PR: #108 Update remmina.md PR: #107 Update netdata.md PR: #106 Update librespeed.md PR: #105 Update flaresolverr.md PR: #104 Update cloudcmd.md PR: #103 Update mount.md PR: #90 Update instaloader.yml PR: #102 Update jackett.md PR: #119 GH updates(deps): Bump docker/setup-buildx-action from 1.3.0 to 1.4.1 PR: #129 Patch 11 PR: #133 Create kitana.yml PR: #131 Create kitana.md PR: #130 GH updates(deps): Bump docker/build-push-action from 2.5.0 to 2.6.1 PR: #135 Patch 12 PR: #136 GH updates(deps): Bump docker/setup-buildx-action from 1.4.1 to 1.5.0 PR: #138 pip-update(deps): bump mkdocs-material from 7.1.9 to 7.1.10 in /wiki PR: #146 GH updates(deps): Bump docker/setup-buildx-action from 1.5.0 to 1.5.1 PR: #145 GH updates(deps): Bump actions/stale from 3.0.19 to 4 PR: #147 pip-update(deps): bump mkdocs-material from 7.1.10 to 7.1.11 in /wiki PR: #149 pip-update(deps): bump mkdocs from 1.2.1 to 1.2.2 in /wiki PR: #150 pip-update(deps): bump mkdocs-material from 7.1.11 to 7.2.0 in /wiki PR: #152 pip-update(deps): bump mkdocs-material from 7.2.0 to 7.2.1 in /wiki PR: #155 Create fail2ban.yml PR: #156 pip-update(deps): bump mkdocs-material from 7.2.1 to 7.2.2 in /wiki PR: #161 Pihole + Unbound (two containers) | Pihole + Unbound (one container) PR: #160 Add TCP BBR PR: #164","title":"v1.1.8 - 2021-08-05 15:13:20"},{"location":"install/changelog.html#patch-update-code-serveryml","text":"PR: #165","title":"patch Update code-server.yml"},{"location":"install/changelog.html#v117-2021-06-23-114042","text":"no changes","title":"v1.1.7 - 2021-06-23 11:40:42"},{"location":"install/changelog.html#v116-2021-06-13-155710","text":"Full Changelog : https://github.com/dockserver/dockserver/compare/v1.1.5...v1.1.6","title":"v1.1.6 - 2021-06-13 15:57:10"},{"location":"install/changelog.html#v115-2021-06-12-165442","text":"","title":"v1.1.5 - 2021-06-12 16:54:42"},{"location":"install/changelog.html#v114-2021-06-12-102347","text":"","title":"v1.1.4 - 2021-06-12 10:23:47"},{"location":"install/changelog.html#v113-2021-06-11-205746","text":"","title":"v1.1.3 - 2021-06-11 20:57:46"},{"location":"install/changelog.html#v112-2021-06-09-212814","text":"","title":"v1.1.2 - 2021-06-09 21:28:14"},{"location":"install/changelog.html#v111-2021-06-09-182731","text":"","title":"v1.1.1 - 2021-06-09 18:27:31"},{"location":"install/changelog.html#v110-2021-06-09-170859","text":"","title":"v1.1.0 - 2021-06-09 17:08:59"},{"location":"install/changelog.html#v100-2021-06-02-180321","text":"* This CHANGELOG was automatically generated by auto-generate-changelog","title":"v1.0.0 - 2021-06-02 18:03:21"},{"location":"install/cloudflare.html","text":"Cloudflare \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Cloudflare"},{"location":"install/cloudflare.html#cloudflare","text":"Wiki Coming Soon .....","title":"Cloudflare"},{"location":"install/cloudflare.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"install/container-gitlog.html","text":"2024-06-05 \u00b6 [Auto Generation] Changelog : (dockserver-bot[bot])","title":"Changelog"},{"location":"install/container-gitlog.html#2024-06-05","text":"[Auto Generation] Changelog : (dockserver-bot[bot])","title":"2024-06-05"},{"location":"install/container.html","text":"Container Images \u00b6 All Dockefiles are automatically generated Do not try to change anything live on the repository All changes are made from our own CI Pipline ( unpublic ) We are out of the dev version. All Containers can be used without breaking. You can use all with dockserver Don't use the images / dockers on other projects This should not work for you. Before open a feature request/ pull_request or issues \u00b6 We don't accept pull_request for other projects. We don't accept any changes what breaks dockserver. We don't give any help for other projects to run this dockers. Notice Alpine Builds \u00b6 radarr sonarr sabnzbd lidarr readarr bazarr duplicati And many more...... More and more dockers will use alpine as base image What that's all ?! \u00b6 Nope... we have build our own CI/CD PIPLINE It's runs inside of a isolated Container environment Specs : (( SELF HOSTED )) I9-9900k 64GB RAM 1 DATACENTER NVME 512GB *( isolated docker based github runner )) Some hidden Updates are pushed \u00b6 We provide as next some hidden scripts to build the docker images based of a json / shell file (( runs since 4 weeks now )) Also we have added a new layer for check of any breaches. Next what is also added : one dependencies script to pull the latest versions of every dependencies what is used inside of the docker push to public ?! And show the code ?? \u00b6 No way ..... We didn't show them , since I know some other are stealing here, Without given any credits or respect Ideas and Code \u00b6 This repository is heavily based on Linuxserver.io images and k8s-at-home idea All Containers have some additional edits just for dockserver.io Please check before you run it on other systems And the best is Fuck XOXO SBOX stealing code to get your product up and running is a bitch move SOME fancy stats Own Builded Containers JsonSchema \u00b6","title":"Container"},{"location":"install/container.html#container-images","text":"All Dockefiles are automatically generated Do not try to change anything live on the repository All changes are made from our own CI Pipline ( unpublic ) We are out of the dev version. All Containers can be used without breaking. You can use all with dockserver Don't use the images / dockers on other projects This should not work for you.","title":"Container Images"},{"location":"install/container.html#before-open-a-feature-request-pull_request-or-issues","text":"We don't accept pull_request for other projects. We don't accept any changes what breaks dockserver. We don't give any help for other projects to run this dockers.","title":"Before open a feature request/ pull_request or issues"},{"location":"install/container.html#notice-alpine-builds","text":"radarr sonarr sabnzbd lidarr readarr bazarr duplicati And many more...... More and more dockers will use alpine as base image","title":"Notice Alpine Builds"},{"location":"install/container.html#what-thats-all","text":"Nope... we have build our own CI/CD PIPLINE It's runs inside of a isolated Container environment Specs : (( SELF HOSTED )) I9-9900k 64GB RAM 1 DATACENTER NVME 512GB *( isolated docker based github runner ))","title":"What that's all ?!"},{"location":"install/container.html#some-hidden-updates-are-pushed","text":"We provide as next some hidden scripts to build the docker images based of a json / shell file (( runs since 4 weeks now )) Also we have added a new layer for check of any breaches. Next what is also added : one dependencies script to pull the latest versions of every dependencies what is used inside of the docker","title":"Some hidden Updates are pushed"},{"location":"install/container.html#push-to-public-and-show-the-code","text":"No way ..... We didn't show them , since I know some other are stealing here, Without given any credits or respect","title":"push to public ?! And show the code ??"},{"location":"install/container.html#ideas-and-code","text":"This repository is heavily based on Linuxserver.io images and k8s-at-home idea All Containers have some additional edits just for dockserver.io Please check before you run it on other systems And the best is Fuck XOXO SBOX stealing code to get your product up and running is a bitch move SOME fancy stats Own Builded Containers","title":"Ideas and Code"},{"location":"install/container.html#jsonschema","text":"","title":"JsonSchema"},{"location":"install/install.html","text":"DockServer \u00b6 Pre-Install \u00b6 Login to your Cloudflare Account & goto DNS click on Add record. Add 1 A-Record pointed to your server's ip. Copy your CloudFlare-Global-Key and CloudFlare-Zone-ID . Set the following on Cloudflare \u00b6 SSL = FULL ( not FULL/STRICT ) Always on = YES HTTP to HTTPS = YES RocketLoader and Broli / Onion Routing = NO TLS min = 1.2 TLS = v1.3 Update System before you begin with installation \u00b6 sudo apt-get update -yqq sudo apt-get upgrade -yqq sudo apt-get autoclean -yqq Easy Mode install \u00b6 Run the following command: sudo wget -qO- https://git.io/J3GDc | sudo bash Long commmand if the short one doesn't work. sudo wget -qO- https://raw.githubusercontent.com/dockserver/dockserver/master/wgetfile.sh | sudo bash Open the dockserver Interface \u00b6 sudo dockserver -i Now the preinstall runs full automatic If not triggered by installer, please restart your server. Install Traefik & Authelia first \u00b6 Note ( critical step | without dockserver will not work ) After deployment of Traefik & Authelia you have to install mount , then you can install any app. Open the dockserver Interface again Type 2 Type 1 now you can see all the apps sections.","title":"Installation"},{"location":"install/install.html#dockserver","text":"","title":"DockServer"},{"location":"install/install.html#pre-install","text":"Login to your Cloudflare Account & goto DNS click on Add record. Add 1 A-Record pointed to your server's ip. Copy your CloudFlare-Global-Key and CloudFlare-Zone-ID .","title":"Pre-Install"},{"location":"install/install.html#set-the-following-on-cloudflare","text":"SSL = FULL ( not FULL/STRICT ) Always on = YES HTTP to HTTPS = YES RocketLoader and Broli / Onion Routing = NO TLS min = 1.2 TLS = v1.3","title":"Set the following on Cloudflare"},{"location":"install/install.html#update-system-before-you-begin-with-installation","text":"sudo apt-get update -yqq sudo apt-get upgrade -yqq sudo apt-get autoclean -yqq","title":"Update System before you begin with installation"},{"location":"install/install.html#easy-mode-install","text":"Run the following command: sudo wget -qO- https://git.io/J3GDc | sudo bash Long commmand if the short one doesn't work. sudo wget -qO- https://raw.githubusercontent.com/dockserver/dockserver/master/wgetfile.sh | sudo bash","title":"Easy Mode install"},{"location":"install/install.html#open-the-dockserver-interface","text":"sudo dockserver -i Now the preinstall runs full automatic If not triggered by installer, please restart your server.","title":"Open the dockserver Interface"},{"location":"install/install.html#install-traefik-authelia-first","text":"Note ( critical step | without dockserver will not work ) After deployment of Traefik & Authelia you have to install mount , then you can install any app. Open the dockserver Interface again Type 2 Type 1 now you can see all the apps sections.","title":"Install Traefik &amp; Authelia first"},{"location":"install/migration.html","text":"Migration Introduction \u00b6 While many of us has enjoyed PGblitz over the years, the project is now scattered. Some simply ghosted the whole community, and the rest of the devs are working on other projects. Even though PGblitz still works, there are numerous upsides in shifting to dockserver: Updated rclone/mount No file limits Sonarr/Radarr can now analyze the media without hitting api bans On-the-fly configuration of HW Transcoding Intelligent uploader that will automatically start pushing your content to the cloud when disk space is getting low ...to name a few... Before you start: \u00b6 We strongly recommend restoring your Server on a VPS or something similar before making the final migration. This is to avoid data-loss and to harden your backups for your final dockserver migration. This guide will take you through a migration with Teamdrive deployed on your pg installation. Feel free to experiement with the gdsa builder in the CLI. Prerequisites: \u00b6 PGblitz Tdrive/Tcrypt mount deployed CloudCMD deployed (Under Community Apps) Open CloudCMD, Navigate to: /appdata/plexguide/.blitzkeys Download the contents of that folder (rclone.conf and GDSA keys) to your local machine. These files are very important. Handle with care. On some forks of PG these files are placed under /uploader and /mount. Now you are ready to backup your PG apps. sudo wget -qO- https://raw.githubusercontent.com/dockserver/dockserver/master/backup.sh | sudo bash This will create a folder named /appbackups on the root of your remote drive. When the backup is done, check that these files exist on your remote drive. Also, check them for file sizes to make sure it looks right. Plex can take a long time, be patient. Now, please order a VPS with ubuntu 22 on it and follow the instructions on the Wiki . When dockserver is installed on your host, return here and follow instructions Mount & Uploader \u00b6 Open a terminal Create the folders sudo mkdir -p /opt/appdata/system/{rclone,servicekeys} sudo chown -cR 1000:1000 /opt/appdata Install CloudCMD (under addons) Navigate to /opt/appdata/system/rclone Upload the rclone.conf from your old server. Do not rename this one. Navigate to /opt/appdata/system/servicekeys Upload the the same rclone.conf to this folder. Rename this rclone.conf to rclonegdsa.conf Navigate to /opt/appdata/system/servicekeys/keys Upload all service keys (GDSA01,02..) Rename all service keys to not containing a 0 so GDSA01 becomes GDSA1 and so forth.. Edit your rclone.conf sudo nano /opt/appdata/system/rclone/rclone.conf Remove all GDSA lines here, only the remotes(g/tdrive, g/tcrypt) are left in the file - PGUNION has to be deleted as well Like this: [gdrive] client_id = XOXOYOURID client_secret = XOXOYOURSECRET type = drive server_side_across_configs = true token = XOXOYOURTOKEN [tdrive] client_id = XOXOYOURID client_secret = XOXOYOURSECRET type = drive server_side_across_configs = true token = XOXOYOURTOKEN team_drive = XXXXXXXXXXXXXXXXXXX [tdrive2] client_id = XOXOYOURID client_secret = XOXOYOURSECRET type = drive server_side_across_configs = true token = XOXOYOURTOKEN team_drive = XXXXXXXXXXXXXXXXXXX CTRX+X press y Edit rclonegdsa.conf sudo nano /opt/appdata/system/servicekeys/rclonegdsa.conf Remove all the remotes (g/tdrive, g/tcrypt) - PGUNION has to be deleted as well. You'll also want to make sure to update the service_account_file line. Remove the previous path and change it to /system/servicekeys/keys/ like below. Again, remove all zeroes so that the values will be displayed like this: [GDSA1] type = drive scope = drive service_account_file = /system/servicekeys/keys/GDSA1 team_drive = XXXXXXXXXXXXXXXXXXX [GDSA2] type = drive scope = drive service_account_file = /system/servicekeys/keys/GDSA2 team_drive = XXXXXXXXXXXXXXXXXXX CTRL+X y Done. Now you can deploy mount & uploader under in the system section in the CLI After this you are ready to restore your PG apps on a brand new Dockserver installation Note: \u00b6 Google Token Expire it may possible that your Google token expires after a server reboot/migration or other things logs can be checked with this: sudo tail -n 50 -f /opt/appdata/system/mount/logs/rclone-union.log And you can also check if remotes are displaying something: sudo docker exec mount ls -1p /mnt/unionfs if you see something like: Token Expired or could not authenticate with google then this is your solution (only do a token refresh): sudo docker stop mount sudo fusermount -uzq /mnt/unionfs sudo fusermount -uzq /mnt/remotes cd /opt/appdata/system/rclone You can install rclone using the following command: sudo apt install curl jq && sudo curl https://rclone.org/install.sh | sudo bash After installing Rclone, verify the Rclone version with the following command: sudo rclone --version Then reconnect: rclone config reconnect tdrive: --config=rclone.conf rclone config reconnect gdrive: --config=rclone.conf Then start mount again: sudo fusermount -uzq /mnt/unionfs sudo docker start mount sudo docker logs -f mount ( or use dozzle for the logs reading ) Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our","title":"Migration"},{"location":"install/migration.html#migration-introduction","text":"While many of us has enjoyed PGblitz over the years, the project is now scattered. Some simply ghosted the whole community, and the rest of the devs are working on other projects. Even though PGblitz still works, there are numerous upsides in shifting to dockserver: Updated rclone/mount No file limits Sonarr/Radarr can now analyze the media without hitting api bans On-the-fly configuration of HW Transcoding Intelligent uploader that will automatically start pushing your content to the cloud when disk space is getting low ...to name a few...","title":"Migration Introduction"},{"location":"install/migration.html#before-you-start","text":"We strongly recommend restoring your Server on a VPS or something similar before making the final migration. This is to avoid data-loss and to harden your backups for your final dockserver migration. This guide will take you through a migration with Teamdrive deployed on your pg installation. Feel free to experiement with the gdsa builder in the CLI.","title":"Before you start:"},{"location":"install/migration.html#prerequisites","text":"PGblitz Tdrive/Tcrypt mount deployed CloudCMD deployed (Under Community Apps) Open CloudCMD, Navigate to: /appdata/plexguide/.blitzkeys Download the contents of that folder (rclone.conf and GDSA keys) to your local machine. These files are very important. Handle with care. On some forks of PG these files are placed under /uploader and /mount. Now you are ready to backup your PG apps. sudo wget -qO- https://raw.githubusercontent.com/dockserver/dockserver/master/backup.sh | sudo bash This will create a folder named /appbackups on the root of your remote drive. When the backup is done, check that these files exist on your remote drive. Also, check them for file sizes to make sure it looks right. Plex can take a long time, be patient. Now, please order a VPS with ubuntu 22 on it and follow the instructions on the Wiki . When dockserver is installed on your host, return here and follow instructions","title":"Prerequisites:"},{"location":"install/migration.html#mount-uploader","text":"Open a terminal Create the folders sudo mkdir -p /opt/appdata/system/{rclone,servicekeys} sudo chown -cR 1000:1000 /opt/appdata Install CloudCMD (under addons) Navigate to /opt/appdata/system/rclone Upload the rclone.conf from your old server. Do not rename this one. Navigate to /opt/appdata/system/servicekeys Upload the the same rclone.conf to this folder. Rename this rclone.conf to rclonegdsa.conf Navigate to /opt/appdata/system/servicekeys/keys Upload all service keys (GDSA01,02..) Rename all service keys to not containing a 0 so GDSA01 becomes GDSA1 and so forth.. Edit your rclone.conf sudo nano /opt/appdata/system/rclone/rclone.conf Remove all GDSA lines here, only the remotes(g/tdrive, g/tcrypt) are left in the file - PGUNION has to be deleted as well Like this: [gdrive] client_id = XOXOYOURID client_secret = XOXOYOURSECRET type = drive server_side_across_configs = true token = XOXOYOURTOKEN [tdrive] client_id = XOXOYOURID client_secret = XOXOYOURSECRET type = drive server_side_across_configs = true token = XOXOYOURTOKEN team_drive = XXXXXXXXXXXXXXXXXXX [tdrive2] client_id = XOXOYOURID client_secret = XOXOYOURSECRET type = drive server_side_across_configs = true token = XOXOYOURTOKEN team_drive = XXXXXXXXXXXXXXXXXXX CTRX+X press y Edit rclonegdsa.conf sudo nano /opt/appdata/system/servicekeys/rclonegdsa.conf Remove all the remotes (g/tdrive, g/tcrypt) - PGUNION has to be deleted as well. You'll also want to make sure to update the service_account_file line. Remove the previous path and change it to /system/servicekeys/keys/ like below. Again, remove all zeroes so that the values will be displayed like this: [GDSA1] type = drive scope = drive service_account_file = /system/servicekeys/keys/GDSA1 team_drive = XXXXXXXXXXXXXXXXXXX [GDSA2] type = drive scope = drive service_account_file = /system/servicekeys/keys/GDSA2 team_drive = XXXXXXXXXXXXXXXXXXX CTRL+X y Done. Now you can deploy mount & uploader under in the system section in the CLI After this you are ready to restore your PG apps on a brand new Dockserver installation","title":"Mount &amp; Uploader"},{"location":"install/migration.html#note","text":"Google Token Expire it may possible that your Google token expires after a server reboot/migration or other things logs can be checked with this: sudo tail -n 50 -f /opt/appdata/system/mount/logs/rclone-union.log And you can also check if remotes are displaying something: sudo docker exec mount ls -1p /mnt/unionfs if you see something like: Token Expired or could not authenticate with google then this is your solution (only do a token refresh): sudo docker stop mount sudo fusermount -uzq /mnt/unionfs sudo fusermount -uzq /mnt/remotes cd /opt/appdata/system/rclone You can install rclone using the following command: sudo apt install curl jq && sudo curl https://rclone.org/install.sh | sudo bash After installing Rclone, verify the Rclone version with the following command: sudo rclone --version Then reconnect: rclone config reconnect tdrive: --config=rclone.conf rclone config reconnect gdrive: --config=rclone.conf Then start mount again: sudo fusermount -uzq /mnt/unionfs sudo docker start mount sudo docker logs -f mount ( or use dozzle for the logs reading )","title":"Note:"},{"location":"install/migration.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our","title":"Support"},{"location":"install/traefik.html","text":"Treafik \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Traefik"},{"location":"install/traefik.html#treafik","text":"Wiki Coming Soon .....","title":"Treafik"},{"location":"install/traefik.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"lxc/lxc.html","text":"LXC Container \u00b6 How to install DockServer on a Proxmox LXC container \u00b6 This guide will take you through how to prepare Proxmox to install DockServer on an LXC. Key Points \u00b6 This guide assumes you already have Proxmox installed and working. These instructions arw working on 6.4-6 Do not use Debian as the Linux image. Networking is shocking and dies after a day or so due to NIC namespace. This guide was written for Ubuntu 20.04 Apparmour must be disabled and deleted. If not, Authelia will fail at the password hashing stage. Your LXC must be a privileged container. Unpriviliged containers do not allow GPU passthrough which is needed for Plex transcoding. If you have local drives that you wish to mount, there are a couple of extra lines required in the xxx.conf file. These are the settings that I have set which I have found work well. Your own millage will vary depending on your setup. Guide \u00b6 Download Ubuntu template. Recommended version is Ubunto 20.04 Standard. Create a new LXC container: General tab: Give the container a name in the 'Hostname' field. Remove the tick from 'Unprivileged container'. Set the password and confirm the password you wish to use for CLI access. Template tab: Choose the Ubuntu template. Root Disk tab: Set the disk size high enough to handle all DockServer apps. Allow room for expansion. I personally have this set to 500Gb. CPU tab: Add the number of cores that you want assigned to the LXC. Remember, you will probably have Plex installed in Docker, along with multiple other apps all demanding processing power. I personally have this set to 6 cores. Memory tab: Set the memory and swap size accordingly. Bear in mind the previous comment regarding number of CPU cores. I personally have this set to 8192MiB for both Memory and Swap. Network tab: Uncheck 'Firewall'. 'IPv4' and 'IPv6' - I set these both of these to DHCP and then reserve the MAC address in my routers DHCP server. DNS tab: Leave this tab alone. Confirm tab - check your settings and select 'Finish'. IMPORTANT NOTE - DO NOT START THE CONTAINER YET! \u00b6 Before starting the container, you need to set the following on the Options, Features tab: Nesting CIFS NFS Fuse GPU Passthrough \u00b6 Run the steps on the following guide to pass through the GPU (my own system is an Intel GPU so I followed each step exactly without any changes and everything worked): https://forums.plex.tv/t/pms-installation-guide-when-using-a-proxmox-5-1-lxc-container/219728 NOTE: the above steps worked for Proxmox 6 however with changes to cgroup to cgroup2, the lxc conf file stated: lxc.cgroup.devices.allow = c 226:0 rwm lxc.cgroup.devices.allow = c 226:128 rwm lxc.cgroup.devices.allow = c 29:0 rwm lxc.autodev: 1 lxc.hook.autodev:/var/lib/lxc/100/mount_hook.sh Changes this to: lxc.cgroup2.devices.allow: a 227 lxc.cap.drop: 228 lxc.cgroup2.devices.allow: c 226:0 rwm 229 lxc.cgroup2.devices.allow: c 226:128 rwm 230 lxc.cgroup2.devices.allow: c 29:0 rwm 231 lxc.autodev: 1 232 lxc.hook.autodev: /var/lib/lxc/112/mount_hook.sh Be mindful of the last line - change this to your correct container number rather than 112! Mounting external NFS Drives \u00b6 In Datacenter , Storage add your NFS external drives. Open a shell from the node. Replace 120 with the container number: nano /etc/pve/lxc/120.conf Add the following line('s) as appropriate to the drives you wish to gain access to: mp0: /mnt/pve/Media,mp = /mnt/Media mp1: /mnt/pve/Pictures,mp = /mnt/Pictures mp2: /mnt/pve/Music,mp = /mnt/Music You can now start the container How to Disable and Delete Apparmour: \u00b6 Once the container is up and running and you have logged in: Stop Apparmour service: systemctl stop apparmor Disable Apparmor from starting on system boot: systemctl disable apparmor Remove Apparmor package and dependencies: apt remove --assume-yes --purge apparmor Now your LXC is ready to continue the install of DockServer Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"LXC-Container"},{"location":"lxc/lxc.html#lxc-container","text":"","title":"LXC Container"},{"location":"lxc/lxc.html#how-to-install-dockserver-on-a-proxmox-lxc-container","text":"This guide will take you through how to prepare Proxmox to install DockServer on an LXC.","title":"How to install DockServer on a Proxmox LXC container"},{"location":"lxc/lxc.html#key-points","text":"This guide assumes you already have Proxmox installed and working. These instructions arw working on 6.4-6 Do not use Debian as the Linux image. Networking is shocking and dies after a day or so due to NIC namespace. This guide was written for Ubuntu 20.04 Apparmour must be disabled and deleted. If not, Authelia will fail at the password hashing stage. Your LXC must be a privileged container. Unpriviliged containers do not allow GPU passthrough which is needed for Plex transcoding. If you have local drives that you wish to mount, there are a couple of extra lines required in the xxx.conf file. These are the settings that I have set which I have found work well. Your own millage will vary depending on your setup.","title":"Key Points"},{"location":"lxc/lxc.html#guide","text":"Download Ubuntu template. Recommended version is Ubunto 20.04 Standard. Create a new LXC container: General tab: Give the container a name in the 'Hostname' field. Remove the tick from 'Unprivileged container'. Set the password and confirm the password you wish to use for CLI access. Template tab: Choose the Ubuntu template. Root Disk tab: Set the disk size high enough to handle all DockServer apps. Allow room for expansion. I personally have this set to 500Gb. CPU tab: Add the number of cores that you want assigned to the LXC. Remember, you will probably have Plex installed in Docker, along with multiple other apps all demanding processing power. I personally have this set to 6 cores. Memory tab: Set the memory and swap size accordingly. Bear in mind the previous comment regarding number of CPU cores. I personally have this set to 8192MiB for both Memory and Swap. Network tab: Uncheck 'Firewall'. 'IPv4' and 'IPv6' - I set these both of these to DHCP and then reserve the MAC address in my routers DHCP server. DNS tab: Leave this tab alone. Confirm tab - check your settings and select 'Finish'.","title":"Guide"},{"location":"lxc/lxc.html#important-note-do-not-start-the-container-yet","text":"Before starting the container, you need to set the following on the Options, Features tab: Nesting CIFS NFS Fuse","title":"IMPORTANT NOTE - DO NOT START THE CONTAINER YET!"},{"location":"lxc/lxc.html#gpu-passthrough","text":"Run the steps on the following guide to pass through the GPU (my own system is an Intel GPU so I followed each step exactly without any changes and everything worked): https://forums.plex.tv/t/pms-installation-guide-when-using-a-proxmox-5-1-lxc-container/219728 NOTE: the above steps worked for Proxmox 6 however with changes to cgroup to cgroup2, the lxc conf file stated: lxc.cgroup.devices.allow = c 226:0 rwm lxc.cgroup.devices.allow = c 226:128 rwm lxc.cgroup.devices.allow = c 29:0 rwm lxc.autodev: 1 lxc.hook.autodev:/var/lib/lxc/100/mount_hook.sh Changes this to: lxc.cgroup2.devices.allow: a 227 lxc.cap.drop: 228 lxc.cgroup2.devices.allow: c 226:0 rwm 229 lxc.cgroup2.devices.allow: c 226:128 rwm 230 lxc.cgroup2.devices.allow: c 29:0 rwm 231 lxc.autodev: 1 232 lxc.hook.autodev: /var/lib/lxc/112/mount_hook.sh Be mindful of the last line - change this to your correct container number rather than 112!","title":"GPU Passthrough"},{"location":"lxc/lxc.html#mounting-external-nfs-drives","text":"In Datacenter , Storage add your NFS external drives. Open a shell from the node. Replace 120 with the container number: nano /etc/pve/lxc/120.conf Add the following line('s) as appropriate to the drives you wish to gain access to: mp0: /mnt/pve/Media,mp = /mnt/Media mp1: /mnt/pve/Pictures,mp = /mnt/Pictures mp2: /mnt/pve/Music,mp = /mnt/Music You can now start the container","title":"Mounting external NFS Drives"},{"location":"lxc/lxc.html#how-to-disable-and-delete-apparmour","text":"Once the container is up and running and you have logged in: Stop Apparmour service: systemctl stop apparmor Disable Apparmor from starting on system boot: systemctl disable apparmor Remove Apparmor package and dependencies: apt remove --assume-yes --purge apparmor Now your LXC is ready to continue the install of DockServer","title":"How to Disable and Delete Apparmour:"},{"location":"lxc/lxc.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"scripts/scripts.html","text":"DS - Scripts \u00b6 Wiki Coming Soon ..... Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Scripts"},{"location":"scripts/scripts.html#ds-scripts","text":"Wiki Coming Soon .....","title":"DS - Scripts"},{"location":"scripts/scripts.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"},{"location":"tunnel/cf_tunnel.html","text":"Cloudflared \u00b6 Cloudflare Tunnel \u00b6 Easily expose your locally hosted services securly, using Cloudflare Tunnel! IMPORTANT - A Cloudflare Tunnel can only be used with apps that can be accessed over port 80 and 443. - Example: TAUTULLI will still be accessible over tautulli.domain.com but PLEX only over SERVER_IP:32400. Cloudflare Setup \u00b6 Create cloudflared folder. mkdir /opt/appdata/cloudflared && chmod 777 /opt/appdata/cloudflared Download latest Cloudflared Docker Image. docker pull cloudflare/cloudflared:latest Clouflare login. docker run -it --rm -v /opt/appdata/cloudflared:/home/nonroot/.cloudflared/ cloudflare/cloudflared:latest tunnel login Follow the link provided and log into your Cloudflare account. Authorize Cloudflared to access your domain. Create your Cloudflare Tunnel. docker run -it --rm -v /opt/appdata/cloudflared:/home/nonroot/.cloudflared/ cloudflare/cloudflared:latest tunnel create tunnel-YOUR_TUNNEL_NAME Change tunnel-YOUR_TUNNEL_NAME to wathever you like. Download the config.yaml to /opt/appdata/cloudflared/ . wget https://raw.githubusercontent.com/dockserver/dockserver/863a2a0dacaf1a9f076d236f1f918dbbed138865/traefik/templates/cloudflared/config.yaml -O /opt/appdata/cloudflared/config.yaml Edit config.yaml and add the TUNNEL_UUID. CONFIG \u00b6 # Cloudflared tunnel : TUNNEL_UUID credentials-file : /home/nonroot/.cloudflared/TUNNEL_UUID.json # NOTE: You should only have one ingress tag, so if you uncomment one block comment the others # forward all traffic to Reverse Proxy w/ SSL #ingress: #- service: https://${SERVERIP}:443 #originRequest: #originServerName: dns-cloudflare.acme #forward all traffic to Reverse Proxy w/ SSL and no TLS Verify ingress : - service : https://traefik:443 originRequest : noTLSVerify : true #ingress: # - hostname: ssh.domain.com # service: ssh://SSHIP:PORT # - service: https://traefik:443 # originRequest: # noTLSVerify: true # forward all traffic to reverse proxy over http #ingress: # - service: http://REVERSEPROXYIP:PORT CONFIG VALUES \u00b6 Setting Default Description tunnel null TUNNEL_UUID retrieved in STEP 5. credentials-file null TUNNEL_UUID retrieved in STEP 5. Example: # Cloudflared tunnel : a8fc25aa-xxxx-450b-8c59-xxxxxx credentials-file : /home/nonroot/.cloudflared/a8fc25aa-xxxx-450b-8c59-xxxxxx.json # NOTE: You should only have one ingress tag, so if you uncomment one block comment the others # forward all traffic to Reverse Proxy w/ SSL #ingress: #- service: https://${SERVERIP}:443 #originRequest: #originServerName: dns-cloudflare.acme #forward all traffic to Reverse Proxy w/ SSL and no TLS Verify ingress : - service : https://traefik:443 originRequest : noTLSVerify : true . . . Download the cloudflared.yml to /opt/dockserver/apps/myapps/ . wget https://raw.githubusercontent.com/dockserver/apps/master/cloudflared/docker-compose.yml -O /opt/dockserver/apps/myapps/cloudflared.yml Deploy Cloudflared over DockServer. Et voil\u00e0! Your tunnel has been created. IMPORTANT - If you already have records for your apps, you need to change the target to the tunnel target. Support \u00b6 Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Cloudflare Tunnel"},{"location":"tunnel/cf_tunnel.html#cloudflared","text":"","title":"Cloudflared"},{"location":"tunnel/cf_tunnel.html#cloudflare-tunnel","text":"Easily expose your locally hosted services securly, using Cloudflare Tunnel! IMPORTANT - A Cloudflare Tunnel can only be used with apps that can be accessed over port 80 and 443. - Example: TAUTULLI will still be accessible over tautulli.domain.com but PLEX only over SERVER_IP:32400.","title":"Cloudflare Tunnel"},{"location":"tunnel/cf_tunnel.html#cloudflare-setup","text":"Create cloudflared folder. mkdir /opt/appdata/cloudflared && chmod 777 /opt/appdata/cloudflared Download latest Cloudflared Docker Image. docker pull cloudflare/cloudflared:latest Clouflare login. docker run -it --rm -v /opt/appdata/cloudflared:/home/nonroot/.cloudflared/ cloudflare/cloudflared:latest tunnel login Follow the link provided and log into your Cloudflare account. Authorize Cloudflared to access your domain. Create your Cloudflare Tunnel. docker run -it --rm -v /opt/appdata/cloudflared:/home/nonroot/.cloudflared/ cloudflare/cloudflared:latest tunnel create tunnel-YOUR_TUNNEL_NAME Change tunnel-YOUR_TUNNEL_NAME to wathever you like. Download the config.yaml to /opt/appdata/cloudflared/ . wget https://raw.githubusercontent.com/dockserver/dockserver/863a2a0dacaf1a9f076d236f1f918dbbed138865/traefik/templates/cloudflared/config.yaml -O /opt/appdata/cloudflared/config.yaml Edit config.yaml and add the TUNNEL_UUID.","title":"Cloudflare Setup"},{"location":"tunnel/cf_tunnel.html#config","text":"# Cloudflared tunnel : TUNNEL_UUID credentials-file : /home/nonroot/.cloudflared/TUNNEL_UUID.json # NOTE: You should only have one ingress tag, so if you uncomment one block comment the others # forward all traffic to Reverse Proxy w/ SSL #ingress: #- service: https://${SERVERIP}:443 #originRequest: #originServerName: dns-cloudflare.acme #forward all traffic to Reverse Proxy w/ SSL and no TLS Verify ingress : - service : https://traefik:443 originRequest : noTLSVerify : true #ingress: # - hostname: ssh.domain.com # service: ssh://SSHIP:PORT # - service: https://traefik:443 # originRequest: # noTLSVerify: true # forward all traffic to reverse proxy over http #ingress: # - service: http://REVERSEPROXYIP:PORT","title":"CONFIG"},{"location":"tunnel/cf_tunnel.html#config-values","text":"Setting Default Description tunnel null TUNNEL_UUID retrieved in STEP 5. credentials-file null TUNNEL_UUID retrieved in STEP 5. Example: # Cloudflared tunnel : a8fc25aa-xxxx-450b-8c59-xxxxxx credentials-file : /home/nonroot/.cloudflared/a8fc25aa-xxxx-450b-8c59-xxxxxx.json # NOTE: You should only have one ingress tag, so if you uncomment one block comment the others # forward all traffic to Reverse Proxy w/ SSL #ingress: #- service: https://${SERVERIP}:443 #originRequest: #originServerName: dns-cloudflare.acme #forward all traffic to Reverse Proxy w/ SSL and no TLS Verify ingress : - service : https://traefik:443 originRequest : noTLSVerify : true . . . Download the cloudflared.yml to /opt/dockserver/apps/myapps/ . wget https://raw.githubusercontent.com/dockserver/apps/master/cloudflared/docker-compose.yml -O /opt/dockserver/apps/myapps/cloudflared.yml Deploy Cloudflared over DockServer. Et voil\u00e0! Your tunnel has been created. IMPORTANT - If you already have records for your apps, you need to change the target to the tunnel target.","title":"CONFIG VALUES"},{"location":"tunnel/cf_tunnel.html#support","text":"Kindly report any issues/broken-parts/bugs on github or discord Join our for Support","title":"Support"}]}